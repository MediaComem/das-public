<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Comput Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Comput. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Computational Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1662-5188</issn><publisher><publisher-name>Frontiers Research Foundation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">21160547</article-id><article-id pub-id-type="pmc">PMC3001740</article-id><article-id pub-id-type="doi">10.3389/fncom.2010.00150</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Unveiling the Neuromorphological Space</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Costa</surname><given-names>Luciano Da Fontoura</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="author-notes" rid="fn001">*</xref></contrib><contrib contrib-type="author"><name><surname>Zawadzki</surname><given-names>Krissia</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Miazaki</surname><given-names>Mauro</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Viana</surname><given-names>Matheus P.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Taraskin</surname><given-names>Sergei N.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Institute of Physics at S&#x000e3;o Carlos, University of S&#x000e3;o Paulo</institution><country>S&#x000e3;o Carlos, S&#x000e3;o Paulo, Brazil</country></aff><aff id="aff2"><sup>2</sup><institution>National Institute of Science and Technology of Complex Systems, Niter&#x000f3;i</institution><country>Rio de Janeiro, Brazil</country></aff><aff id="aff3"><sup>3</sup><institution>St. Catharine's College, University of Cambridge</institution><country>Cambridge, UK</country></aff><aff id="aff4"><sup>4</sup><institution>Department of Chemistry, University of Cambridge</institution><country>Cambridge, UK</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Jaap van Pelt, Vrije Universiteit Amsterdam, Netherlands</p></fn><fn fn-type="edited-by"><p>Reviewed by: Jaap van Pelt, Vrije Universiteit Amsterdam, Netherlands; Herbert Jelinek, Charles Sturt University, Australia</p></fn><corresp id="fn001">*Correspondence: Luciano Da Fontoura Costa, Institute of Physics at S&#x000e3;o Carlos, University of S&#x000e3;o Paulo, PO Box 369, S&#x000e3;o Carlos, S&#x000e3;o Paulo 13.560-970, Brazil. e-mail: <email>luciano@ifsc.usp.br</email></corresp></author-notes><pub-date pub-type="epub"><day>02</day><month>12</month><year>2010</year></pub-date><pub-date pub-type="collection"><year>2010</year></pub-date><volume>4</volume><elocation-id>150</elocation-id><history><date date-type="received"><day>13</day><month>8</month><year>2010</year></date><date date-type="accepted"><day>09</day><month>11</month><year>2010</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2010 Costa, Zawadzki, Miazaki, Viana and Taraskin.</copyright-statement><copyright-year>2010</copyright-year><license license-type="open-access" xlink:href="http://www.frontiersin.org/licenseagreement"><license-p>This is an open-access article subject to an exclusive license agreement between the authors and the Frontiers Research Foundation, which permits unrestricted use, distribution, and reproduction in any medium, provided the original authors and source are credited.</license-p></license></permissions><abstract><p>This article proposes the concept of neuromorphological space as the multidimensional space defined by a set of measurements of the morphology of a representative set of almost 6000 biological neurons available from the NeuroMorpho database. For the first time, we analyze such a large database in order to find the general distribution of the geometrical features. We resort to McGhee's biological shape space concept in order to formalize our analysis, allowing for comparison between the geometrically possible tree-like shapes, obtained by using a simple reference model, and real neuronal shapes. Two optimal types of projections, namely, principal component analysis and canonical analysis, are used in order to visualize the originally 20-D neuron distribution into 2-D morphological spaces. These projections allow the most important features to be identified. A data density analysis is also performed in the original 20-D feature space in order to corroborate the clustering structure. Several interesting results are reported, including the fact that real neurons occupy only a small region within the geometrically possible space and that two principal variables are enough to account for about half of the overall data variability. Most of the measurements have been found to be important in representing the morphological variability of the real neurons.</p></abstract><kwd-group><kwd>neuromorphological space</kwd><kwd>NeuroMorpho</kwd><kwd>neural morphology</kwd><kwd>neuroscience</kwd></kwd-group><counts><fig-count count="12"/><table-count count="2"/><equation-count count="9"/><ref-count count="39"/><page-count count="13"/><word-count count="8141"/></counts></article-meta></front><body><sec sec-type="introduction"><label>1</label><title>Introduction</title><p>Despite the continuing scientific and technological advances in neuroscience, the understanding of the nervous system of living organisms still remains largely incipient. Among the several problems which have constrained the advances in this area, one of the most prominent issues regards the relationship between shape and functioning of neuronal cells (Costa et al., <xref ref-type="bibr" rid="B8">2002</xref>; Schierwagen, <xref ref-type="bibr" rid="B31">2008</xref>; Wen and Chklovskii, <xref ref-type="bibr" rid="B38">2008</xref>). Remarkably, the nervous systems of most animals are composed by neuronal cells exhibiting a large variety of shapes. This was first realized through the pioneering work of Cajal (<xref ref-type="bibr" rid="B5">1989</xref>), who went so far as to assign human intelligence to the &#x0201c;unaccustomed&#x0201d; variety of neuronal morphology. Indeed, neuronal cells vary from relatively simple structures such as the bipolar cells of the retina, to the exuberant complexity of Purkinje and some pyramidal cells (Masland, <xref ref-type="bibr" rid="B23">2004</xref>; Bota and Swanson, <xref ref-type="bibr" rid="B4">2007</xref>). The emerging dynamics in neuronal systems is ultimately the consequence of established synaptic connections, which are to a large extent defined by the neuronal branching pattern (Kreindler, <xref ref-type="bibr" rid="B21">1965</xref>; Elston and Rosa, <xref ref-type="bibr" rid="B12">2000</xref>), relative position of the neuronal cells, and the respective history of dynamical response to stimuli presentation. For instance, cells which are very simple and separated from each other tend to make a smaller number of synapses. Therefore, the proper understanding of the connectivity patterns in the nervous system demands the analysis of neuronal morphology. In addition, the dynamical operation of neurons is also intrinsically constrained and even defined by their respective shapes (Koch et al., <xref ref-type="bibr" rid="B20">1982</xref>; Fukuda et al., <xref ref-type="bibr" rid="B13">1984</xref>; Agmon-Snir et al., <xref ref-type="bibr" rid="B1">1998</xref>; Segev, <xref ref-type="bibr" rid="B33">1998</xref>; Jan and Jan, <xref ref-type="bibr" rid="B19">2003</xref>; P&#x000e9;rez-Reche et al., <xref ref-type="bibr" rid="B28">2010</xref>). For all such reasons, it becomes exceedingly important to investigate neuronal morphology in a systematic and comprehensive way.</p><p>Following the works of Ram&#x000f3;n-y-Cajal, the main interest in neuroscience was shifted to electrophysiology, which dominated much of the research in this area for many decades thereon. The relatively few approaches to neuromorphometry developed along this period include the Sholl (<xref ref-type="bibr" rid="B34">1953</xref>) analysis, fractal dimension characterization (Montague and Friedlander, <xref ref-type="bibr" rid="B27">1991</xref>), influence area analysis (Toris et al., <xref ref-type="bibr" rid="B35">1995</xref>), and dendrogram representation (Poznanski, <xref ref-type="bibr" rid="B29">1992</xref>). More recently, the scientific community resumed interest on neuromorphological research. Improvements in high definition visualization (Hosking and Schwartz, <xref ref-type="bibr" rid="B18">2009</xref>), as well as in the methodology used for analysis paved the way for the development of computational neuromorphometry (Costa et al., <xref ref-type="bibr" rid="B8">2002</xref>), a research field aimed at quantifying the shape of these cells. At the same time, the development of new methods and measurements (Costa, <xref ref-type="bibr" rid="B7">2003</xref>; Rodrigues et al., <xref ref-type="bibr" rid="B30">2005</xref>) complemented the characterization and modeling of neuronal systems. Neuromorphological analysis comprises both characterization (Costa and Velte, <xref ref-type="bibr" rid="B10">1999</xref>; Costa et al., <xref ref-type="bibr" rid="B9">2007</xref>) and classification (Bota and Swanson, <xref ref-type="bibr" rid="B4">2007</xref>) of neuronal cells through multivariate techniques, which require choosing appropriate measurements (Costa, <xref ref-type="bibr" rid="B6">1995</xref>) and the application of pattern recognition methods. A particularly relevant approach involves the grouping of neuronal cells into categories according to their morphological similarity. Such an approach is important for understanding the heterogeneity of the groups, as well as for unveiling the relationship between neuronal structure and function, and can be applied to comparative anatomy, developmental neurobiology, and diagnosis.</p><p>One of the most promising recent trends in neuroscience has been the advent of public data repository such as the <italic>NeuroMorpho</italic> Database<xref ref-type="fn" rid="fn1"><sup>1</sup></xref> (Ascoli et al., <xref ref-type="bibr" rid="B2">2007</xref>). Initiated in 2006, this database has grown steadily to become what is the most complete database of neuronal morphology, comprising currently 5673 cells of several types and species. It includes 3-D reconstructions, measurements, softwares, and general information about the cells, such as reference papers, animal species, brain region, neuron class, amongst many others.</p><p>The current work explores the availability of such welcomed public repositories in order to perform a systematic and comprehensive investigation of the morphological characteristics of a large and representative set of neurons. More specifically, we use optimal multivariate statistical approaches in order to investigate the distribution of neuronal geometry as characterized by the several measurements available in the NeuroMorpho database. The multidimensional measurement space where the cells are mapped is henceforth called the neuromorphological space, NS for short.</p><p>In this paper, we address the following important questions: (i) What are the most populated areas in the NS and where are their boundaries? (ii) Out of the set of possible tree-like structures, which are actually found in biological neurons? (iii) Do the cells of the same type, tissue, or species tend to cluster together? (iv) Are there redundancies between the available geometrical features, as quantified by their pairwise correlations? (v) What are the features contributing more decisively for the variability of the cell morphologies and separation of different types of cells?</p><p>Each of the neuronal cells in NeuroMorpho is characterized by 20 available features quantifying different aspects of the respective morphology. In order to allow the visualization of the distribution of the cells in the NS, we resort to two optimal projection methods, namely, principal component analysis (PCA) and canonical analysis. While the former defines the projection axes so as to maximize the variability of the data, the latter performs the projection so as to maximize the separation between the several imposed categories. We also propose a simple reference model of tree-like structures, which is capable of generating the most diverse types of trees. This model is used in order to identify, in the projected spaces, the overall region of almost every possible tree-like structures with unbiased branching. So, we can compare how the biological neurons are distributed within this wide region of geometrically possible shapes. The application of the projection methods also paved the way to identifying the contribution of every considered feature for the variability of the original data as well as for the separation between the groups of cells (type, tissue, or species). We also performed a density analysis in the original 20-D space, in order to complement the clustering structures observed in the projection approach.</p><p>Several relevant results are obtained. The most remarkable finding is that the biological neurons occupy only a rather small portion of the larger space of the unbiased branched structures. The article starts by presenting the several involved basic concepts, methods and models, and follows by presenting and discussing the results.</p></sec><sec sec-type="materials|methods"><label>2</label><title>Materials and Methods</title><p>In this section, we describe the NeuroMorpho database and the characteristics (measurements) of neural cells available from this repository. Then, the concept of morphospace is introduced and the statistical methods of its analysis are briefly described. In particular, a new approach to analysis of the morphospace based on use of radial density function is discussed in detail. Finally, a numerical model for generating diverse branching tree-like structures is developed and used for exploring the morphospace.</p><sec><label>2.1</label><title>The neuromorpho database</title><p>NeuroMorpho (Ascoli et al., <xref ref-type="bibr" rid="B2">2007</xref>) is an on-line public repository of reconstructed neurons, obtained from available WWW databases and direct peer-to-peer requests to individual laboratories and researchers. The purpose of this repository is to facilitate neuronal data access and sharing in the scientific community. New data is only uploaded by administrators, who first standardize the data format. The Computational Neuroanatomy Group (Krasnow Institute for Advanced Study, George Mason University), under the direction of Prof. Giorgio Ascoli, is the developer and maintainer of NeuroMorpho. This repository integrates the Neuroscience Information Framework (NIF) consortium (Halavi et al., <xref ref-type="bibr" rid="B14">2008</xref>), which include several academic institutions, such as Cornell, Stanford, and California Universities. The first version of NeuroMorpho (Alpha) was released on August 01, 2006, with 932 neurons. Since then, it has being continuously updated to include more neurons and to improve the site functionality (Halavi et al., <xref ref-type="bibr" rid="B14">2008</xref>; Figure <xref ref-type="fig" rid="F1">1</xref>). At the present version (4.0), it has 5673 neurons. The available data includes 3-D reconstructions and measurements (volume, diameter, etc.), as well as general information such as the data provider (researcher and laboratory), reference papers and URLs related to the data, experiment setup (protocol, staining method, etc.), animal type (species, age, etc.), brain region and sub-region, neuron class and sub-class, and methods and software used in the reconstruction.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Version releases and evolution of the number of neurons in the NeuroMorpho database: since its release in 2006, data has being continuously added and currently it is the largest database of neuronal morphology, containing 5673 cells</bold>.</p></caption><graphic xlink:href="fncom-04-00150-g001"/></fig><p>Usually, neuronal morphology data acquisition involves the sectioning of the neuron and their serial reconstruction. It is well known that this process can potentially introduce artifacts (Horcholle-Bossavit et al., <xref ref-type="bibr" rid="B17">2000</xref>; Hamam and Kennedy, <xref ref-type="bibr" rid="B15">2003</xref>), such as shrinkage and distortion caused by fixation, dehydration, loss of tissue parts during sectioning, and misalignment of slices during reconstruction. Also, the image segmentation and the connection of the neuronal parts between sections in the reconstruction are challenging tasks (Meijering, <xref ref-type="bibr" rid="B26">2010</xref>). Because each of these artifacts will imply specific, different bias on the estimation of each of the possible neuromorphological measurements, a comprehensive study would need to be carried out at quantifying and characterizing such biases. At any rate, such problems tend to be reduced with the advances in experimental procedures and equipment.</p></sec><sec><label>2.2</label><title>Measurements</title><p>In order to study the morphology of neurons, it is necessary to represent and characterize them in some way suitable for processing and analysis. NeuroMorpho provides the L-Measure (Scorcioni et al., <xref ref-type="bibr" rid="B32">2008</xref>), a tool to extract several measurements from the neurons in the database. The measurements used in this work are illustrated in Figure <xref ref-type="fig" rid="F2">2</xref>, numbered from 1 to 20 and named as in the software documentation.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>NeuroMorpho measurements</bold>.</p></caption><graphic xlink:href="fncom-04-00150-g002"/></fig><p>The concepts of compartment, branch, and bifurcation are illustrated in Figure <xref ref-type="fig" rid="F2">2</xref>. Compartments are segments represented as cylinders with diameter and extremity points coordinates. Branches are formed with one or more compartments between the soma, the bifurcations, and the tips. Bifurcations are points where a branch splits into two other branches. Measurements 1, 2, and 3 are the height, width, and depth of a neuron, calculated after its alignment along the principal axis obtained by PCA. The number of stems, bifurcations, and branches in a neuron correspond to the measurements 4, 5, and 6. The feature 7 is the diameter averaged over all compartments. Features from 8 to 10 are length, surface area, and volume, respectively, which are summed over all compartments.</p><p>The branches have their associated measurements numbered from 11 to 15. Measurement 11 is the maximum Euclidean distance between a compartment and the soma, while the path distance (12) is the maximum of the sums of the lengths of the compartments between two endpoints. Contraction (13) is the average ratio between the Euclidean distance and its path distance. Measure 14 is the maximum branching order with respect to the soma, which has order 0. This measurement corresponds to the topological distance of a branch to the soma. Fragmentation (15) is the total sum of compartments in a branch. Only compartments between bifurcations or between a bifurcation and a tip are considered.</p><p>Measurement 16 is the soma surface area. The soma can be of two types: a sphere or a set of compartments. In the latter case, the area is calculated as the sum of the area surfaces of the soma compartments.</p><p>The other measurements are related to bifurcations. Pk_classic (17) is the average ratio <inline-formula><mml:math id="M1"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>1</mml:mn><mml:mi>r</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mi>r</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mi>r</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>r</italic> is the Rall's power law value, set in this measure as 1.5, and <italic>b</italic>, <italic>d</italic><sub>1</sub>, and <italic>d</italic><sub>2</sub> are the diameters of the bifurcation compartments (the parent and the two daughters, respectively). The partition asymmetry (18) considers the average number of tips on the left and on the right daughter subtrees of a bifurcation as <italic>n</italic>1 and <italic>n</italic>2 in the expression |<italic>n</italic>1 &#x02212;&#x02009;<italic>n</italic>2|/(<italic>n</italic>1 +&#x02009;<italic>n</italic>2 &#x02212;&#x02009;2). In Figure <xref ref-type="fig" rid="F2">2</xref>, the analyzed bifurcation has vertical stripes, while the left daughter subtree has horizontal stripes and the right one has a pattern of squares. Then, in this example, <italic>n</italic>1 =&#x02009;3 and <italic>n</italic>2 =&#x02009;2 gives |3 &#x02212;&#x02009;2|/(3 +&#x02009;2 &#x02212;&#x02009;2) =&#x02009;0.33. Measurement 19 is the angle between two daughter compartments in a bifurcation averaged over all bifurcation points, while measurement 20 is the angle regarding the endpoints of two daughter branches also averaged over all bifurcation points.</p></sec><sec><label>2.3</label><title>Modeling the hyperspace of biological forms</title><p>A theoretical shape-hyperspace, in an analogy with geometrical concepts, can be understood as a <italic>n</italic>-dimensional space, which axes are associated respectively with some measurements. In biology, particularly for morphological analysis, these measurements refer to shape properties, such as length, height, depth, or volume of a living organism or structure. Ideally, the morphospace can be constructed by modeling biological entities through variations of these parameters and considering all possible individuals whose existence is deemed possible. So, although continuous, the morphospace is ultimately reduced as a consequence of several constraints imposed by specific properties of the organisms and their habitat.</p><p>By using the morphospace, it becomes possible to define regions and boundaries corresponding to allowed geometrical, functional, phylogenetically, and developmental properties of the investigated biological entities (McGhee, <xref ref-type="bibr" rid="B24">2006</xref>; see Figure <xref ref-type="fig" rid="F3">3</xref>). An important subset of the shape-hyperspace corresponds to the set of geometrically possible forms (GPF), in the sense that the points outside this region belong to the set of geometrically impossible forms (GIF). There are two exclusive sub-regions within the GPF subspace distinguished by the functionality of the forms, namely, between those that are functionally viable and allow the biological entity to survive (functional possible forms &#x02013; FPF) and those that are not functionally viable (nonfunctional possible forms &#x02013; NPF).</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Generic representation of the several possible regions in a shape-hyperspace</bold>.</p></caption><graphic xlink:href="fncom-04-00150-g003"/></fig><p>These four classifications (GPF, GIF, FPF, and NPF) are based on the extrinsic constraints that are imposed by physical or geometrical laws, in contrast to the intrinsic constraints which refer to the biology of a specific organism. The region defined by the intrinsic properties can be subdivided further into developmental (developmentally possible form &#x02013; DPF) and phylogenetic (phylogenetically possible forms &#x02013; PPF) constraints for a given species, respectively limited by its potential for development and its genetic coding. It is possible to have overlaps between the PPF region and the NPF and GIF spaces. The set defined by the overlaps of these regions comprises the theoretical shape-hyperspace, denoted by morphospace. As an example, a set of cells which are related to genetic diseases must belong to the phylogenetic possible region, but its respective developmental region (DPF) is constrained by the viability of the life of the organism, so that a shorter life implies for that individual to be assigned to the impossible developmental region (DIF).</p><p>In addition, there is an empirical morphospace which is defined as the space of the experimental measurements extracted from real individuals. The investigation of the empirical morphospace can help us to make hypotheses such as what factors along both evolutionary and developmental stages affect the subsequent trajectories inside the morphospace.</p><p>In order to simulate a possible representation of theoretical morphospace, algorithms aimed at producing a set of artificial neurons can be implemented. They are based on statistical models which select some morphological features and vary the corresponding measurements, checking their existence or even fitness. Of course, this method is unable to reproduce accurately the natural processes of life creation and development. At the same time, we should take into account that the adopted set of empirical individuals contains only a fraction of the natural neurons. Nevertheless, both these subsets will provide insights, as well as an estimate for the density and location of the empirical data within the simulated theoretical hyperspace. It is important to note that several models for generation of tree-like neuronal structures have been proposed before, which some of them are based on stochastic sampling of real features (Ascoli and Krichmar, <xref ref-type="bibr" rid="B3">2000</xref>; van Ooyen and van Pelt, <xref ref-type="bibr" rid="B36">2002</xref>; van Pelt and Uylings, <xref ref-type="bibr" rid="B37">2007</xref>), entropy maximization (Wen et al., <xref ref-type="bibr" rid="B39">2009</xref>), and diffusion-limited aggregation process (Luczak, <xref ref-type="bibr" rid="B22">2006</xref>).</p><p>As proposed in this work, the morphological theoretical approach can be applied to neuroscience in order to model the hyperspace of neuronal shapes (neuronal morphospace). Considering a set of measurements extracted from some real set of neuronal cells by using the available measurements in NeuroMorpho database, we can model the empirical morphospace and verify the behavior (boundaries and overlaps) of each of the above defined regions.</p></sec><sec><label>2.4</label><title>Principal component analysis</title><p>Principal component analysis (Duda et al., <xref ref-type="bibr" rid="B11">2001</xref>; H&#x000e4;rdle and Simar, <xref ref-type="bibr" rid="B16">2007</xref>) is a powerful statistical method aiming to reduce the dimension of problems with many measurements. In several applications, PCA promotes the elimination of redundancies, transforming a system described by a set of possibly correlated variables into a new fully uncorrelated system. The technique changes the orientation of the axes in the original space, and then project the measurements space to the subspace characterized by the first principal axes with maximal dispersion.</p><p>The data can be arranged as a <italic>N</italic>&#x02009;&#x000d7;&#x02009;<italic>M</italic> matrix <bold>W</bold>, where each row corresponds to a feature vector <inline-formula><mml:math id="M2"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> associated with one of <italic>N</italic> neuronal cells. Each element of these vectors is related to a particular measure. It is important to note that these measures can be at different scales and a data standardization is therefore required. The next step is to define the covariance matrix <bold>V</bold> as (H&#x000e4;rdle and Simar, <xref ref-type="bibr" rid="B16">2007</xref>):</p><disp-formula id="E1"><label>(1)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><p>where <inline-formula><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mo>&#x003a3;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the mean value of the <italic>i</italic>-th measure. Now, we define the correlation matrix <bold>R</bold> as follows</p><disp-formula id="E2"><label>(2)</label><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula><p>Next, we calculate the eigenvalues &#x003bb; and eigenvectors of <inline-formula><mml:math id="M6"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x003bb;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> <bold>R</bold>. The <italic>M</italic> eigenvalues are sorted in descending order and the first <italic>P</italic> values are chosen (<italic>P</italic>&#x02009;&#x0003c; <italic>M</italic>) for PCA. Linear transformation with the use of the restricted eigenvector basis,</p><disp-formula id="E3"><label>(3)</label><mml:math id="M7"><mml:mrow><mml:msub><mml:msup><mml:mi>W</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><p>reduces the size of original data matrix from <italic>N</italic>&#x02009;&#x000d7; <italic>M</italic> to <italic>N</italic>&#x02009;&#x000d7; <italic>P</italic>. The amount of the variance explained by the <italic>P</italic> chosen eigenvectors can be quantified by the following value:</p><disp-formula id="E4"><label>(4)</label><mml:math id="M8"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula><p>All these characteristics were used for analysis of the organization of neuronal cells in the morphospace.</p></sec><sec><label>2.5</label><title>Canonical variable analysis</title><p>Canonical Variable Analysis (McLachlan, <xref ref-type="bibr" rid="B25">2004</xref>; Costa et al., <xref ref-type="bibr" rid="B9">2007</xref>) is an algebraic method to find the data projection that best separates predefined data classes. This can be achieved through the maximization of the interclass dispersion, i.e., dispersion between classes, while minimizing the intraclass dispersion inside each class. Let us suppose that each element can be classified into a class <italic>C</italic><sub><italic>i</italic></sub> containing <italic>n</italic><sub><italic>i</italic></sub> elements, where <italic>i</italic>&#x02009;=&#x02009;1,2,&#x02026;<italic>N</italic><sub><italic>c</italic></sub> and <italic>N</italic><sub><italic>c</italic></sub> is the maximum number of classes. Using these definitions, we can express the interclass scatter matrix (Equation <xref ref-type="disp-formula" rid="E5">5</xref>) and the intraclass scatter matrix (Equation <xref ref-type="disp-formula" rid="E6">6</xref>) as:</p><disp-formula id="E5"><label>(5)</label><mml:math id="M9"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mtext>inter</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo stretchy="false">&#x0232a;</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mo stretchy="false">&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo stretchy="false">&#x0232a;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(6)</label><mml:math id="M10"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mtext>intra</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><p>where <inline-formula><mml:math id="M11"><mml:mrow><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the mean feature vector of the elements in class <italic>C</italic><sub><italic>i</italic></sub>, <inline-formula><mml:math id="M12"><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x0232a;</mml:mo></mml:mrow></mml:math></inline-formula> is the mean feature vector of all elements, and <italic>S</italic><sub><italic>i</italic></sub> is the dispersion of the measurements inside each class (scatter matrix for each class <italic>C</italic><sub><italic>i</italic></sub>):</p><disp-formula id="E7"><label>(7)</label><mml:math id="M13"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula><p>Then, we can calculate the eigenvalues and eigenvectors of the matrix <inline-formula><mml:math id="M14"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mtext>intra&#x02009;&#x02009;</mml:mtext></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mtext>inter</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="M15"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mtext>intra</mml:mtext></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the inverse of <italic>S</italic><sub>intra</sub>. After that, the eigenvalues must be ordered in descending order. Afterwards, we can pick up the eigenvectors corresponding to the highest eigenvalues to build up the new data projections. For example, if we choose the three eigenvectors corresponding to the three highest eigenvalues, we can reduce the data-space dimensionality to 3, allowing us to visualize the data.</p></sec><sec id="s1"><label>2.6</label><title>Analysis of the hyperspace density</title><p>Although, in the present work, we mainly focus on analysis of the 2-D spaces obtained from the projections of 20-D original spaces, we can also investigate the relationship between the several neuronal cells in the original high-dimensional space using a radial density approach. This will be done by evaluating a radial density function around each neuron in the original space. The radial function <italic>f</italic>(<italic>R</italic>) gives the number of neurons that are located between distance <italic>R</italic> and <italic>R</italic>&#x02009;+&#x02009;&#x00394;<italic>R</italic> from a particular neuron (with &#x00394;<italic>R</italic>&#x02009;=&#x02009;1 used below).</p><p>Each neuron, represented by a vector with components given by the respective morphological measurements, is taken as the centre of a n-dimensional sphere, whose radius is progressively increased, as showed in Figure <xref ref-type="fig" rid="F4">4</xref>A. For each step, the number of neurons inside the shell of the hypersphere is computed, as a function of <italic>R</italic>. Because each of such functions reflects the surrounding distribution of neighbours Figure <xref ref-type="fig" rid="F4">4</xref>B, it is expected that two neurons with similar geometrical features and thus mapped nearby in the feature space, will yield similar radial density functions. In addition, because of the finite size of the space occupied by the neurons in the feature space, it is expected that the radial functions will have a peak at some value of <italic>R</italic>&#x02032;. In particular, neurons near the border of the occupied space will tend to have such a peak displaced to the larger values of <italic>R</italic> (corresponding to outliers), while the more central neurons will produce peaks at smaller values of <italic>R</italic>.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Example of radial density function</bold>. <bold>(A)</bold> Distribution of real neurons in the 2-D feature space. <bold>(B)</bold> Respective radial density function for the central neuron (in red).</p></caption><graphic xlink:href="fncom-04-00150-g004"/></fig></sec><sec id="s2"><label>2.7</label><title>Simple reference model</title><p>In this section, we describe a simple reference model to represent the locus of the possible tree-like shapes. The artificial tree-like structures were constructed in the following way. We start with a single straight branch represented by a vector <inline-formula><mml:math id="M16"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> The end of this vector is a bifurcation point at which two other vectors (branches) <inline-formula><mml:math id="M17"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M18"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula>are added to the structure. All these three vectors are coplanar and bifurcation is symmetric so that vectors <inline-formula><mml:math id="M19"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M20"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> form equal angles with vector <inline-formula><mml:math id="M21"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> The bifurcation angle, &#x003b8; (angle between vectors <inline-formula><mml:math id="M22"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M23"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) is a random variable distributed according to truncated normal distribution in the interval &#x003b8;&#x02009;&#x02208; [0, &#x003c0;],</p><disp-formula id="E8"><label>(8)</label><mml:math id="M24"><mml:mrow><mml:msub><mml:mo>&#x003c1;</mml:mo><mml:mo>&#x003b8;</mml:mo></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b8;</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>&#x003b8;</mml:mo></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x003c0;</mml:mo><mml:msubsup><mml:mo>&#x003c3;</mml:mo><mml:mo>&#x003b8;</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b8;</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mo>&#x003b8;</mml:mo><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mo>&#x003c3;</mml:mo><mml:mo>&#x003b8;</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><p>where <italic>A</italic><sub>&#x003b8;</sub> is the normalization constant <inline-formula><mml:math id="M25"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b8;</mml:mo><mml:mo stretchy="true">&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M26"><mml:mrow><mml:msubsup><mml:mo>&#x003c3;</mml:mo><mml:mo>&#x003b8;</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and are the parameters of the distribution approaching mean value and variance in the case of sufficiently narrow distribution. Once created, the vectors <inline-formula><mml:math id="M27"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M28"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are then simultaneously rotated about vector <inline-formula><mml:math id="M29"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> by random angle &#x003c6;&#x02009;&#x02208; [&#x02212;&#x003c6;<sub>*</sub>, &#x003c6;<sub>*</sub>] distributed according to the truncated normal distribution given by Equation (<xref ref-type="disp-formula" rid="E8">8</xref>) with <italic>theta</italic> replaced everywhere by &#x003c6;. Such a rotation is redundant for the first bifurcation point but becomes significant for the subsequent branching points because it enables appearance of 3-D rather than 2-D structures.</p><p>The ends of the vectors <inline-formula><mml:math id="M30"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M31"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> serve as new bifurcation points. For example, the vectors <inline-formula><mml:math id="M32"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M33"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are added to the end of vector <inline-formula><mml:math id="M34"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> but now with additional constrain such that both vectors <inline-formula><mml:math id="M35"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M36"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are coplanar with <inline-formula><mml:math id="M37"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> vector and original vector <inline-formula><mml:math id="M38"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (this original vector is always coplanar to the new branches added to the structure). The other rules are similar to those described for the first branching point.</p><p>In order to account for existence of not necessarily straight branches between bifurcation points, at each bifurcation point, one of the new branches is allowed to be randomly removed with probability <italic>p</italic><sub><italic>r</italic></sub>. The growth process terminates once the predefined number of branches, <italic>N</italic><sub><italic>b</italic></sub>, both straight and curved, is reached. The lengths of the vectors, <inline-formula><mml:math id="M39"><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02192;</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo>&#x02113;</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> are random discrete variables, &#x02113;&#x02009;=&#x02009;0, 1,&#x02026;, distributed with the following probabilities,</p><disp-formula id="E9"><label>(9)</label><mml:math id="M40"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02113;</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02113;</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo stretchy="true">&#x0220f;</mml:mo><mml:mrow><mml:mo>&#x02113;</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02113;</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x02113;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><p>where <italic>p</italic>(&#x02113;) is the probability for length of the vector to be equal to &#x02113; (&#x02265;1), <italic>p</italic><sub><italic>g</italic></sub>(&#x02113;)is the parameter of the model and has the meaning of probability of further growth for a branch of length &#x02113;. It was assumed that <italic>p</italic><sub><italic>g</italic></sub>(0)&#x02009;=&#x02009;1, <italic>p</italic><sub><italic>g</italic></sub>(&#x02113;)&#x02009;= <italic>p</italic><sub><italic>g</italic></sub> if 0&#x02009;&#x0003c;&#x02009;&#x02113;&#x02009;&#x0003c;&#x02009;&#x02113;<sub>max</sub> and <italic>p</italic><sub><italic>g</italic></sub>(&#x02113;)&#x02009;=&#x02009;0 if &#x02113;&#x02009;&#x02265;&#x02009;&#x02113;<sub>max</sub>, so that the maximum branch length is restricted by parameter &#x02113;<sub>max</sub>.</p><p>By using this procedure, we generated <italic>N</italic>&#x02009;=&#x02009;6000 artificial neurons considering almost all possible values of free parameters according to the real data, i.e., 1&#x02009;&#x02264; <italic>N</italic><sub><italic>b</italic></sub>&#x02009;&#x02264; 8000, 0&#x02009;&#x02264; <italic>p</italic><sub><italic>g</italic></sub>&#x02009;&#x02264; 1, 0&#x02009;&#x02264; <italic>p</italic><sub><italic>r</italic></sub>&#x02009;&#x02264; 1, 0&#x02009;&#x02264; <inline-formula><mml:math id="M41"><mml:mover accent="true"><mml:mo>&#x003b8;</mml:mo><mml:mo>&#x000af;</mml:mo></mml:mover></mml:math></inline-formula>&#x02264;&#x02009;&#x003c0;, &#x003c6;<sub>*</sub>&#x02009;=&#x02009;&#x003c0;, &#x003c6;<sub>*</sub>&#x02009;=&#x02009;0,<inline-formula><mml:math id="M42"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003d5;</mml:mo><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> &#x02113;<sub>max</sub>&#x02009;=&#x02009;100. For the variables &#x003c3;<sub>&#x003b8;</sub> and &#x003c3;<sub>&#x003c6;</sub>, we considered the ranges [0, &#x003c0;/6] and [0, &#x003c0;/9], respectively. All variables were chosen at random, except for <italic>N</italic><sub><italic>b</italic></sub> and <inline-formula><mml:math id="M43"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b8;</mml:mo><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> which were chosen according to the distribution of the real data. It is relevant to note that, because of the generality of our model, we believe it covers the GPF in an almost ideal way. Such a generality of our model is that each of the morphological parameters are covered independently one another in a uniform way. Therefore, provided a large enough number of samples are adopted, the shapes produced by this model can include all cases, even those characterized by interdependence of morphological features. For instance, even if real neurons were characterized by dendritic segments whose length diminished along the branching hierarchy, such a type of neurons would also be generated by our model as a consequence of the independent choice of lengths.</p></sec></sec><sec><label>3</label><title>Results and Discussion</title><p>In this section, we present the main findings regarding the morphological neuronal space and its organization. First, the simple reference model is applied for generation of artificial cells used for obtaining the boundaries of the theoretical space. Next, we show how the real cells are distributed in this space. In this analysis, we consider seven measurements and their projections onto 2-D space by using PCA.</p><p>Next, we analyze the correlations between all the 20 measurements available in the NeuroMorpho database. These measurements are also analyzed using PCA and canonical projections. Finally, we check how the cells are located in the high-dimensional and projected spaces.</p><sec><label>3.1</label><title>Modeling the morphologically possible space</title><p>In order to demonstrate the feasibility of delineating the boundaries for theoretically possible neuronal forms in the morphospace, we used the reference model presented in Section <xref ref-type="sec" rid="s2">2.7.</xref> By using this model, we generated 6000 artificial neurons, which then had the following seven features extracted: width, height, and depth of the neurons, number of bifurcations and branches, branch order, and angle between branches. Considering that artificial and real neurons have different length scales, the first three measurements were used in order to generate another three dimensionless measurements, denoted by: <italic>L</italic><sub>1</sub>&#x02009;= Height/Width, <italic>L</italic><sub>2</sub>&#x02009;= Depth/Width, and <italic>L</italic><sub>3</sub>&#x02009;= Depth/Height. The distributions of these variables for thus created artificial neurons are presented by red curves in Figures <xref ref-type="fig" rid="F5">5</xref>A&#x02013;G. For comparison, corresponding distributions for real neurons are shown in black. It can be seen that they are quite similar in shape and scale. Partly, this was achieved by using experimentally available values for some of the free parameters in the model, such as the mean number of branches (see Figure <xref ref-type="fig" rid="F5">5</xref>E) and mean bifurcation angle (G).</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Distribution of (A)<italic>L</italic><sub>1</sub>, (B) <italic>L</italic><sub>2</sub>, (C) <italic>L</italic><sub>3</sub>, (D)</bold> number of bifurcations, <bold>(E)</bold> number of branches, <bold>(F)</bold> branch orders, and <bold>(G)</bold> bifurcation angle remote. The red lines correspond to the distribution for the artificial neurons generated by using the model described in this paper. The insets are magnifications of the interest peak regions.</p></caption><graphic xlink:href="fncom-04-00150-g005"/></fig><p>The 7-D space was projected onto two dimensions by using PCA. The results are shown in Figure <xref ref-type="fig" rid="F6">6</xref>. As we can see, the proposed model (gray points) successfully spanned the entire real morphospace (black open circles). By analyzing the distribution of the real neurons in the morphospace in Figure <xref ref-type="fig" rid="F6">6</xref>, we can see that the neurons tend to become more 3-D as one moves upwards along the right-hand border of the distribution (i.e., neuron (B) is more 3-D than neuron (A), and so on). A similar effect is observed for artificial neurons shown in Figure <xref ref-type="fig" rid="F7">7</xref>, where one can also identify the dense globular-type structures typical for the region of morphospace not containing any real neurons.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Principal component analysis obtained by considering both real (black open circles) and artificial neurons (grey circles)</bold>. (<bold>A&#x02013;G</bold>) Some real neurons are presented around the plot.</p></caption><graphic xlink:href="fncom-04-00150-g006"/></fig><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Principal component analysis considering both real (black open circles) and artificial neurons (gray circles)</bold>. Some artificial neurons are presented around the plot.</p></caption><graphic xlink:href="fncom-04-00150-g007"/></fig><p>We verified that the first principal variable covers 38.3% of the total variance, while the second adds another 25.4%, which means that 63.7% of the total data variation is accounted for by the first two principal components in the PCA. Table <xref ref-type="table" rid="T1">1</xref> shows the PCA weights given by the respective eigenvector components of the two principal main axes. In the first axis, almost all variables have a significant contribution. On the other hand, in the second axis, the variables <italic>L</italic><sub>3</sub> and <italic>L</italic><sub>2</sub> have a slight dominance while branch order and bifurcation angle remote have little influence.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Principal component analysis weights considering both real and artificial neurons (see projections in Figures <xref ref-type="fig" rid="F6">6</xref> and <xref ref-type="fig" rid="F7">7</xref>): the seven considered measurements and their respective percentage weights in each principal component axis (PC1 and PC2) are presented</bold>. A higher value means that the measurement has a larger contribution to the data variance on the axis.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Measurements</th><th align="left" rowspan="1" colspan="1">PC1</th><th align="left" rowspan="1" colspan="1">PC2</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><italic>L</italic><sub>1</sub></td><td align="left" rowspan="1" colspan="1">0.11</td><td align="left" rowspan="1" colspan="1">0.04</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>L</italic><sub>2</sub></td><td align="left" rowspan="1" colspan="1">0.15</td><td align="left" rowspan="1" colspan="1">0.23</td></tr><tr><td align="left" rowspan="1" colspan="1"><italic>L</italic><sub>3</sub></td><td align="left" rowspan="1" colspan="1">0.11</td><td align="left" rowspan="1" colspan="1">0.25</td></tr><tr><td align="left" rowspan="1" colspan="1">Number bifurcations</td><td align="left" rowspan="1" colspan="1">0.19</td><td align="left" rowspan="1" colspan="1">0.16</td></tr><tr><td align="left" rowspan="1" colspan="1">Number branches</td><td align="left" rowspan="1" colspan="1">0.19</td><td align="left" rowspan="1" colspan="1">0.16</td></tr><tr><td align="left" rowspan="1" colspan="1">Branch order</td><td align="left" rowspan="1" colspan="1">0.14</td><td align="left" rowspan="1" colspan="1">0.08</td></tr><tr><td align="left" rowspan="1" colspan="1">Bifurcation angle remote</td><td align="left" rowspan="1" colspan="1">0.11</td><td align="left" rowspan="1" colspan="1">0.08</td></tr></tbody></table></table-wrap></sec><sec><label>3.2</label><title>Measurements interrelationship and pca analysis</title><p>We now focus on the organization of the DPF space, which contains the real neurons. In order to do so, we used all 20 measurements available in NeuroMorpho database. First, we analyzed the interrelationship between these measurements by calculating the Pearson's correlation coefficient (H&#x000e4;rdle and Simar, <xref ref-type="bibr" rid="B16">2007</xref>) between them. The results are represented in gray scale in Figure <xref ref-type="fig" rid="F8">8</xref>. Particularly high positive values of correlations can be observed between the branch order and the Number of branch and Number of Bifurcation. In principle, provided there is a high number of branching orders, a larger number of branches and bifurcations could be expected. However, this is only true in case most of the orders are well-populated by branches, unlike what would be observed in more linear chains of branchings. Therefore, these two correlations seem to indicate that most of the branching orders are well-populated by branches. Other particularly high correlations can be noticed between the Euclidean distance and the width, height, and depth measurements, which was inherently expected. The three latter measurements are also strongly correlated one another.</p><fig id="F8" position="float"><label>Figure 8</label><caption><p><bold>Pearson's correlation coefficients between pairs of measurements</bold>.</p></caption><graphic xlink:href="fncom-04-00150-g008"/></fig><p>Figure <xref ref-type="fig" rid="F9">9</xref> presents the PCA results for the cells grouped by cell type (A), brain regions (B), and species (C). For the cell type, we selected the 15 largest groups from among the original 39 features. The neurons in these 15 groups correspond to 95% of the total number of cells. As we can observe in Figure <xref ref-type="fig" rid="F9">9</xref>A, only the Uniglomerular Projected Neurons (cyan solid circles) constitute a compact cluster.</p><fig id="F9" position="float"><label>Figure 9</label><caption><p><bold>Principal component analysis visualization of the categories grouped by: (A)</bold> cell type, <bold>(B)</bold> brain region, and <bold>(C)</bold> animal species. There are 39 cell types (only 15 shown here), 15 regions, and 11 species.</p></caption><graphic xlink:href="fncom-04-00150-g009"/></fig><p>Neurogliaform (yellow squares), Calretinin (bright blue star), and Bitufted (green solid circles) exhibit most part of their cells grouped together on the left, while the other categories are not grouped in very-well-defined clusters. The Pyramidal cells (open blue circles), the most numerous group, can be found in many areas of this PCA projection. On the lower right part of the diagram, it is possible to distinguish some cells of the Motoneuron (purple stars) and some Pyramidal cells (blue open circles) forming two separated and scattered subgroups.</p><p>In Figure <xref ref-type="fig" rid="F9">9</xref>B, a larger number of grouped categories can be observed, such as Protocerebrum (blue crosses), Cercal Sensory System (cyan squares), Retina (red upward-pointing triangles), Brainstem (blue squares), Basal Forebrain (green downward-pointing triangles), and Olfactory Bulb (green solid circles). The latter remained well-separated from the others and can be found to correspond to the Uniglomerular cell type. The Cerebral Cortex cells (black plus signs) correspond mainly to the Pyramidal cells and includes some not reported cells. The regions of Spinal Cord (red stars) and Brainstem (Blue squares) are mostly composed by Motoneuron cell type.</p><p>Figure <xref ref-type="fig" rid="F9">9</xref>C, which shows the distinction between cell groups according to the species in which they are found. We can distinguish three well-separated clusters: drosophila (blue right-pointing triangles), human (red diamonds), and cat (blue squares). Cricket (purple left-pointing triangles), salamander (yellow solid circles), and monkey (black plus signs) also have well-defined regions, but they overlap with mouse (green squares) and rat (cyan crosses), which are the two larger categories.</p><p>Figure <xref ref-type="fig" rid="F10">10</xref> shows the variance accounted for by each of the principal axes. This was calculated using the eigenvalues: higher values contribute more. In this plot, the eigenvalues were converted into percentages and presented in a cumulative sequence of bars, highlighting the cumulative contribution of each variable for the data variability. The first two eigenvalues used in the PCA plots explained 46% of the variance.</p><fig id="F10" position="float"><label>Figure 10</label><caption><p><bold>Cumulative explained variance in the PCA, sorted in descending order of their contribution</bold>.</p></caption><graphic xlink:href="fncom-04-00150-g010"/></fig><p>Analyzing Table <xref ref-type="table" rid="T2">2</xref>, it is possible to see that data variance is distributed amongst several measurements. In the first principal variable, Length and Euclidean Distance have the higher contributions, 0.089 and 0.083, respectively. The largest weights in the second principal variable are the Bifurcation Angle Local (0.090) and Bifurcation Angle Remote (0.093).</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Principal component analysis weights regarding the real neurons in NeuroMorpho database (see projections in Figure <xref ref-type="fig" rid="F9">9</xref>): the percentage weights of the 20 measurements in each principal component axis (PC1 and PC2) are shown</bold>. Recall that higher values correspond to measurements which most contribute to the data variance on the axis.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Measurements</th><th align="left" rowspan="1" colspan="1">PC1</th><th align="left" rowspan="1" colspan="1">PC2</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Soma surface</td><td align="left" rowspan="1" colspan="1">0.026</td><td align="left" rowspan="1" colspan="1">0.077</td></tr><tr><td align="left" rowspan="1" colspan="1">Number of stems</td><td align="left" rowspan="1" colspan="1">0.023</td><td align="left" rowspan="1" colspan="1">0.037</td></tr><tr><td align="left" rowspan="1" colspan="1">Number of bifurcations</td><td align="left" rowspan="1" colspan="1">0.066</td><td align="left" rowspan="1" colspan="1">0.047</td></tr><tr><td align="left" rowspan="1" colspan="1">Number of branches</td><td align="left" rowspan="1" colspan="1">0.067</td><td align="left" rowspan="1" colspan="1">0.046</td></tr><tr><td align="left" rowspan="1" colspan="1">Width</td><td align="left" rowspan="1" colspan="1">0.073</td><td align="left" rowspan="1" colspan="1">0.043</td></tr><tr><td align="left" rowspan="1" colspan="1">Height</td><td align="left" rowspan="1" colspan="1">0.074</td><td align="left" rowspan="1" colspan="1">0.029</td></tr><tr><td align="left" rowspan="1" colspan="1">Depth</td><td align="left" rowspan="1" colspan="1">0.066</td><td align="left" rowspan="1" colspan="1">0.051</td></tr><tr><td align="left" rowspan="1" colspan="1">Diameter</td><td align="left" rowspan="1" colspan="1">0.022</td><td align="left" rowspan="1" colspan="1">0.067</td></tr><tr><td align="left" rowspan="1" colspan="1">Length</td><td align="left" rowspan="1" colspan="1">0.089</td><td align="left" rowspan="1" colspan="1">0.026</td></tr><tr><td align="left" rowspan="1" colspan="1">Surface</td><td align="left" rowspan="1" colspan="1">0.060</td><td align="left" rowspan="1" colspan="1">0.062</td></tr><tr><td align="left" rowspan="1" colspan="1">Volume</td><td align="left" rowspan="1" colspan="1">0.024</td><td align="left" rowspan="1" colspan="1">0.043</td></tr><tr><td align="left" rowspan="1" colspan="1">Euclidean distance</td><td align="left" rowspan="1" colspan="1">0.083</td><td align="left" rowspan="1" colspan="1">0.035</td></tr><tr><td align="left" rowspan="1" colspan="1">Path distance</td><td align="left" rowspan="1" colspan="1">0.069</td><td align="left" rowspan="1" colspan="1">0.016</td></tr><tr><td align="left" rowspan="1" colspan="1">Branch order</td><td align="left" rowspan="1" colspan="1">0.070</td><td align="left" rowspan="1" colspan="1">0.061</td></tr><tr><td align="left" rowspan="1" colspan="1">Contraction</td><td align="left" rowspan="1" colspan="1">0.028</td><td align="left" rowspan="1" colspan="1">0.035</td></tr><tr><td align="left" rowspan="1" colspan="1">Fragmentation</td><td align="left" rowspan="1" colspan="1">0.052</td><td align="left" rowspan="1" colspan="1">0.034</td></tr><tr><td align="left" rowspan="1" colspan="1">Partition asymmetry</td><td align="left" rowspan="1" colspan="1">0.035</td><td align="left" rowspan="1" colspan="1">0.058</td></tr><tr><td align="left" rowspan="1" colspan="1">Rall's ratio</td><td align="left" rowspan="1" colspan="1">0.019</td><td align="left" rowspan="1" colspan="1">0.050</td></tr><tr><td align="left" rowspan="1" colspan="1">Bifurcation angle local</td><td align="left" rowspan="1" colspan="1">0.028</td><td align="left" rowspan="1" colspan="1">0.090</td></tr><tr><td align="left" rowspan="1" colspan="1">Bifurcation angle remote</td><td align="left" rowspan="1" colspan="1">0.027</td><td align="left" rowspan="1" colspan="1">0.093</td></tr></tbody></table></table-wrap></sec><sec><label>3.3</label><title>Distribution of categories</title><p>The canonical variable analysis is a suitable method to visualize and investigate the distribution of categories in the NeuroMorpho database. Figure <xref ref-type="fig" rid="F11">11</xref>A shows the results for cell type, Figure <xref ref-type="fig" rid="F11">11</xref>B depicts the results for brain region, and Figure <xref ref-type="fig" rid="F11">11</xref>C gives the results for species classifications. We used the same 15 types of cells as described in the previous section.</p><fig id="F11" position="float"><label>Figure 11</label><caption><p><bold>Canonical variable analysis visualization of the categories, grouped by (A)</bold> cell type, <bold>(B)</bold> brain region, and <bold>(C)</bold> animal species. There are 39 cell types (only 15 shown here), 15 regions, and 11 species.</p></caption><graphic xlink:href="fncom-04-00150-g011"/></fig><p>As could be expected, the canonical analysis revealed a better separation between the considered groups. In Figure <xref ref-type="fig" rid="F11">11</xref>A, the Uniglomerular Projection Neuron class (cyan circles) remained compact in a specific region and some Motoneuron cells (pink asterisk) are found in the left-hand (middle and bottom) of the graph. In both PCA and canonical analysis, the not reported cells (upside down red triangles) overlapped other cell categories, but on the latter analysis one can observe a well-defined dense core. Also similar as in PCA, the Granule (black crosses), Basket (yellow circles), Bitufted (green solid circles), Somatostatin (cyan square), and Stellate cells (upside down black triangles) are clustered in the same region.</p><p>In Figure <xref ref-type="fig" rid="F11">11</xref>B, we can see a good separation of neuronal cells according to their respective brain regions. Cercal Sensory System (cyan squares), Olfactory Bulb (green circles), and Brainstem (blue squares) yielded well-separated groups. Some regions were split into two sub-regions, particularly cells from Olfactory Bulb (green solid circles), Protocerebrum (blue crosses), and Hippocampus (yellow stars). Basal Forebrain (upside down triangles), Retina (red triangles), and Hippocampus (yellow circles) overlap one another within the greater cluster.</p><p>The projection that better allowed the identification of the groups of neuronal cells and their respective regions are given with respect to animal species in Figure <xref ref-type="fig" rid="F11">11</xref>C. It is clear from this figure that cells from the same animal species tended to group together. Again, we observed splitting of groups into two subgroups for both drosophilas (blue right-pointing triangles) and rats (cyan crosses). Mice (green squares) are scattered between principal cluster and other regions.</p></sec><sec><label>3.4</label><title>Radial function</title><p>In order to investigate the data directly in the 20-D feature space, we used the radial functions as defined in Section <xref ref-type="sec" rid="s1">2.6.</xref> Figure <xref ref-type="fig" rid="F12">12</xref> demonstrates the radial density functions for four cell types and the PCA projections with both real and artificial neurons. Some representative types of cells were selected in order to investigate for coherence between the densities in the 20-D space and the respective 2-D projections. Purkinje, stellate, Martinotti cells, and lateral horn neuron were selected for this analysis, appearing highlighted within the region of the morphospace (Figure <xref ref-type="fig" rid="F12">12</xref>E). The radial density functions of the neurons within each of these groups tend to be similar, defining respective clusters in the 20-D space.</p><fig id="F12" position="float"><label>Figure 12</label><caption><p><bold>Radial density functions for (A)</bold> Purkinje cells, <bold>(B)</bold> stellate cells, <bold>(C)</bold> Martinotti cells, and <bold>(D)</bold> lateral horn cells. Note that cells of the same type tend to have similar radial curves, meaning that they are located around the same region in the 20-D multidimensional feature space. This behavior is also observed when the dimension is reduced by using PCA <bold>(E)</bold>, where cells of the same type tend to be close.</p></caption><graphic xlink:href="fncom-04-00150-g012"/></fig><p>It is interesting to observe the presence of outliers curves in Figures <xref ref-type="fig" rid="F12">12</xref>B,C. In the first case, we can easily identify the corresponding outlier point in the 2-D projection space. This is not the case of the outlier curves observed in 12(C), where we cannot identify the correspondent outlier points in the projection space. Moreover, stellate neurons are an exception in sense that all of them are close in 20-D space, but give rise to separated clusters in 2-D.</p></sec></sec><sec><label>4</label><title>Conclusions</title><p>Several connectivity and functional properties of the nervous system are ultimately determined or strongly affected by the morphology of the involved individual cells. Given that thousands of neurons became recently available in the public NeuroMorpho database, it is now possible to investigate general morphological properties of neuronal cells. This was the main purpose of the current article. More specifically, we have analyzed the whole public repository NeuroMorpho, which currently contains 5673 cataloged neurons. We resorted to an extension of McGhee's theoretical framework (morphospace) in order to formalize our approach (McGhee, <xref ref-type="bibr" rid="B24">2006</xref>). Twenty measurements, readily available from NeuroMorpho, were used in order to describe the morphological space in which the neurons are embedded. For the visualization of the morphospace, we applied PCA and canonical analysis over the original 20-D measurement space, yielding the respective 2-D projections. Seven of the original measurements were used in order to compare the real cells with artificial neurons generated by using the reference model proposed in this paper. This allowed us to compare the region of geometrically possible neurons with those neurons which actually appear in nature.</p><p>Our results indicate that there is only one single region in the morphological space defined by a density peak. Also, we observed a large empty region extending away from the real neuron cluster. These regions therefore correspond to the geometrically possible neurons, generated by the reference model, which are not found in nature. The neurons belonging to these regions are characterized by significantly greater number of branches.</p><p>Regarding the measurements provided by the NeuroMorpho database, we found that some of them are strongly correlated. In particular, measurements that involve euclidean measurements, such as depth&#x02009;&#x000d7; length and euclidean distance&#x02009;&#x000d7; path distance have Pearson correlations above 0.75. All of these correlations were eliminated by using the PCA, which was used to decrease the dimensionality of our data. Yet, the two principal axes were found to depend strongly on almost all the 20 considered measurements. Even so, the two principal axes explained almost 50% the total variance in the original measurement space.</p><p>One particularly interesting result is that, with a few exceptions, the neuronal cells tend to cluster together when taken by type, region, and species. This clustering was substantially increased as a result of applying the canonical analysis. We also verified, by using the radial functions, that the clusters in the original 20-D space tended to remain separated in the respective 2-D projections.</p><p>The morphology of neurons provides potentially valuable insights not only for neuronal function, but for species evolution, ecology, and functional differences between brain areas. However, the current database size only allows global studies. Important questions, such as &#x0201c;how neuronal morphology evolved along species&#x0201d; or &#x0201c;have neurons become more or less branched along the phylogenetic scale,&#x0201d; remain intractable. Our findings indicate a trend of morphological similarity among neurons from the same species, such as monkey and humans, and rats and mice, but it is not enough to predict any general behavior. The database growth also could help to answer questions regarding ecology, such as &#x0201c;would the neurons of interrelated species share any morphological traits as implied by co-existence and sharing of habitats.&#x0201d; These topics can be considered in future works as well as the improvement of the proposed model, incorporating a larger number of measures in order to decrease the degree of degeneracy implied by using just a few morphological features.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ack><title>5</title><p>Luciano Da Fontoura Costa is grateful to FAPESP (05/00587-5) and CNPq (301303/06-1 and 573583/2008-0) for sponsorship. Krissia Zawadzki is grateful to FAPESP sponsorship (2010/01994-1). Mauro Miazaki thanks FAPESP (07/50988-1) for financial support. Matheus Viana is grateful to FAPESP sponsorship (07/50882-9).</p></ack><fn-group><fn id="fn1"><p><sup>1</sup><uri xlink:type="simple" xlink:href="http://neuromorpho.org">http://neuromorpho.org</uri></p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agmon-Snir</surname><given-names>H.</given-names></name><name><surname>Carr</surname><given-names>C. E.</given-names></name><name><surname>Rinzel</surname><given-names>J.</given-names></name></person-group> (<year>1998</year>). <article-title>The role of dendrites in auditory coincidence detection</article-title>. <source>Nature</source><volume>393</volume>, <fpage>268</fpage>&#x02013;<lpage>272</lpage><pub-id pub-id-type="doi">10.1038/30505</pub-id><pub-id pub-id-type="pmid">9607764</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ascoli</surname><given-names>G. A.</given-names></name><name><surname>Donohue</surname><given-names>D. E.</given-names></name><name><surname>Halavi</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>NeuroMorpho.Org: a central resource for neuronal morphologies</article-title>. <source>J. Neurosci.</source><volume>27</volume>, <fpage>9247</fpage>&#x02013;<lpage>9251</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2055-07.2007</pub-id><pub-id pub-id-type="pmid">17728438</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ascoli</surname><given-names>G. A.</given-names></name><name><surname>Krichmar</surname><given-names>J. L.</given-names></name></person-group> (<year>2000</year>). <article-title>L-neuron: a modeling tool for the efficient generation and parsimonious description of dendritic morphology</article-title>. <source>Neurocomputing</source><volume>32</volume>, <fpage>1003</fpage><pub-id pub-id-type="doi">10.1016/S0925-2312(00)00272-1</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bota</surname><given-names>M.</given-names></name><name><surname>Swanson</surname><given-names>L. W.</given-names></name></person-group> (<year>2007</year>). <article-title>The neuron classification problem</article-title>. <source>Brain Res. Rev.</source><volume>56</volume>, <fpage>79</fpage>&#x02013;<lpage>88</lpage><pub-id pub-id-type="doi">10.1016/j.brainresrev.2007.05.005</pub-id><pub-id pub-id-type="pmid">17582506</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cajal</surname><given-names>S. R.</given-names></name></person-group> (<year>1989</year>). <article-title>Recollections of My Life</article-title>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>L. d. F.</given-names></name></person-group> (<year>1995</year>). <article-title>Computer vision based morphometric characterization of neural cells</article-title>. <source>Rev. Sci. Instrum.</source><volume>66</volume>, <fpage>3770</fpage>&#x02013;<lpage>3773</lpage><pub-id pub-id-type="doi">10.1063/1.1145435</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>L. d. F.</given-names></name></person-group> (<year>2003</year>). <article-title>Enhanced multiscale skeletons</article-title>. <source>Real-time imaging</source><volume>9</volume>, <fpage>315</fpage>&#x02013;<lpage>319</lpage><pub-id pub-id-type="doi">10.1016/j.rti.2003.08.002</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>L. d. F.</given-names></name><name><surname>Manoel</surname><given-names>E. T. M.</given-names></name><name><surname>Faucereau</surname><given-names>F.</given-names></name><name><surname>Chelly</surname><given-names>J.</given-names></name><name><surname>van Pelt</surname><given-names>J.</given-names></name><name><surname>Ramakers</surname><given-names>G.</given-names></name></person-group> (<year>2002</year>). <article-title>A shape analysis framework for neuromorphometry</article-title>. <source>Netw. Comput. Neural Syst.</source><volume>13</volume>, <fpage>283</fpage>&#x02013;<lpage>310</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/13/3/303</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>L. d. F.</given-names></name><name><surname>Rodrigues</surname><given-names>F. A.</given-names></name><name><surname>Travieso</surname><given-names>G.</given-names></name><name><surname>Villas Boas</surname><given-names>P. R.</given-names></name></person-group> (<year>2007</year>). <article-title>Characterization of complex networks: a survey of measurements</article-title>. <source>Adv. Phys.</source><volume>56</volume>, <fpage>167</fpage>&#x02013;<lpage>242</lpage><pub-id pub-id-type="doi">10.1080/00018730601170527</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>L. d. F.</given-names></name><name><surname>Velte</surname><given-names>T. J.</given-names></name></person-group> (<year>1999</year>). <article-title>Automatic characterization and classification of ganglion cells from salamander retina</article-title>. <source>J. Comp. Neurol.</source><volume>404</volume>, <fpage>33</fpage>&#x02013;<lpage>51</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19990201)404:1&#x0003c;33::AID-CNE3&#x0003e;3.0.CO;2-Y</pub-id><pub-id pub-id-type="pmid">9886023</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duda</surname><given-names>R. O.</given-names></name><name><surname>Hart</surname><given-names>P. E.</given-names></name><name><surname>Stork</surname><given-names>D. G.</given-names></name></person-group> (<year>2001</year>). <article-title>Pattern Classification</article-title>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley-Interscience</publisher-name></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>G. N.</given-names></name><name><surname>Rosa</surname><given-names>M. G. P.</given-names></name></person-group> (<year>2000</year>). <article-title>Pyramidal cells, patches, and cortical columns: a comparative study of infragranular neurons in TEO, TE, and the superior temporal polysensory area of the macaque monkey</article-title>. <source>J. Neurosci.</source><volume>20</volume>, <fpage>RC117</fpage><pub-id pub-id-type="pmid">11125016</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukuda</surname><given-names>Y.</given-names></name><name><surname>Hsiao</surname><given-names>C. F.</given-names></name><name><surname>Watanabe</surname><given-names>M.</given-names></name><name><surname>Ito</surname><given-names>H.</given-names></name></person-group> (<year>1984</year>). <article-title>Morphological correlates of physiologically identified y-, x-, and w-cells in cat retina</article-title>. <source>J. Neurophysiol.</source><volume>52</volume>, <fpage>999</fpage>&#x02013;<lpage>1013</lpage><pub-id pub-id-type="pmid">6520634</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halavi</surname><given-names>M.</given-names></name><name><surname>Polavaram</surname><given-names>S.</given-names></name><name><surname>Donohue</surname><given-names>D. E.</given-names></name><name><surname>Hamilton</surname><given-names>G.</given-names></name><name><surname>Hoyt</surname><given-names>J.</given-names></name><name><surname>Smith</surname><given-names>K. P.</given-names></name><name><surname>Ascoli</surname><given-names>G. A.</given-names></name></person-group> (<year>2008</year>). <article-title>NeuroMorpho.Org implementation of digital neuroscience: dense coverage and integration with the NIF</article-title>. <source>Neuroinformatics</source><volume>6</volume>, <fpage>241</fpage>&#x02013;<lpage>252</lpage><pub-id pub-id-type="doi">10.1007/s12021-008-9030-1</pub-id><pub-id pub-id-type="pmid">18949582</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamam</surname><given-names>B. N.</given-names></name><name><surname>Kennedy</surname><given-names>T. E.</given-names></name></person-group> (<year>2003</year>). <article-title>Visualization of the dendritic arbor of neurons in intact 500 &#x003bc;m thick brain slices</article-title>. <source>J. Neurosci. Methods</source><volume>123</volume>, <fpage>61</fpage>&#x02013;<lpage>67</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(02)00341-2</pub-id><pub-id pub-id-type="pmid">12581850</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>H&#x000e4;rdle</surname><given-names>W. K.</given-names></name><name><surname>Simar</surname><given-names>L.</given-names></name></person-group> (<year>2007</year>). <source>Applied Multivariate Statistical Analysis</source>, <edition>2nd Edn</edition> <publisher-loc>Berlin/Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horcholle-Bossavit</surname><given-names>G.</given-names></name><name><surname>Gogan</surname><given-names>P.</given-names></name><name><surname>Ivanov</surname><given-names>Y.</given-names></name><name><surname>Korogod</surname><given-names>S.</given-names></name><name><surname>Tyc-Dumont</surname><given-names>S.</given-names></name></person-group> (<year>2000</year>). <article-title>The problem of the morphological noise in reconstructed dendritic arborizations</article-title>. <source>J. Neurosci. Methods</source><volume>95</volume>, <fpage>83</fpage>&#x02013;<lpage>93</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(99)00159-4</pub-id><pub-id pub-id-type="pmid">10776818</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hosking</surname><given-names>C. R.</given-names></name><name><surname>Schwartz</surname><given-names>J. L.</given-names></name></person-group> (<year>2009</year>). <article-title>The future's bright: imaging cell biology in the 21st century</article-title>. <source>Trends Cell Biol.</source><volume>9</volume>, <fpage>553</fpage>&#x02013;<lpage>554</lpage><pub-id pub-id-type="doi">10.1016/j.tcb.2009.09.005</pub-id><pub-id pub-id-type="pmid">19833517</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jan</surname><given-names>Y.-N.</given-names></name><name><surname>Jan</surname><given-names>L. Y.</given-names></name></person-group> (<year>2003</year>). <article-title>The control of dendrite development</article-title>. <source>Neuron</source><volume>40</volume>, <fpage>229</fpage>&#x02013;<lpage>242</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00631-7</pub-id><pub-id pub-id-type="pmid">14556706</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>C.</given-names></name><name><surname>Poggio</surname><given-names>T.</given-names></name><name><surname>Torre</surname><given-names>V.</given-names></name></person-group> (<year>1982</year>). <article-title>Retinal ganglion cells: a functional interpretation of dendritic morphology</article-title>. <source>Philos. Trans. R. Soc. Lond., B, Biol. Sci.</source><volume>298</volume>, <fpage>227</fpage>&#x02013;<lpage>264</lpage><pub-id pub-id-type="doi">10.1098/rstb.1982.0084</pub-id><pub-id pub-id-type="pmid">6127730</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kreindler</surname><given-names>A.</given-names></name></person-group> (<year>1965</year>). <article-title>Experimental Epilepsy</article-title>. <source>Progress in Brain Research</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Elsevier Publishing Company</publisher-name></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luczak</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>Spatial embedding of neuronal trees modeled by diffusive growth</article-title>. <source>J. Neurosci. Methods</source><volume>157</volume>, <fpage>132</fpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.03.024</pub-id><pub-id pub-id-type="pmid">16690135</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masland</surname><given-names>R. H.</given-names></name></person-group> (<year>2004</year>). <article-title>Neuronal cell types</article-title>. <source>Curr. Biol.</source><volume>14</volume>, <fpage>497</fpage>&#x02013;<lpage>500</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2004.06.035</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McGhee</surname><given-names>G. R.</given-names></name></person-group> (<year>2006</year>). <article-title>The Geometry of Evolution: Adaptive Landscapes and Theoretical Morphospaces</article-title>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511618369</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McLachlan</surname><given-names>G. J.</given-names></name></person-group> (<year>2004</year>). <source>Discriminant Analysis and Statistical Pattern Recognition</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley-Interscience</publisher-name></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meijering</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>Neuron tracing in perspective</article-title>. <source>Cytometry A</source><volume>77</volume>, <fpage>693</fpage>&#x02013;<lpage>704</lpage><pub-id pub-id-type="doi">10.1002/cyto.a.20895</pub-id><pub-id pub-id-type="pmid">20583273</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montague</surname><given-names>P. R.</given-names></name><name><surname>Friedlander</surname><given-names>M. J.</given-names></name></person-group> (<year>1991</year>). <article-title>Morphogenesis and territorial coverage by isolated mammalian retinal ganglion cells</article-title>. <source>J. Neurosci.</source><volume>11</volume>, <fpage>1440</fpage>&#x02013;<lpage>1457</lpage><pub-id pub-id-type="pmid">2027055</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>P&#x000e9;rez-Reche</surname><given-names>F. J.</given-names></name><name><surname>Taraskin</surname><given-names>S. N.</given-names></name><name><surname>Costa</surname><given-names>L. d. F.</given-names></name><name><surname>Neri</surname><given-names>M. F.</given-names></name><name><surname>Gilligan</surname><given-names>A. C.</given-names></name></person-group> (<year>2010</year>). <article-title>Complexity and anisotropy in host morphology make populations less susceptible to epidemic outbreaks</article-title>. <source>J. R. Soc. Interface</source><volume>7</volume>, <fpage>1083</fpage><pub-id pub-id-type="doi">10.1098/rsif.2009.0475</pub-id><pub-id pub-id-type="pmid">20075039</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poznanski</surname><given-names>R. R.</given-names></name></person-group> (<year>1992</year>). <article-title>Modelling the electronic structure of starburst amacrine cells in the rabbit retina: functional interpretation of dendritic morphology</article-title>. <source>Bull. Math. Biol.</source><volume>54</volume>, <fpage>905</fpage>&#x02013;<lpage>928</lpage><pub-id pub-id-type="pmid">1515871</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodrigues</surname><given-names>E. P.</given-names></name><name><surname>Barbosa</surname><given-names>M. S.</given-names></name><name><surname>Costa</surname><given-names>L. d. F.</given-names></name></person-group> (<year>2005</year>). <article-title>Self-referred approach to lacunarity</article-title>. <source>Phys. Rev. E</source><volume>72</volume>, <fpage>016707</fpage><pub-id pub-id-type="doi">10.1103/PhysRevE.72.016707</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schierwagen</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Neuronal morphology: shape characteristics and model</article-title>. <source>Neurophysiology</source><volume>40</volume>, <fpage>310</fpage>&#x02013;<lpage>315</lpage><pub-id pub-id-type="doi">10.1007/s11062-009-9054-7</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scorcioni</surname><given-names>R.</given-names></name><name><surname>Polavaram</surname><given-names>S.</given-names></name><name><surname>Ascoli</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>L-measure: a web-accessible tool for the analysis, comparison and search of digital reconstructions of neuronal morphologies</article-title>. <source>Nat. Protoc.</source><volume>3</volume>, <fpage>866</fpage>&#x02013;<lpage>876</lpage><pub-id pub-id-type="doi">10.1038/nprot.2008.51</pub-id><pub-id pub-id-type="pmid">18451794</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segev</surname><given-names>I.</given-names></name></person-group> (<year>1998</year>). <article-title>Sound grounds for computing dendrites</article-title>. <source>Nature</source><volume>393</volume>, <fpage>207</fpage>&#x02013;<lpage>208</lpage><pub-id pub-id-type="doi">10.1038/30340</pub-id><pub-id pub-id-type="pmid">9607753</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sholl</surname><given-names>D. A.</given-names></name></person-group> (<year>1953</year>). <article-title>Dendritic organization in the neurons of the visual and motor cortices of the cat</article-title>. <source>J. Anat.</source><volume>87</volume>, <fpage>387</fpage>&#x02013;<lpage>406</lpage><pub-id pub-id-type="pmid">13117757</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toris</surname><given-names>C. B.</given-names></name><name><surname>Eiesland</surname><given-names>J. L.</given-names></name><name><surname>Miller</surname><given-names>R. F.</given-names></name></person-group> (<year>1995</year>). <article-title>Morphology of ganglion cells in the neotenous tiger salamander retina</article-title>. <source>J. of Comp. Neurol.</source><volume>352</volume>, <fpage>535</fpage>&#x02013;<lpage>559</lpage><pub-id pub-id-type="doi">10.1002/cne.903520405</pub-id><pub-id pub-id-type="pmid">7721999</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>van Ooyen</surname><given-names>A.</given-names></name><name><surname>van Pelt</surname><given-names>J.</given-names></name></person-group> (<year>2002</year>). <source>Computational Neuroanatomy: Principles and Methods</source>. <publisher-loc>Totowa, NJ</publisher-loc>: <publisher-name>Humana Press</publisher-name></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>van Pelt</surname><given-names>J.</given-names></name><name><surname>Uylings</surname><given-names>H. B. M.</given-names></name></person-group> (<year>2007</year>). <article-title>&#x0201c;Modeling neuronal growth and shape,&#x0201d;</article-title> in <source>Modeling Biology &#x02013; Structures, Behaviors, Evolution</source>, eds <person-group person-group-type="editor"><name><surname>Laubichler</surname><given-names>M. D.</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>G. B.</given-names></name></person-group> (<publisher-name>The MIT Press</publisher-name>, <publisher-loc>Cambridge, Massachusetts</publisher-loc>), <fpage>195</fpage>&#x02013;<lpage>215</lpage></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>Q.</given-names></name><name><surname>Chklovskii</surname><given-names>D. B.</given-names></name></person-group> (<year>2008</year>). <article-title>A cost-benefit analysis of neuronal morphology</article-title>. <source>J. Neurophysiol.</source><volume>99</volume>, <fpage>497</fpage>&#x02013;<lpage>500</lpage><pub-id pub-id-type="doi">10.1152/jn.00280.2007</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>Q.</given-names></name><name><surname>Stepanyants</surname><given-names>A.</given-names></name><name><surname>Elston</surname><given-names>G. N.</given-names></name><name><surname>Grosberg</surname><given-names>A. Y.</given-names></name><name><surname>Chklovskii</surname><given-names>D. B.</given-names></name></person-group> (<year>2009</year>). <article-title>Maximization of the connectivity repertoire as a statistical principle governing the shapes of dendritic arbors</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>106</volume>, <fpage>12536</fpage><pub-id pub-id-type="doi">10.1073/pnas.0901530106</pub-id><pub-id pub-id-type="pmid">19622738</pub-id></mixed-citation></ref></ref-list></back></article>
