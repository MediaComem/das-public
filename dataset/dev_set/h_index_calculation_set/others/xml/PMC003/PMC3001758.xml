<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Hum Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Hum. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Human Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1662-5161</issn><publisher><publisher-name>Frontiers Research Foundation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">21160551</article-id><article-id pub-id-type="pmc">PMC3001758</article-id><article-id pub-id-type="doi">10.3389/fnhum.2010.00215</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>Attention, Uncertainty, and Free-Energy</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Feldman</surname><given-names>Harriet</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Friston</surname><given-names>Karl J.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001">*</xref></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>The Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London</institution><country>London, UK</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Sven Bestmann, University College London, UK</p></fn><fn fn-type="edited-by"><p>Reviewed by: William Milberg, Harvard Medical School, USA; Tamer Demiralp, Istanbul University, Turkey; Laurence T. Maloney, New York University, USA</p></fn><corresp id="fn001">*Correspondence: Karl J. Friston, Wellcome Trust Centre for Neuroimaging, Institute of Neurology, Queen Square, London WC1N 3BG, UK. e-mail: <email>k.friston@fil.ion.ucl.ac.uk</email></corresp></author-notes><pub-date pub-type="epreprint"><day>24</day><month>9</month><year>2010</year></pub-date><pub-date pub-type="epub"><day>02</day><month>12</month><year>2010</year></pub-date><pub-date pub-type="collection"><year>2010</year></pub-date><volume>4</volume><elocation-id>215</elocation-id><history><date date-type="received"><day>04</day><month>8</month><year>2010</year></date><date date-type="accepted"><day>18</day><month>10</month><year>2010</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2010 Feldman and Friston.</copyright-statement><copyright-year>2010</copyright-year><license license-type="open-access" xlink:href="http://www.frontiersin.org/licenseagreement"><license-p>This is an open-access article subject to an exclusive license agreement between the authors and the Frontiers Research Foundation, which permits unrestricted use, distribution, and reproduction in any medium, provided the original authors and source are credited.</license-p></license></permissions><abstract><p>We suggested recently that attention can be understood as inferring the level of uncertainty or precision during hierarchical perception. In this paper, we try to substantiate this claim using neuronal simulations of directed spatial attention and biased competition. These simulations assume that neuronal activity encodes a probabilistic representation of the world that optimizes free-energy in a Bayesian fashion. Because free-energy bounds surprise or the (negative) log-evidence for internal models of the world, this optimization can be regarded as evidence accumulation or (generalized) predictive coding. Crucially, both predictions about the state of the world generating sensory data and the precision of those data have to be optimized. Here, we show that if the precision depends on the states, one can explain many aspects of attention. We illustrate this in the context of the Posner paradigm, using the simulations to generate both psychophysical and electrophysiological responses. These simulated responses are consistent with attentional bias or gating, competition for attentional resources, attentional capture and associated speed-accuracy trade-offs. Furthermore, if we present both attended and non-attended stimuli simultaneously, biased competition for neuronal representation emerges as a principled and straightforward property of Bayes-optimal perception.</p></abstract><kwd-group><kwd>attention</kwd><kwd>biased competition</kwd><kwd>precision</kwd><kwd>free-energy</kwd><kwd>perception</kwd><kwd>generative models</kwd><kwd>predictive coding</kwd></kwd-group><counts><fig-count count="8"/><table-count count="0"/><equation-count count="27"/><ref-count count="148"/><page-count count="23"/><word-count count="18281"/></counts></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>Attention is a ubiquitous and important construct in cognitive neuroscience. Many accounts of attention fall back on Jamesian formulations, famously articulated as &#x0201c;the taking possession by the mind, in clear and vivid form, of one out of what seem several simultaneously possible objects or trains of thought&#x0201d; (James, <xref ref-type="bibr" rid="B71">1890</xref>). More recent and formal accounts appeal to information theory and computational principles (Duncan and Humphreys, <xref ref-type="bibr" rid="B39">1989</xref>; Deco and Rolls, <xref ref-type="bibr" rid="B32">2005</xref>; Jaramillo and Pearlmutter, <xref ref-type="bibr" rid="B72">2007</xref>; Spratling, <xref ref-type="bibr" rid="B121">2008</xref>; Bruce and Tsotsos, <xref ref-type="bibr" rid="B15">2009</xref>; Reynolds and Heeger, <xref ref-type="bibr" rid="B110">2009</xref>; Spratling, <xref ref-type="bibr" rid="B122">2010</xref>), with an increasing emphasis on Bayesian formulations (Rao, <xref ref-type="bibr" rid="B106">2005</xref>; Chikkerur et al., <xref ref-type="bibr" rid="B23">2010</xref>; Itti and Baldi, <xref ref-type="bibr" rid="B69">2009</xref>). We pursue these attempts to understand attention in computational terms. This means we will be using terms like uncertainty, surprise and precision in a rather formal way. Without exception, these terms refer to properties of probability distributions. Probability distributions are central to modern treatments of perception that cast perception as inference. Inference requires us to represent probability distributions (or densities) over possible causes or explanations for our sensations. These distributions have several important attributes: for example, a broad distribution encodes a high degree of <italic>uncertainty</italic> about a particular cause. This uncertainty is, mathematically, the average (expected) <italic>surprise</italic> over all possibilities. A key measure of uncertainty is the width or variance of the distribution, or its inverse, <italic>precision</italic>. (see <xref ref-type="other" rid="G1">Glossary of Terms</xref>). In what follows, we hope to show that attention is more concerned with optimizing the uncertainty or precision of probabilistic representations, rather than what is being represented. By describing perception in formal terms, one can see almost intuitively where attention fits into the larger picture and how it might be mediated neurobiologically. This is important because a formal framework allows one to link classical psychological constructs to current physiological perspectives on attention (e.g., communication through coherence; Fries, <xref ref-type="bibr" rid="B46">2005</xref>). We hope to show that the perspectives afforded by cognitive psychology, neurophysiology and formal (theoretical) treatments are all remarkably consistent.</p><p>We have suggested recently that perception is the inference about causes of sensory inputs and attention is the inference about the uncertainty (precision) of those causes (Friston, <xref ref-type="bibr" rid="B49">2009</xref>). This places attention in the larger context of perceptual inference under uncertainty (Rao, <xref ref-type="bibr" rid="B106">2005</xref>; Spratling, <xref ref-type="bibr" rid="B121">2008</xref>; Whiteley and Sahani, <xref ref-type="bibr" rid="B138">2008</xref>; Chikkerur et al., <xref ref-type="bibr" rid="B23">2010</xref>). In this work, we try to show that attention emerges naturally in a Bayes-optimal scheme used previously to address predictive coding (Friston and Kiebel, <xref ref-type="bibr" rid="B50">2009</xref>), perceptual categorization (Kiebel et al., <xref ref-type="bibr" rid="B76">2009</xref>), learning (Friston, <xref ref-type="bibr" rid="B48">2008</xref>) and action (Friston et al., <xref ref-type="bibr" rid="B51">2010a</xref>). In other words, we try to explain some simple attentional phenomena using an established framework that has explanatory power in domains beyond attention. Specifically, we show how attention can be construed as inferring the precision of sensory signals and their causes. The idea is illustrated using computational simulations of neuronal processing that try to establish face validity in terms of psychophysical and electrophysiological responses. We do this in the context of the Posner paradigm (Posner, <xref ref-type="bibr" rid="B101">1980</xref>); a classical paradigm for studying directed spatial attention in vision, using cued targets. This paradigm also allows us to address, in a heuristic way, biased competition (Desimone, <xref ref-type="bibr" rid="B33">1996</xref>) by presenting validly and invalidly cued targets simultaneously. Our hope was to connect psychophysical studies of attention with theories based upon detailed electrophysiological studies in monkeys.</p><p>The basic idea we pursue is that attention entails estimating uncertainty during hierarchical inference about the causes of sensory input. We develop this idea in the context of perception based on Bayesian principles, under the free-energy principle (Friston, <xref ref-type="bibr" rid="B49">2009</xref>). Formally, this scheme can be regarded as a generalization of predictive coding (Rao and Ballard, <xref ref-type="bibr" rid="B107">1998</xref>) and involves recurrent message passing among hierarchical levels of cortical systems to optimize a probabilistic representation of the world (Mumford, <xref ref-type="bibr" rid="B92">1992</xref>; Friston, <xref ref-type="bibr" rid="B49">2009</xref>). In these generalized schemes, precision is encoded by the synaptic gain (post-synaptic responsiveness) of units reporting prediction errors (Friston, <xref ref-type="bibr" rid="B48">2008</xref>). There are many metaphors for attention that relate closely to the idea we are trying to describe. Perhaps the simplest is that of statistical inference, which treats perception as hypothesis testing (Gregory, <xref ref-type="bibr" rid="B58">1980</xref>): indeed, most modern theories of perception draw on Helmholtz's ideas about the brain as an inference machine (e.g., Gregory, <xref ref-type="bibr" rid="B57">1968</xref>; Ballard et al., <xref ref-type="bibr" rid="B5">1983</xref>; Dayan et al., <xref ref-type="bibr" rid="B30">1995</xref>). These theories regard the brain as inferring how sensory data are generated using generative models (cf, hypotheses) in exactly the same way that we analyze scientific data. The simplest example of this is the Student's <italic>t</italic>-statistic, where a difference in group means is divided by its standard error to test for group differences. Under the null hypothesis, the observed difference is the <italic>prediction error</italic> and the standard error is an estimate of its <italic>precision</italic> (inverse variance). This means that one can regard the <italic>t</italic>-statistic as a precision-weighted prediction error. Crucially, both the prediction error and its precision have to be estimated, given empirical (sensory) data. The idea here is that attention rests on estimating precision and is therefore an integral part of perception. Things get more interesting if we consider that the precision of sensory signals depend on states of the world. This means that optimizing precision entails optimizing inferred states of the world that affect the precision or uncertainty about our sensations. It is this generalization of generative models we exploit in this paper. In brief, most generative models (including those used to simulate perception) ignore state-dependent noise or error variance; assuming that it is constant for any (sensory) data channel. In what follows, we relax this assumption and consider generative models in which the states of the world (for example the presence of attentional cues) can change the precision of sensory data. A simple example of this would be the direction (state) in which we pointed a searchlight. This determines which part of the sensorium contains precise information; namely visual information reflected by surfaces that are illuminated. Any coupling between the state of the world (content) and the precision of sensory samples (context) should be an inherent part of veridical generative models of sensory input. Under this perspective, searchlight (spotlight) metaphors for attention become a natural way to think about its functional role (Shulman et al., <xref ref-type="bibr" rid="B118">1979</xref>; Crick, <xref ref-type="bibr" rid="B26">1984</xref>; Cave and Bichot, <xref ref-type="bibr" rid="B19">1999</xref>; Eckstein et al., <xref ref-type="bibr" rid="B40">2002</xref>). Mechanistically, this role is to weight or bias selected sensory channels (Desimone and Duncan, <xref ref-type="bibr" rid="B35">1995</xref>; Maunsell and Treue, <xref ref-type="bibr" rid="B86">2006</xref>; Reynolds and Heeger, <xref ref-type="bibr" rid="B110">2009</xref>; Stokes et al., <xref ref-type="bibr" rid="B124">2009</xref>). In statistical terms, this is formally identical to weighted least squares that underlies all optimal (maximum <italic>a posteriori</italic>) estimates of model parameters. Put simply, this involves weighting data in proportion to their estimated precision.</p><p>In predictive coding schemes, sensory data are replaced by prediction error, because this is the only sensory information that has yet to be explained. Here, the weighting is implemented by synaptic gain. We therefore return to the central role of precision-weighted prediction errors in optimal inference. Neurobiologically, this is easy to relate to theories of attentional gain, where the post-synaptic responsiveness of sensory (prediction error) units is modulated by attentional mechanisms (Desimone, <xref ref-type="bibr" rid="B33">1996</xref>; Maunsell and Treue, <xref ref-type="bibr" rid="B86">2006</xref>). We will focus on two neurobiological candidates for modulating synaptic gain that have been linked to attention: synchronous gain (Chawla et al., <xref ref-type="bibr" rid="B20">1999a</xref>) mediated by fast oscillatory or synchronized activity (Womelsdorf and Fries, <xref ref-type="bibr" rid="B141">2006</xref>; Fries et al., <xref ref-type="bibr" rid="B47">2008</xref>) and classical neuromodulatory (e.g., cholinergic) neurotransmission (Schroeder et al., <xref ref-type="bibr" rid="B116">2001</xref>; Hirayama et al., <xref ref-type="bibr" rid="B66">2004</xref>).</p><p>Electrophysiologically, desynchronization with increased gamma activity (between 30 and 100 Hz) is seen during attentional tasks in invasive (Steinmetz et al., <xref ref-type="bibr" rid="B123">2000</xref>; Bichot et al., <xref ref-type="bibr" rid="B9">2005</xref>; Fries et al., <xref ref-type="bibr" rid="B47">2008</xref>), and non-invasive EEG and MEG studies (Gruber et al., <xref ref-type="bibr" rid="B60">1999</xref>; Sokolov et al., <xref ref-type="bibr" rid="B120">1999</xref>; Pavlova et al., <xref ref-type="bibr" rid="B97">2006</xref>; Vidal et al., <xref ref-type="bibr" rid="B133">2006</xref>). Gamma oscillations induced with subliminal flicker may improve attention-based performance (Bauer et al., <xref ref-type="bibr" rid="B7">2009</xref>). Furthermore, increased gamma is associated with faster reaction times (Womelsdorf et al., <xref ref-type="bibr" rid="B142">2006</xref>; Fr&#x000fc;nd et al., <xref ref-type="bibr" rid="B53">2007</xref>). Gamma oscillations can control gain by affording synchronized neuronal discharges a greater influence on the firing rate of downstream neurons (Chawla et al., <xref ref-type="bibr" rid="B20">1999a</xref>; Salinas and Sejnowski, <xref ref-type="bibr" rid="B114">2001</xref>; Zeitler et al., <xref ref-type="bibr" rid="B147">2008</xref>). Gamma activity has also been proposed as a solution to the &#x0201c;binding problem,&#x0201d; which we discuss below in relation to attention (Treisman and Schmidt, <xref ref-type="bibr" rid="B129">1982</xref>).</p><p>In terms of neurotransmitters, gamma oscillations are profoundly affected by acetylcholine, which is released into sensory cortex from nuclei in the basal forebrain. It acts through both fast ion channel (nicotinic) receptors and slow metabotropic (muscarinic) receptors (Wonnacott, <xref ref-type="bibr" rid="B143">1997</xref>; Zilles et al., <xref ref-type="bibr" rid="B148">2004</xref>; Hasselmo and Giocomo, <xref ref-type="bibr" rid="B61">2006</xref>). Disruption of the cholinergic system by drugs or lesions can interfere with attentional processes, including the Posner paradigm (Voytko et al., <xref ref-type="bibr" rid="B136">1994</xref>; Witte et al., <xref ref-type="bibr" rid="B139">1997</xref>; Dalley et al., <xref ref-type="bibr" rid="B27">2001</xref>; Herrero et al., <xref ref-type="bibr" rid="B63">2008</xref>; Vossel et al., <xref ref-type="bibr" rid="B135">2008</xref>). Acetylcholine appears to increase synaptic gain directly by, for example, reducing spike-frequency adaptation (McCormick and Prince, <xref ref-type="bibr" rid="B88">1985</xref>, <xref ref-type="bibr" rid="B89">1986</xref>). It may also facilitate the induction of gamma oscillations by reducing adaptation in pyramidal cells (Buhl et al., <xref ref-type="bibr" rid="B16">1998</xref>; B&#x000f6;rgers et al., <xref ref-type="bibr" rid="B10">2005</xref>), decreasing activity of inhibitory interneurons (Buia and Tiesinga, <xref ref-type="bibr" rid="B17">2006</xref>) or directly inactivating specific interneurons (Xiang et al., <xref ref-type="bibr" rid="B144">1998</xref>). However, the time course of acetylcholine release can be quite protracted (Parikh et al., <xref ref-type="bibr" rid="B96">2007</xref>). This suggests rapid (10&#x02013;100&#x02009;ms) attentional mechanisms may rest on an interaction of cholinergic mechanisms with fast activity-dependent modulation of synaptic gain. It is this activity (state) dependent optimization we pursue in this paper.</p><p>In summary, it may be the case that attention is the process of optimizing synaptic gain to represent the precision of sensory information (prediction error) during hierarchical inference. Furthermore, if we allow for state-dependent changes in precision, the neurobiology of attention must involve activity-dependent changes in synaptic gain; assuming that neuronal activity represents the states of the world and synaptic gain represents precision. Given this sort of architecture we can, in principle, simulate attentional processing with established (Bayes-optimal) inversion or recognition schemes, using models with state-dependent noise. What follows is an attempt to do this.</p><p>This paper comprises four sections. In the remainder of Section we provide a brief review of attention in psychological and neurobiological terms. This section focuses on directed spatial attention and, in particular, the Posner (cueing) paradigm that emphasizes the importance of valid cues in establishing attentional set during target detection (Posner, <xref ref-type="bibr" rid="B101">1980</xref>). To complement this psychophysical perspective, we consider biased competition models that are based on careful electrophysiological studies of evoked visual responses using intracranial recordings (Desimone, <xref ref-type="bibr" rid="B33">1996</xref>). Biased competition is probably the most established and influential theory that accounts for unit responses in attentional paradigms framed at the level of receptive fields. We also review the concepts of attentional resources and other constructs associated with early and late attentional selection and the feature-integration theory of attention. In Section <xref ref-type="sec" rid="s2">&#x0201c;Methods,&#x0201d;</xref> we provide a more technical treatment of perception under the free-energy principle and consider the form of generative models that will be used in later sections. The emphasis here is on generalizing previous models to include state-dependent noise and what this means for their neurobiological optimization or inversion. The resulting inversion scheme corresponds to recognizing the causes of sensory data (that include both states of the world and their precision). We will see that precision is encoded by the synaptic gain of sensory or prediction error-units, which pass messages to units representing conditional expectations about the world. In this scheme, optimization of synaptic gain may correspond to attention. In Section <xref ref-type="sec" rid="s3">&#x0201c;Results,&#x0201d;</xref> we present simulations of the Posner paradigm using the recognition scheme of the previous section. This allows us to demonstrate some basic characteristics of attention-based inference; including attentional bias, attentional capture and the cue-validity effect. We supplement a direct interpretation of the probabilistic representations encoded by simulated neuronal activity with simulated psychophysical and electrophysiological data. These simulated responses make some clear predictions about speed-accuracy trade-offs and event-related electrophysiological responses, which we compare against the literature. In the final section, we use the same simulations but present both valid and invalidly cued targets together. This is a rough metaphor for paradigms used to study biased competition and allows us to see if biased competition emerges from the free-energy formulation. We examine this by looking at competition between cues via the effect of an attended cue on the responses evoked by an unattended cue. We conclude with a brief discussion and indicate how the scheme in this paper could be applied to empirical psychophysical and electroencephalographic observations. This is a rather long paper that tries to link a vast literature on the cognitive psychology of attention with a large body of theoretical work on perceptual inference, learning and action. Many readers, who are familiar with one or other of these areas, could easily skip the background material in this section or the next.</p><sec id="s1"><title>Attention, biased competition and the posner paradigm</title><p>In this section, we review some of the key paradigms and theories that have dominated attention research over the past decades. This review can be regarded as a primer for readers who do not have a cognitive neuroscience background (and should be omitted by readers who do). Our focus will be the Posner paradigm, which we simulate in later sections, and biased competition, which is one of the most prevalent electrophysiologically grounded theories of attention. We will also cover some key distinctions, such as the difference between early and late selection and exogenous versus endogenous cueing.</p><p>Early cognitive models of attention, although inherently limited by lack of knowledge about the underlying neural processes, elucidated the important difference between early and late selection. Broadbent (<xref ref-type="bibr" rid="B13">1958</xref>), working in the auditory domain, suggested that attention operated by selecting stimuli at an early stage of processing, when only basic physical attributes had been encoded. The selected stimulus was then processed by an &#x0201c;identification system,&#x0201d; which could handle only one stimulus at a time; to explain why semantic information about unattended stimuli is unavailable to recall (Broadbent, <xref ref-type="bibr" rid="B11">1952a</xref>,<xref ref-type="bibr" rid="B12">b</xref>). However, there are stimuli which violate this principle: Moray (<xref ref-type="bibr" rid="B91">1959</xref>) demonstrated that a subject's name, which is salient only after semantic processing, could shift attention to a previously unattended auditory stream. The competing theory, that all stimuli are processed semantically before selection for consciousness recall, was posited by Deutsch and Deutsch (<xref ref-type="bibr" rid="B37">1963</xref>), whereas Treisman (<xref ref-type="bibr" rid="B126">1964</xref>) suggested that unattended stimuli are attenuated so that attention can be diverted to them, if they become behaviorally salient. Lavie (<xref ref-type="bibr" rid="B80">1995</xref>) attempted to reconcile these models by demonstrating that perceptual load plays an important role in attentional selection: intuitively, early selection occurs with higher attentional load and late selection with lower load. This differential selection rests on the notion of limited capacity. Many of these ideas can be understood in the framework of biased competition theory, which tries to explain some of the phenomena described above using neurobiological mechanisms.</p><sec><title>Biased competition</title><p>Biased competition (Desimone and Duncan, <xref ref-type="bibr" rid="B35">1995</xref>) is a model of attention based on electrophysiological studies and earlier behavioral models. Its main contribution was to make the notion of limited capacity or resources more concrete, by suggesting small lower level receptive fields (RFs) compete to drive larger RFs at higher hierarchical levels. Biased competition says that attention is an emergent property of competition between stimuli for attentional resources, which is influenced by the properties of the stimuli and task requirements. Its premise is that, in a crowded visual field, objects must compete for neural representation at some point along the visual processing stream. This can be deduced from the large size of classical RFs in higher visual areas, such as monkey area TE, which can cover up to 25&#x000b0; of visual angle (Gross et al., <xref ref-type="bibr" rid="B59">1972</xref>; Desimone and Gross, <xref ref-type="bibr" rid="B36">1979</xref>). Clearly, many objects can fall into such a visual field but the neuron can only represent (report) one thing with its firing. If an object is represented by these higher-order visual neurons, they are unavailable to represent other objects. Thus the object has consumed some finite &#x0201c;attentional resource.&#x0201d;</p><p>This premise leads to a key prediction: if two stimuli are presented within a cell's receptive field, the response to both will be smaller than the sum of the response to the stimuli presented separately (Reynolds et al., <xref ref-type="bibr" rid="B109">1999</xref>). Single-cell electrophysiological studies have confirmed that stimuli interact in this mutually suppressive manner in areas V2 and V4 (Reynolds et al., <xref ref-type="bibr" rid="B109">1999</xref>), IT (Rolls and Tovee, <xref ref-type="bibr" rid="B113">1995</xref>) and MT (Recanzone et al., <xref ref-type="bibr" rid="B108">1997</xref>), but not V1, where RFs are so small it is difficult to present competing stimuli (Moran and Desimone, <xref ref-type="bibr" rid="B90">1985</xref>). The average responses of visual cortical areas in fMRI studies in humans mirror the results from electrophysiological studies in animals (Kastner et al., <xref ref-type="bibr" rid="B73">1998</xref>; Beck and Kastner, <xref ref-type="bibr" rid="B8">2005</xref>). An important result is that the maximum spatial separation between stimuli, which induces suppressive interactions, increases at higher levels of visual processing, which is consistent with increasing receptive field size (Kastner et al., <xref ref-type="bibr" rid="B74">2001</xref>).</p><p>Large RFs thus cause stimuli to compete. The probability with which stimuli are represented by cells is thought to be influenced by a number of top-down and bottom-up biases. Bottom-up biases result from the properties of the stimulus itself, such as visual or emotional salience and novelty. Abrupt-onset stimuli, which have high temporal contrast, and thus salience, can attract attention even if they are task-irrelevant (Yantis and Jonides, <xref ref-type="bibr" rid="B145">1984</xref>). In the visual search paradigm, used to address feature-integration and binding (Treisman and Gelade, <xref ref-type="bibr" rid="B128">1980</xref>; Treisman and Schmidt, <xref ref-type="bibr" rid="B129">1982</xref>; Treisman, <xref ref-type="bibr" rid="B127">1998</xref>), subjects are required to find a unique object in a display cluttered with distracters. If the unique object is particularly salient, for example if it is brighter than the distracters or has a unique color, the search time remains constant regardless of the number of distracters. This phenomenon is called &#x0201c;pop-out.&#x0201d; Salience does not have to be a function of simple visual attributes: distractor faces exhibiting negative emotions slow search times more than neutral faces (Pessoa et al., <xref ref-type="bibr" rid="B99">2002</xref>). Novelty preference, the well-documented tendency for neurons to respond more strongly to a new stimulus than to a familiar one, can also be considered as a bottom-up bias (Desimone, <xref ref-type="bibr" rid="B33">1996</xref>).</p><p>Top-down biases reflect the cognitive requirements of the task rather than the stimuli. Top-down biases have been most studied via spatially-directed attention experiments. Electrophysiologically, if attention is directed toward one of two competing stimuli in a receptive field, the mutually suppressive effect disappears and the response of the cell emulates the response to the attended stimulus alone (Moran and Desimone, <xref ref-type="bibr" rid="B90">1985</xref>; Chelazzi et al., <xref ref-type="bibr" rid="B22">1993</xref>; Treue and Maunsell, <xref ref-type="bibr" rid="B130">1996</xref>; Desimone, <xref ref-type="bibr" rid="B34">1998</xref>). Even in the absence of visual stimulation, baseline increases in firing rate of 30&#x02013;40% may be seen, if attention is directed to a location within a cell's receptive field (Luck et al., <xref ref-type="bibr" rid="B81">1997</xref>). Indeed, in fMRI studies, responses are increased in visual areas after attentional cuing but before stimulus onset (Chawla et al., <xref ref-type="bibr" rid="B21">1999b</xref>; Kastner et al., <xref ref-type="bibr" rid="B75">1999</xref>; O'Connor et al., <xref ref-type="bibr" rid="B94">2002</xref>; Stokes et al., <xref ref-type="bibr" rid="B124">2009</xref>). In addition, cells respond more strongly to attended than unattended stimuli (Luck et al., <xref ref-type="bibr" rid="B81">1997</xref>). Thus, top-down bias has both additive (baseline shift) and multiplicative (attentional gain) components that may depend on each other (Chawla et al., <xref ref-type="bibr" rid="B21">1999b</xref>). In summary, biased competition is a mechanistic framework, which provides a plausible neurobiological account of attention. Later, we will see how biased competition emerges naturally in predictive coding formations of Bayes-optimal perception.</p></sec><sec><title>The Posner paradigm</title><p>In later sections we will simulate optimal perception under the Posner task, a covert attention task. Attending to an object usually involves looking at it; that is placing its image at the fovea (the central area of the retina with highest acuity). However, attention can be directed independently of eye movement (Posner et al., <xref ref-type="bibr" rid="B104">1978</xref>). Under the Posner paradigm, subjects are required to foveate a central spot and respond as quickly as possible to the appearance of a peripheral target. The target is cued with either a central arrow indicating the side it will appear on, or a peripheral box around the target's eventual location. The cue is correct (valid) most (usually 80%) of the time. Posner found that reaction times to validly cued targets were significantly shorter than to invalidly cued targets, which appeared on the opposite side. This demonstrated that attention could be moved to salient locations in the absence of gaze shift. The cuing seen in the Posner paradigm seems to be separable from the phenomenon of &#x0201c;alerting,&#x0201d; in which a non-directional signal indicates the imminent onset of a target (Fernandez-Duque and Posner, <xref ref-type="bibr" rid="B43">1997</xref>; Posner, <xref ref-type="bibr" rid="B102">2008</xref>). Subjects are quicker to respond to a target if the cue indicates the location of the target than when it only indicates the timing (Davidson and Marrocco, <xref ref-type="bibr" rid="B29">2000</xref>). In addition, a pharmacological double dissociation exists such that inhibitors of the cholinergic system selectively reduce the benefits of spatial cues, while noradrenergic inhibitors selectively reduce the benefits of alerting cues (Marrocco et al., <xref ref-type="bibr" rid="B85">1994</xref>). Furthermore, dopamine and noradrenalin antagonists can reduce the reaction time cost of invalidly cued targets, while preserving the validly effect (Clark et al., <xref ref-type="bibr" rid="B24">1989</xref>). However, this effect may be due to the role of noradrenalin in task switching (Sara, <xref ref-type="bibr" rid="B115">1998</xref>; Yu and Dayan, <xref ref-type="bibr" rid="B146">2005</xref>).</p><p>The two types of cues used in the Posner paradigm &#x02013; central and peripheral &#x02013; show the same facilitation effect. However, they may operate by different mechanisms. Peripheral stimuli are labeled as &#x0201c;exogenous,&#x0201d; because the change in attention is triggered by an external event. It is well established that abrupt-onset peripheral stimuli can attract attention via bottom-up mechanisms (Yantis and Jonides, <xref ref-type="bibr" rid="B145">1984</xref>), even when task-irrelevant (Theeuwes, <xref ref-type="bibr" rid="B125">1991</xref>). Central stimuli are &#x0201c;endogenous&#x0201d; because they do not in themselves indicate target location; attention must be directed to the correct location according to information conveyed by the cue. The most common central cues are inherently directional: an arrow pointing to where the target will appear, or an asterisk just to one side of fixation. Although cues such as this may automatically &#x0201c;push&#x0201d; attention, even when the subject has been told the cue is invalid (Hommel et al., <xref ref-type="bibr" rid="B67">2001</xref>).</p><p>Exogenous and endogenous cuing fit well with biased competition theory: exogenous cuing can be thought of as a bottom-up bias, based on the prior expectation that salient events recur in the same part of the visual field. On the other hand the effect of endogenous cues must be mediated by top-down bias. However, these top-down effects do not necessarily call on semantic or explicit processing: for example, Decaix et al. (<xref ref-type="bibr" rid="B31">2002</xref>) examined performance on the Posner paradigm when subjects were not informed about the cue-target relationship but subjects still learnt cue-target relationships within 90 trials, and performance was independent of whether the learnt relationship was accessible to verbal report. Bartolomeo et al. (<xref ref-type="bibr" rid="B6">2007</xref>) compared performance of informed and non-informed subjects and found no effect of explicit knowledge on reaction time. Finally, Risko and Stolz (<xref ref-type="bibr" rid="B111">2010</xref>) demonstrated that knowledge of the proportion of valid trials did not affect reaction time. In short, the basic phenomena disclosed in the Posner paradigm may not depend on high-level cognitive processing. This suggests that a low-level simulation of perceptual processing should be able to account for cue-validity effects. This is what we attempt to show and demonstrate that cue-validity effects are Bayes-optimal. In the next section, we review the principles that lie behind Bayes-optimal perception and apply these principles to the Posner paradigm in the subsequent section.</p></sec></sec></sec><sec sec-type="methods" id="s2"><title>Methods</title><sec><title>Free-energy and bayes-optimal perception</title><p>This section reviews the theoretical principles used later to explain perception and attention. This treatment is a bit technical but serves as a standalone summary of the mathematical principles behind the simulations of subsequent sections. More mathematical details can be found in (Friston et al., <xref ref-type="bibr" rid="B52">2010b</xref>). Readers who are familiar with generalized predictive coding should skip directly to &#x0201c;Perception and Attention.&#x0201d; We start with the objective of the free-energy formulation; namely to suppress surprise. We end with a set of ordinary differential equations describing changes in synaptic activity, gain and efficacy. These dynamics correspond to perceptual inference, attention and learning respectively. Basically, the resulting scheme can be regarded as a form of evidence accumulation (Mazurek et al., <xref ref-type="bibr" rid="B87">2003</xref>) that is formally equivalent to generalized predictive coding. Free-energy is a bound on surprise and is therefore a bound on the log-evidence for the brain's generative model of its world. The second half of this section considers particular forms of these generative models, with a focus on state-dependent noise and the implications for the neurobiology of perception. The amount of this noise is measured in terms of its variance, which reflects the degree of randomness in the processes generating sensory data. Inverse variance is called precision; therefore precision increases with certainty about states of the world. We will see that precision is encoded by the post-synaptic gain of sensory or prediction error-units. This means that state-dependent changes in precision may be modeled in the brain by activity-dependent modulation of the synaptic gain of principal cells originating forward connections. This is the optimization we associate with attention.</p><sec><title>Recognition from basic principles</title><p>Our objective, given a model (brain), <italic>m</italic>, is to minimize the average uncertainty (entropy) about some generalized sensory states, <inline-formula><mml:math id="M1"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo>&#x02295;</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x02295;</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#x02033;</mml:mo></mml:msup><mml:mo>&#x02295;</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>&#x02208;</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula> it experiences (&#x02a01; means concatenation). Generalized states comprise the state itself, its velocity, acceleration, jerk, <italic>etc</italic>. This average uncertainty is <disp-formula id="E1"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></disp-formula></p><p>Under ergodic assumptions, this is proportional to the long-term average of surprise, also known as negative log-evidence <inline-formula><mml:math id="M3"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> <disp-formula id="E2"><label>(2)</label><mml:math id="M4"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0221d;</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:munderover><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Minimizing sensory entropy therefore corresponds to maximizing the accumulated log-evidence for a model of the world. Although sensory entropy cannot be minimized directly, we can create an upper bound <inline-formula><mml:math id="M5"><mml:mrow><mml:mi mathvariant="script">S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02265;</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> This bound is induced with a recognition density <italic>q</italic>(<italic>t</italic>) :=&#x02009;<italic>q</italic>(&#x003d1;) on the causes (i.e., environmental states and parameters) of sensory signals. We will see later that these causes comprise time-varying states <italic>u</italic>(<italic>t</italic>) &#x02282;&#x02009;&#x003d1; and slowly varying parameters &#x003c6;(<italic>t</italic>) &#x02282;&#x02009;&#x003d1;. The recognition density is sometimes called a proposal density and becomes the conditional density over causes, when it minimizes the bound. The bound itself is the path integral of free-energy &#x003c6;(<italic>t</italic>), which is created simply by adding a non-negative function of the recognition density to surprise: <disp-formula id="E3"><label>(3)</label><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="script">S</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mtext>&#x02131;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x02131;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d1;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d1;</mml:mtext><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This function is a Kullback&#x02013;Leibler divergence <italic>D</italic><sub><italic>KL</italic></sub> and is greater than zero, with equality when <inline-formula><mml:math id="M7"><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d1;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d1;</mml:mtext><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the true conditional density. This means that minimizing free-energy, by changing <italic>q</italic>(&#x003d1;), makes the recognition density an approximate conditional density on sensory causes. This is Bayes-optimal recognition. The free-energy can be evaluated easily because it is a function of the recognition density and a generative model &#x02112;(<italic>t</italic>) entailed by <italic>m</italic> <disp-formula id="E4"><label>(4)</label><mml:math id="M8"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>&#x02131;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mrow><mml:mtext>&#x02112;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>q</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x0210b;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x02112;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mtext>&#x003d1;</mml:mtext><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x0210b;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mo>&#x02329;</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x0232a;</mml:mo></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The free-energy has been expressed here in terms of &#x1d4d7;(<italic>t</italic>), the negentropy of <italic>q</italic>(<italic>t</italic>) and an energy &#x02112;(<italic>t</italic>) expected under <italic>q</italic>(<italic>t</italic>). The energy &#x02112;(<italic>t</italic>) reports the surprise about sensations and their causes under a generative model. If we assume that recognition density <italic>q</italic>(&#x003d1;)&#x02009;=&#x02009;&#x1d4a9;(&#x003bc;, <italic>C</italic>) is Gaussian (known as the Laplace assumption), we can express free-energy in terms of the mean and covariance of the recognition density <disp-formula id="E5"><label>(5)</label><mml:math id="M9"><mml:mrow><mml:mtext>&#x02131;</mml:mtext><mml:mo>=</mml:mo><mml:mtext>&#x02112;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003bc;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003bc;</mml:mo><mml:mo>&#x003bc;</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>|</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mn>2</mml:mn><mml:mtext>&#x003c0;</mml:mtext><mml:mi>e</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Where <italic>n</italic>&#x02009;=&#x02009;dim(&#x003bc;) and subscripts denote derivatives. We can now minimize free-energy with respect to the conditional precision (inverse covariance). The free-energy is minimized when &#x1d4df;&#x02009;=&#x02009;&#x1d49e;<sup>&#x02212;1</sup>&#x02009;=&#x02009;&#x02112;<sub>&#x003bc;&#x003bc;</sub>&#x02009;&#x021d2;&#x02009;&#x02131;<sub>C</sub>&#x02009;=&#x02009;0 &#x021d2;&#x02009;&#x003b4;<sub>C</sub>S&#x02009;=&#x02009;0 and allows us to eliminate &#x1d49e; from Eq. <xref ref-type="disp-formula" rid="E5">5</xref> <disp-formula id="E6"><label>(6)</label><mml:math id="M10"><mml:mrow><mml:mtext>&#x02131;</mml:mtext><mml:mo>=</mml:mo><mml:mtext>&#x02112;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003bc;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003bc;</mml:mo><mml:mo>&#x003bc;</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mn>2</mml:mn><mml:mtext>&#x003c0;</mml:mtext></mml:mrow></mml:math></disp-formula></p><p>Crucially, this means the free-energy is only a function of the conditional mean or expectation. The expectations that minimize free-energy are the solutions to the following differential equations. For the generalized states <inline-formula><mml:math id="M11"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02282;</mml:mo><mml:mtext>&#x003d1;</mml:mtext></mml:mrow></mml:math></inline-formula> <disp-formula id="E7"><label>(7)</label><mml:math id="M12"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x021d4;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mi>u</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02033;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:msup><mml:mi>u</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mo>&#x02033;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02034;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:msup><mml:mi>u</mml:mi><mml:mo>&#x02033;</mml:mo></mml:msup></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Where &#x1d49f; is a derivative matrix operator with identity matrices above the leading diagonal, such that <inline-formula><mml:math id="M13"><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x02295;</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mo>&#x02033;</mml:mo></mml:msup><mml:mo>&#x02295;</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Here and throughout, we assume all gradients are evaluated at the mean; here <inline-formula><mml:math id="M14"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> The stationary solution of Eq. <xref ref-type="disp-formula" rid="E7">7</xref> minimizes free-energy and its path integral: <inline-formula><mml:math id="M15"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x021d2;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x021d2;</mml:mo><mml:msub><mml:mtext>&#x003b4;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:math></inline-formula> This ensures that when free-energy is minimized the mean of the motion is the motion of the mean; that is <inline-formula><mml:math id="M16"><mml:mrow><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x021d2;</mml:mo><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p><p>For slowly varying parameters &#x003c6;(<italic>t</italic>) &#x02282;&#x02009;&#x003d1; this motion disappears and we can use the following scheme <disp-formula id="E8"><label>(8)</label><mml:math id="M17"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mo>&#x003d5;</mml:mo></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Here, the solution <inline-formula><mml:math id="M18"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> minimizes free-energy, under constraint that the motion of the expected parameters is small: <inline-formula><mml:math id="M19"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x021d2;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mo>&#x003d5;</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x021d2;</mml:mo><mml:msub><mml:mtext>&#x003b4;</mml:mtext><mml:mo>&#x003d5;</mml:mo></mml:msub><mml:mi mathvariant="script">S</mml:mi><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:math></inline-formula> The last equality &#x003b4;<sub>&#x003c6;</sub>S&#x02009;=&#x02009;0 just means that variations in the parameters do change the path integral of free-energy (cf, keeping to the floor of a valley to minimize the average height of ones path).</p><p>Equations <xref ref-type="disp-formula" rid="E7">7</xref> and <xref ref-type="disp-formula" rid="E8">8</xref> prescribe recognition dynamics for the expected states and parameters of the world respectively. The dynamics for states can be thought of as a gradient descent in a frame of reference that moves with the expected motion of the world (cf, surfing a wave). Conversely, the dynamics for the parameters can be thought of as a gradient descent that resists transient fluctuations with a damping term (&#x02212;&#x003ba;&#x003bc;&#x02032;<sup>(&#x003c6;)</sup>), which instantiates our prior belief that the fluctuations in the parameters are small. We use &#x003ba;&#x02009;=&#x02009;<italic>N</italic>, where <italic>N</italic> is the number of sensory samples.</p><p>In summary, we have derived recognition dynamics for expected states (in generalized coordinates of motion) and parameters, which cause sensory samples. The solutions to these equations minimize free-energy and therefore minimize a bound on surprise or (negative) log-evidence. Optimization of the expected states and parameters corresponds to perceptual inference and learning respectively. The precise form of the recognition depends on the energy <inline-formula><mml:math id="M20"><mml:mrow><mml:mtext>&#x02112;</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mtext>&#x003d1;</mml:mtext><mml:mo>|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> associated with a particular generative model. In what follows, we examine dynamic models of the world.</p></sec><sec><title>Hierarchical dynamic models</title><p>We next introduce a very general model based on the hierarchal dynamic model discussed in Friston (<xref ref-type="bibr" rid="B48">2008</xref>). We will assume that any sensory data can be modeled with a special case of this model <disp-formula id="E9"><label>(9)</label><mml:math id="M21"><mml:mtable><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The non-linear functions <italic>f</italic><sup>(<italic>u</italic>)</sup> :&#x02009;<italic>u</italic>&#x02009;&#x02208;&#x02009;<italic>v</italic>, <italic>x</italic> represent a sensory mapping and equations of motion respectively and are parameterized by &#x003b8;&#x02009;&#x02282;&#x02009;&#x003c6;. The variables <italic>v</italic>&#x02009;&#x02282;&#x02009;<italic>u</italic> are referred to as hidden causes, while hidden states <italic>x</italic>&#x02009;&#x02282;&#x02009;<italic>u</italic> meditate the influence of the causes on sensory data and endow the system with memory. We assume the random fluctuations <italic>z</italic><sup>(<italic>u</italic>)</sup> are analytic, such that the covariance <inline-formula><mml:math id="M22"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of is well defined. Unlike our previous treatments (Friston, <xref ref-type="bibr" rid="B48">2008</xref>), this model allows for state-dependent changes in the amplitude of random fluctuations. It is this generalization that furnishes a model of attention and introduces the key distinction between the effect of states on first- and second-order sensory dynamics. These effects are meditated by the vector and matrix functions <sup><italic>f</italic>(<italic>u</italic>)</sup>&#x02009;&#x02208;&#x02009;&#x1d57d;<sup><italic>dim</italic>(<italic>u</italic>)</sup> and &#x003a3;<sup>(<italic>u</italic>)</sup>&#x02009;&#x02208;&#x02009; &#x1d57d;<sup>dim(<italic>u</italic>)&#x02009;&#x000d7;&#x02009;dim(<italic>u</italic>)</sup> respectively, which are parameterized by first- and second-order parameters {&#x003b8;, &#x003b3;} &#x02282;&#x02009;&#x003c6;.</p><p>Under local linearity assumptions, the generalized motion of the sensory response and hidden states can be expressed compactly as <disp-formula id="E10"><label>(10)</label><mml:math id="M23"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="script">D</mml:mi><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> Where the generalized predictions are <disp-formula id="E11"><label>(11)</label><mml:math id="M24"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo>&#x02032;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>x</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>v</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo>&#x02032;</mml:mo><mml:mtext>&#x0200b;</mml:mtext><mml:mo>&#x02032;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>x</mml:mi><mml:mo>&#x02033;</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mi>v</mml:mi><mml:mo>&#x02033;</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Equation 10 means that Gaussian assumptions about the random fluctuations specify a generative model in terms of a likelihood and empirical priors on the motion of hidden states <disp-formula id="E12"><label>(12)</label><mml:math id="M25"><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>These probability densities are encoded by their covariances <inline-formula><mml:math id="M26"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> or precisions <inline-formula><mml:math id="M27"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with precision parameters &#x003b3;&#x02009;&#x02282;&#x02009;&#x003c6; that control the amplitude and smoothness of the random fluctuations. Generally, the covariances factorize; <inline-formula><mml:math id="M28"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:msup><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> into a covariance proper and a matrix of correlations <italic>V</italic><sup>(<italic>u</italic>)</sup> among generalized fluctuations that encodes their smoothness.</p><p>Given this generative model we can now write down the energy as a function of the conditional means, which has a simple quadratic form (ignoring constants) <disp-formula id="E13"><label>(13)</label><mml:math id="M29"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>&#x02112;</mml:mtext><mml:mo>=</mml:mo><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b7;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Here, the auxiliary variables <inline-formula><mml:math id="M30"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mtext>&#x003d5;</mml:mtext></mml:mrow></mml:math></inline-formula> are prediction errors for sensory data, the motion of hidden states and parameters respectively. The predictions for the states are <inline-formula><mml:math id="M31"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003bc;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mi>u</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> and the predictions for the parameters are the prior expectations <inline-formula><mml:math id="M32"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b7;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Equation <xref ref-type="disp-formula" rid="E13">13</xref> assumes flat priors on the states and that priors <inline-formula><mml:math id="M33"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">|</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b7;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> on the parameters are Gaussian. We next consider hierarchical forms of this model. These are just special cases of Eq. <xref ref-type="disp-formula" rid="E9">9</xref>, in which we make certain conditional independencies explicit. Although they may look more complicated, they are simpler than the general form above. They are useful because they provide an empirical Bayesian perspective on inference and learning that may be exploited by the brain. Hierarchical dynamic models have the following form <disp-formula id="E14"><label>(14)</label><mml:math id="M34"><mml:mtable><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mtext>&#x003b7;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Again, <italic>f</italic><sup>(<italic>i,u</italic>)</sup> :=&#x02009;<italic>f</italic><sup>(<italic>u</italic>)</sup>(<italic>x</italic><sup>(<italic>i</italic>)</sup>, <italic>v</italic><sup>(<italic>i</italic>)</sup>, &#x003b8;) :&#x02009;<italic>u</italic>&#x02009;&#x02208;&#x02009;<italic>v</italic>, <italic>x</italic> are continuous non-linear functions and &#x003b7;<sup>(<italic>v</italic>)</sup>(<italic>t</italic>) is a prior mean on the hidden causes at the highest level. The random terms <italic>z</italic><sup>(<italic>i,u</italic>)</sup>&#x02009;&#x0223c;&#x02009;&#x1d4a9;(0, &#x003a3;(<italic>x</italic><sup>(<italic>i</italic>)</sup>, <italic>v</italic><sup>(<italic>i</italic>)</sup>, &#x003b3;<sup>(<italic>i,u</italic>)</sup>) are conditionally independent and enter each level of the hierarchy. They play the role of observation error or noise at the first level and induce random fluctuations in the states at higher levels. The causes <italic>v</italic>&#x02009;=&#x02009;<italic>v</italic><sup>(1)</sup>&#x02009;&#x02295; <italic>v</italic><sup>(2)</sup>&#x02009;&#x02295;&#x02026; link levels, whereas the hidden states <italic>x</italic>&#x02009;=&#x02009;<italic>x</italic><sup>(1)</sup>&#x02009;&#x02295; <italic>x</italic><sup>(2)</sup>&#x02009;&#x02295;&#x02026; link dynamics over time. In hierarchical form, the output of one level acts as an input to the next. This input can enter non-linearly to produce quite complicated generalized convolutions with deep (hierarchical) structure. This structure appears in the energy as empirical priors &#x02112;<sup>(<italic>i,u</italic>)</sup> :&#x02009;<italic>u</italic>&#x02009;&#x02208;&#x02009;<italic>x</italic>, <italic>v</italic> where, ignoring constants <disp-formula id="E15"><label>(15)</label><mml:math id="M35"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>&#x02112;</mml:mtext><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Note that the data enter the prediction errors at the lowest level; <inline-formula><mml:math id="M36"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> At intermediate levels the prediction errors mediate empirical priors on the causes.</p><p>In summary, these models are as general as one could imagine; they comprise hidden causes and states, whose dynamics can be coupled with arbitrary (analytic) non-linear functions. Furthermore, these states can be subject to random fluctuations with state-dependent changes in amplitude and arbitrary (analytic) autocorrelation functions. A key aspect is their hierarchical form, which induces empirical priors on the causes. In the next section, we look at the recognition dynamics entailed by this form of generative model, with a particular focus on how recognition might be implemented in the brain. We consider perception first and then attention. For completeness, we also mention learning; but will only pursue this in subsequent papers on learning and related phenomena (e.g., inhibition of return; Posner and Cohen, <xref ref-type="bibr" rid="B103">1984</xref>; Rafal et al., <xref ref-type="bibr" rid="B105">1989</xref>).</p></sec><sec><title>Perception and attention</title><p>If we now write down the recognition dynamics (Eq. <xref ref-type="disp-formula" rid="E7">7</xref>) using precision-weighted prediction errors <inline-formula><mml:math id="M37"><mml:mrow><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> from Eq. <xref ref-type="disp-formula" rid="E15">15</xref>, one can see the hierarchical message passing this scheme entails (ignoring the derivatives of the energy curvature); <disp-formula id="E16"><label>(16)</label><mml:math id="M38"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003bb;</mml:mtext><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003bb;</mml:mtext><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003bb;</mml:mtext><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mtext>&#x003bb;</mml:mtext><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi mathvariant="script">D</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x003be;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Here, we have assumed the amplitude of random fluctuations is parameterized in terms of log-precisions, where <disp-formula id="E17"><label>(17)</label><mml:math id="M39"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>I</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The vector function &#x003c0;<sup>(<italic>i,u</italic>)</sup> :=&#x02009;&#x003c0;(<italic>x</italic>, <italic>v</italic>, &#x003b3;<sup>(<italic>i,u</italic>)</sup>) returns state-dependent log-precisions and <italic>R</italic><sup>(<italic>i,u</italic>)</sup> is the inverse smoothness matrix <italic>V</italic><sup>(<italic>i,u</italic>)</sup>. In what follows we will quantify the amplitude (variance) of random fluctuations in terms of log-precisions, such that the associated variance is exp(&#x02212;&#x003c0;<sup>(<italic>i,u</italic>)</sup>). With this particular form for the precisions, the terms <inline-formula><mml:math id="M40"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M41"><mml:mrow><mml:msubsup><mml:mtext>&#x003bb;</mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are constant for states <inline-formula><mml:math id="M42"><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> that affect the log-precisions linearly and zero if they have no effect.</p><p>It is difficult to overstate the generality and importance of Eq. <xref ref-type="disp-formula" rid="E16">16</xref>: it grandfathers nearly every known statistical estimation scheme, under parametric assumptions about either additive or multiplicative noise. These range from ordinary least squares to advanced variational deconvolution schemes (see Friston, <xref ref-type="bibr" rid="B48">2008</xref>). For example, the schemes used to invert stochastic dynamic causal models of imaging time series (e.g., Daunizeau et al., <xref ref-type="bibr" rid="B28">2009</xref>) use Eq. <xref ref-type="disp-formula" rid="E16">16</xref>. This is generalized predictive coding.</p><p>In neural network terms, Eq. <xref ref-type="disp-formula" rid="E16">16</xref> says that error-units receive messages from the states in the same level and the level above. Conversely, state-units are driven by error-units in the same level and the level below, were <inline-formula><mml:math id="M43"><mml:mrow><mml:msubsup><mml:mtext>&#x003c7;</mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>:</mml:mo><mml:mi>u</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula> are the forward connection strengths to the state-unit representing <inline-formula><mml:math id="M44"><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Crucially, recognition requires only the prediction error from the lower level &#x003be;<sup>(<italic>i,v</italic>)</sup> and the level in question, &#x003be;<sup>(<italic>i,x</italic>)</sup> and &#x003be;<sup>(<italic>i</italic>+1,<italic>v</italic>)</sup> (see Figure <xref ref-type="fig" rid="F1">1</xref>). These constitute bottom-up and lateral messages that drive conditional means <inline-formula><mml:math id="M45"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> toward a better prediction, which reduces the prediction error in the level below. These top-down and lateral predictions correspond to <inline-formula><mml:math id="M46"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> This is the essence of recurrent message passing between hierarchical levels to optimize free-energy or suppress prediction error; i.e., perceptual inference (see Friston, <xref ref-type="bibr" rid="B48">2008</xref> for a more detailed discussion).</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Schematic detailing the neuronal architecture that might implement the generalized predictive coding described in Eq. <xref ref-type="disp-formula" rid="E16">16</xref></bold>. This shows the speculative cells of origin of forward driving connections that convey prediction error from a lower area to a higher area and the backward connections that construct predictions (Mumford, <xref ref-type="bibr" rid="B92">1992</xref>; Friston, <xref ref-type="bibr" rid="B48">2008</xref>). These predictions try to explain away prediction error in lower levels. In this scheme, the sources of forward and backward connections are superficial and deep pyramidal cells respectively. The equations represent a gradient descent on free-energy under a hierarchical dynamic model (see Eq. <xref ref-type="disp-formula" rid="E16">16</xref>). State-units are in black and error-units in red. Here, neuronal populations are deployed hierarchically within three cortical areas (or macro-columns). Subscripts denote derivatives.</p></caption><graphic xlink:href="fnhum-04-00215-g001"/></fig><p>In the present context, the key thing about this scheme is that the precisions <inline-formula><mml:math id="M47"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> depend on the expected hidden causes and states. It is this dependency that we propose mediates attentional processing. Equation <xref ref-type="disp-formula" rid="E16">16</xref> tells us that the state-dependent precisions modulate the responses of the error-units to their pre-synaptic inputs. This modulation depends on the conditional expectations about the states and suggests something intuitive; attention is mediated by activity-dependent modulation of the synaptic gain of principal cells that convey sensory information (prediction error) from one cortical level to the next. These are generally thought to be the superficial pyramidal cells responsible for generating EEG signals. More specifically, precision sets the synaptic gain of error-units to their top-down and lateral inputs. In hierarchical models, the gain modulation of error-unit activity &#x003be;<sup>(<italic>i,u</italic>)</sup> depends on <inline-formula><mml:math id="M48"><mml:mrow><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and therefore depends on the conditional expectations of <italic>x</italic><sup>(<italic>i</italic>)</sup> in the current level and <italic>v</italic><sup>(<italic>i</italic>)</sup> in the level above. This translates into a top-down control of synaptic gain <inline-formula><mml:math id="M49"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> in principal (superficial pyramidal) cells elaborating prediction errors and fits comfortably with the modulatory effects of top-down connections in cortical hierarchies that have been associated with attention. Note that the precisions or synaptic gain also depends on the slowly varying parameters &#x003b3;&#x02009;&#x02282;&#x02009;&#x003c6; responsible for learning. It is these parameters we associate with the slower dynamics of classical neuromodulation (e.g., cholinergic neurotransmission; Friston, <xref ref-type="bibr" rid="B48">2008</xref>).</p></sec><sec><title>Perceptual learning</title><p>Perceptual learning corresponds to optimizing the first-order parameters &#x003b8;&#x02009;&#x02282;&#x02009;&#x003c6; according to Eq. <xref ref-type="disp-formula" rid="E8">8</xref>. This describes a process that is remarkably similar to models of associative plasticity based on correlated pre- and post-synaptic activity. This can be seen most easily by assuming an explicit form for the generating functions; for example (for a single parameter and ignoring high-order derivatives) <disp-formula id="E18"><label>(18)</label><mml:math id="M50"><mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:msubsup><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x021d2;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mtext>&#x003be;</mml:mtext><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mtext>&#x003a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Here &#x003bc;<sup>(&#x003b8;)</sup> is the connection strength mediating the influence of the <italic>p</italic>-th hidden state on the motion of the <italic>q</italic>-th, at hierarchical level <italic>i</italic>&#x02009;&#x02208;&#x02009;1, 2,&#x02026; This strength changes in proportion to a &#x0201c;synaptic tag&#x0201d;&#x02009;&#x003bc;&#x02032;<sup>(&#x003b8;)</sup> that accumulates in proportion to the product of the <italic>p</italic>-th pre-synaptic input <inline-formula><mml:math id="M51"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and post-synaptic response <inline-formula><mml:math id="M52"><mml:mrow><mml:msubsup><mml:mtext>&#x003be;</mml:mtext><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> of the <italic>q</italic>-th error-unit (first term of Eq. <xref ref-type="disp-formula" rid="E18">18</xref>). The tag is auto-regulated by the synaptic strength and decays with first-order kinetics (second and third terms respectively).</p><p>We conclude by considering the equivalent dynamics for the second-order (precision) parameters &#x003b3;&#x02009;&#x02282;&#x02009;&#x003c6;. These precision parameters govern lateral and top-down state-dependent gain control and are learned according to Eq. <xref ref-type="disp-formula" rid="E8">8</xref> (for a single parameter) <disp-formula id="E19"><label>(19)</label><mml:math id="M53"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mtext>&#x003a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>As with perceptual learning, the precision parameters change in proportion to a synaptic tag that decays in proportion to the precision <italic>per se</italic> and the amount of tag. This tag accumulates sum of squared predications errors, weighted by <inline-formula><mml:math id="M54"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a9;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to select those errors whose precision is encoded. In this paper, we will focus on perceptual inference and return to learning in a later paper. The numerics of the integration scheme used to simulate inference (Eq. <xref ref-type="disp-formula" rid="E16">16</xref>) and learning (Eq. <xref ref-type="disp-formula" rid="E8">8</xref>) are provided in Appendix &#x0201c;Integrating the Recognition Dynamics (Generalized Filtering).&#x0201d;</p></sec><sec><title>Summary</title><p>In this section, we have applied the general form of recognition dynamics prescribed by the free-energy treatment to a generic hierarchical dynamic model with state-dependent noise. When formulated as a neuronal message-passing scheme something quite important emerges; namely, a lateral and top-down modulation of synaptic gain in principal cells that convey sensory information (prediction error) from one cortical level to the next. It is this necessary and integral component of perpetual inference that we associate with attention.</p></sec></sec></sec><sec id="s3"><title>Results</title><sec><title>Simulating the posner paradigm</title><p>In this section, we use the hierarchical dynamic model of the previous section as a generative model of stimuli used in the Posner paradigm. Inversion of this model, using generalized predictive coding (Eq. <xref ref-type="disp-formula" rid="E16">16</xref>) will be used to simulate neuronal responses. This allows us to explore some of the inferential and empirical aspects of perception the Posner paradigm was designed to study. We first describe the particular model and stimuli used. We then present simulated responses to valid and invalid targets to highlight their differences, in terms of implicit speed-accuracy trade-offs and their electrophysiological correlates.</p><sec><title>The Posner model</title><p>We deliberately tried to keep the generative model as simple as possible so that its basic behavior can be seen clearly. To this end, we used a model with two levels, the first representing visual input and the second representing the causes of that input. The model has the following form, which we unpack below.</p><disp-formula id="E20"><label>(20)</label><mml:math id="M55"><mml:mtable><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mstyle><mml:munder><mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mstyle><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">&#x0fe38;</mml:mo></mml:munder><mml:mrow><mml:mtext>exogenous</mml:mtext></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:munder><mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">&#x0fe38;</mml:mo></mml:munder><mml:mrow><mml:mtext>endogenous</mml:mtext></mml:mrow></mml:munder><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:mfrac></mml:mstyle><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><p>This minimal model has all the ingredients needed to demonstrate some complicated but intuitive phenomena. It helps to bear in mind that this is a generative model of how sensory data are caused that is used by the (synthetic) brain; we actually generated sensory data by simply presenting visual cues in various positions. Because this is a model the prior assumptions about the causes of visual input are that they are just random fluctuations about a mean of zero; i.e., <italic>v</italic><sup>(1)</sup>&#x02009;=&#x02009;<italic>z</italic><sup>(2,<italic>v</italic>)</sup>. Perception (model inversion) uses this model to explain sensory input in terms of conditional expectations about what caused that input.</p><p>We first describe the model in terms of the way that it explains sensory data; in other words, how it maps from causes to consequences. We then reprise the description in terms of its inversion; namely, mapping from consequences (sensory data) to causes (percepts). As a generative model, Eq. <xref ref-type="disp-formula" rid="E20">20</xref> describes how hidden causes generate sensory input. There are three causes, which are just random fluctuations with a mean of zero and a precision of one. Two causes generate targets in the right and left visual fields <inline-formula><mml:math id="M56"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> respectively and a third <inline-formula><mml:math id="M57"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> generates a cue. This cue establishes the probabilistic context in which the first two causes are expressed. This context is determined by hidden states <inline-formula><mml:math id="M58"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> which modulate the log-precision (inverse amplitude) of random fluctuations that are added to the hidden causes to create sensory data. Here, <inline-formula><mml:math id="M59"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mrow><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are mean centered versions and &#x003b3;&#x02009;&#x02282;&#x02009;&#x003c6; is a constant that controls the potency of hidden states. Unless stated otherwise we used &#x003b3;&#x02009;=&#x02009;2. Crucially, the hidden causes induce sensory signals directly but also drive increases or decreases in the hidden states (second equality in Eq. <xref ref-type="disp-formula" rid="E20">20</xref>). The two hidden states represent a high precision on the left and a low precision on the right and <italic>vice versa</italic>. In other words, they induce a redistribution of precision to the left and right in a complementary way. The first cause <inline-formula><mml:math id="M60"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> generates a stimulus <italic>s</italic><sub><italic>L</italic></sub> in the left hemi-field and drives its corresponding hidden state <inline-formula><mml:math id="M61"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> to increase precision on the left; similarly for the right cause. This means that hidden causes not only cause sensory signals but also augment their precision. In other words, they cause precise visual information with spatial specificity.</p><p>Note how the log-precision &#x003c0;<sup>(1,<italic>v</italic>)</sup>(<italic>x</italic><sup>(1)</sup>, &#x003b3;) of sensory noise <italic>z</italic><sup>(1,<italic>v</italic>)</sup>&#x02009;&#x0223c;&#x02009;&#x1d4a9;(0, <italic>diag</italic>(exp(&#x02212;&#x003c0;<sup>(1,<italic>v</italic>)</sup>))) depends on the hidden states. The motivation for this dependency is simple: high levels of signal are generally associated with lower levels of noise (i.e., high signal to noise). More formally, this represents a prior expectation that sensory input conforms to Weber's law (Formankiewicz and Mollon, <xref ref-type="bibr" rid="B44">2009</xref>): for stimulus intensities with a fixed precision (of sensory noise), under Weber's law (after log-transform) the log-precision scales with the magnitude of the signal. See <xref ref-type="app" rid="A1">Appendix</xref> &#x0201c;State-Dependent Noise and Weber's Law.&#x0201d;</p><p>The ensuing increase in local precision can be regarded as analogous to exogenous cuing in the Posner paradigm, in the sense that it co-localizes in space and time with its sensory expression. Endogenous effects on precision that do not co-localize correspond to the probabilistic context established by <inline-formula><mml:math id="M62"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> that enables endogenous cuing. This hidden cause drives hidden states to increase precision on the right. One can think of <italic>s</italic><sub><italic>C</italic></sub> as the corresponding endogenous cue in the center of the field of view. Note that the hidden states decay slowly. This represents a formal prior that once a cause has been expressed in any part of the visual field, subsequent causes will be expressed in the same vicinity with a high sensory precision. The time constants for the accumulation of hidden causes by hidden states (4 and 2) and their decay (32) are somewhat arbitrary, because we can assign any units of time to the dynamics. The important thing is that the decay is slower than the accumulation (by factors of 8 and 16 here).</p><p>Some readers may wonder why we have used two hidden states that are placed in (redundant) opposition to each other. The reason for this is that we will use this model for more realistic simulations in the future, where hidden states encode a high precision in their circumscribed part of the visual field: this involves generating data in multiple sensory channels, with a hidden state for each channel or location. The vectors of ones and minus ones in Eq. <xref ref-type="disp-formula" rid="E20">20</xref> then become (radial) basis functions. Furthermore, one can easily add further hierarchical levels to make the sensory dynamics more realistic (i.e., the causes at the sensory level could excite hidden states in a lower level to produce spatiotemporally structured or moving stimuli; cf, Nobre et al., <xref ref-type="bibr" rid="B93">2007</xref>). However, the basic behavior we want to illustrate here does not change. Finally, note that there is no hand-crafted gain modulation of sensory signals in the generative model. Attentional boosting of sensory signals is an emergent property of model inversion, which we now consider:</p><p>From the perspective of model inversion (mapping from sensory signals to causes) the predictive coding scheme of the previous section implies the following sort of behavior. When a cue <italic>s</italic><sub><italic>C</italic></sub> is presented, it induces high-precision prediction errors, which excite the representation of the hidden cause <inline-formula><mml:math id="M63"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> at the higher level. This then drives up the hidden states biasing precision to the valid (right) hemi-field, which remain activated after the cue disappears. If a subsequent (valid) target is presented, it will induce high-precision prediction errors and a consequent representation of its associated cause at the second level <inline-formula><mml:math id="M64"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> with a reasonably high degree of conditional confidence. Conversely, if an invalid target is presented, it faces two challenges. First, the prediction errors it elicits have low precision and will therefore exert less drive on its associated cause <inline-formula><mml:math id="M65"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Furthermore, this cause has to activate its associated hidden or contextual state <inline-formula><mml:math id="M66"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> from much lower (negative) levels. This means that the invalid target may never actually be perceived or, if it is inferred, then it will take considerably longer before the prediction error increases its own potency (by changing the hidden causes and states). In short, invalid targets will be perceived later and with a lower degree of conditional certainty (cf. Vibell et al., <xref ref-type="bibr" rid="B132">2007</xref>).</p><p>Figure <xref ref-type="fig" rid="F2">2</xref> shows an example of these dynamics. In this simulation, both cue and target stimuli were generated with Gaussian functions presented one-quarter and two-thirds of the way during the trial (each trial comprised sixty-four 10&#x02009;ms time bins; i.e., 640&#x02009;ms). When generating stimuli we suppressed all random fluctuations, using a log-precision of eight. The cue was a simple bump function with a duration (standard deviation) of about 45&#x02009;ms. The target was a (biphasic) time derivative of a Gaussian bump function with a duration of about 90&#x02009;ms. The cue and target stimuli are shown as broken gray lines in Figure <xref ref-type="fig" rid="F2">2</xref>. These are nearly underneath the respective predictions in red <italic>s</italic><sub><italic>C</italic></sub> and green <italic>s</italic><sub><italic>L</italic></sub> respectively. The dotted red lines show the prediction error and reflect the small amount of noise we used in the simulations (a log-precision of eight; see Eq. <xref ref-type="disp-formula" rid="E20">20</xref>). The ensuing conditional expectations of the underlying causal states <inline-formula><mml:math id="M67"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are shown below (lower left). The gray areas around the expectations correspond to 90% conditional confidence regions (referred to as tubes). Note that the conditional tube for the cued target (green line <inline-formula><mml:math id="M68"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> ) is relatively tight because the precision of the prediction errors associated with this location is high. Conversely, the tube for the non-target <inline-formula><mml:math id="M69"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is somewhat wider but correctly centered on an expectation of zero. The precisions are determined by the hidden states shown on the upper right. The green line corresponds to a precision or attentional bias to the right <inline-formula><mml:math id="M70"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and the blue line to the left <inline-formula><mml:math id="M71"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> It can be seen that by the time the target arrives, the log-precision is about four (see Eq. <xref ref-type="disp-formula" rid="E20">20</xref>). This is substantially greater than the prior precision on the hidden causes (we set this to a log-precision of zero). Therefore, the representation of the hidden cause (target) is driven primarily by sensory input. The insert on the lower level provides a schematic indicating the sort of stimuli that would be generated by these hidden causes. Now, compare these results with the equivalent responses to an identical stimulus but presented in the other hemi-field.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Simulation of the Posner task (validly cued target)</bold>. Upper left panel: the time-dependent expression of the cue and target stimuli are shown as broken gray lines, while the respective predictions are in red <italic>s</italic><sub><italic>C</italic></sub> and green <italic>s</italic><sub><italic>L</italic></sub> respectively. The dotted red lines show the prediction error and reflect the small amount of noise we used in these simulations. Lower left panel: the ensuing conditional expectations of the underlying hidden causes <inline-formula><mml:math id="M72"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are shown below. The gray areas correspond to 90% conditional confidence tubes; this confidence reflects the estimated precision of the sensory data, which is encoded by the expectations of the hidden states in the upper right panel. The green line corresponds to a precision or attentional bias to the right <inline-formula><mml:math id="M73"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and the blue line to the left <inline-formula><mml:math id="M74"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> They gray lines are the true precisions. Lower right panel: this insert indicates the sort of stimuli that would be generated by these hidden causes.</p></caption><graphic xlink:href="fnhum-04-00215-g002"/></fig><p>Figure <xref ref-type="fig" rid="F3">3</xref> uses the same format as Figure <xref ref-type="fig" rid="F2">2</xref> to show the responses to an invalid target (blue lines) presented on the right. It can be seen here that the predictions on this sensory channel are substantially less than the true value (compare the blue and dotted gray lines) with a consequent and marked expression of prediction error (dotted red line). As anticipated, the conditional confidence regions for the conditional expectation of this invalid target (lower left panel) are now much larger; with the 90% confidence tube always containing the value zero. The reason for this is that this invalid cue has failed to reverse the attentional context and is still operating under low levels of precision. This is reflected by the hidden states. In comparison with the previous figure, the attentional bias (difference between the right and left hidden states) has been subverted by the invalid cue but has not been reversed (the dotted gray lines show the true values of these hidden or contextual states).</p><p>The result of this asymmetry between valid and invalid cueing means that responses to valid targets are of higher amplitude and have much tighter confidence tubes, in relation to invalid targets. This is shown on the lower right panel of Figure <xref ref-type="fig" rid="F3">3</xref>, where one can compare the conditional estimates of the valid (green) and the invalid (blue) cause. Note that these profoundly different responses were elicited using exactly the same stimulus amplitude, after the cue had disappeared. This means that the difference is attributable only to the context (hidden states) that is instantiated by the endogenous cue. This is the basic phenomenon that we wanted to demonstrate, namely attentional bias in the ability of stimuli to capture attentional resources, where these resources correspond to the precision of sensory samples encoded by inferred hidden states or context. The reason that precision behaves like a resource is that the generative model contains prior beliefs that log-precision is redistributed over sensory channels in a context-sensitive fashion but is conserved over all channels.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>This figure uses the same format as Figure <xref ref-type="fig" rid="F2">2</xref> but shows responses to an invalid target (blue line) presented on the right</bold>. The predictions of this sensory channel are substantially less than the true value (compare the blue and dotted gray lines) with a consequent expression of prediction error (dotted red line). The conditional confidence regions for the conditional expectation of this invalid target (lower left panel) are now much larger than in the previous figure. This is shown in the lower right panel, where one can compare the conditional estimates of the valid (green; see Figure <xref ref-type="fig" rid="F2">2</xref>) and the invalid (blue) hidden cause, with their respective conditional confidences (gray). Note that these responses were elicited using exactly the same stimulus amplitude.</p></caption><graphic xlink:href="fnhum-04-00215-g003"/></fig></sec><sec><title>The psychophysics of the Posner paradigm</title><p>The difference in the confidence tubes between valid and invalidly cued targets (Figure <xref ref-type="fig" rid="F3">3</xref>; lower right) can be usefully interpreted in relation to behavior (cf. Gordon, <xref ref-type="bibr" rid="B56">1967</xref>). At each point in peristimulus time, the conditional density implicit in the conditional mean and precision can be used to compute the conditional probability that the target intensity is present. This provides the posterior probability <inline-formula><mml:math id="M75"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">|</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> of the presence of a target as a function of peristimulus time shown in Figure <xref ref-type="fig" rid="F4">4</xref> (left panel). These results can be interpreted in terms of a speed-accuracy trade-off. For example, one can identify the amount of peristimulus time required to accumulate sufficient evidence for a fixed level of accuracy, as determined by the posterior conditional confidence. Note how the conditional probability of the target being present shrinks toward chance (50%) levels, under invalid cueing. In this example, 80% conditional confidence for valid targets (solid line) is attained at about 20&#x02009;ms before the same accuracy for invalid targets (broken line). This translates into a reaction time advantage for valid targets of about 20&#x02009;ms.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Left panel: the posterior probability of a target being present as a function of peristimulus time, which can be interpreted in terms of a speed-accuracy trade-off</bold>. A reaction time can be derived from this data, as the post-stimulus time taken to achieve a fixed level of accuracy, as determined by the posterior or conditional confidence. In this example, 80% conditional confidence is attained at about 340&#x02009;ms for valid targets (solid line). However, for invalid targets (broken line) the same accuracy is only attained after about 360&#x02009;ms. This translates into a reaction time advantage for valid targets of about 20&#x02009;ms. Right panel: this shows the reaction times for invalid, neural and valid cues, where neutral cues caused a small reduction in precision but with no spatial bias. The reaction times here are shown to within an additive constant, to better reflect empirical data (see Figure <xref ref-type="fig" rid="F5">5</xref>).</p></caption><graphic xlink:href="fnhum-04-00215-g004"/></fig><p>Figure <xref ref-type="fig" rid="F4">4</xref> (right panel) shows the time taken to reach 80% conditional confidence after the onset of invalid, neutral and valid cues (we simulated these reaction times with &#x003b3;&#x02009;=&#x02009;0.8). Neutral cues are modeled by reducing &#x003b3;&#x02009;=&#x02009;0.2 and removing any spatial bias afforded by the hidden states (by only using valid targets). This produces a temporal facilitation (temporal alerting effect) but without spatial specificity. The reaction time advantage with valid cues and the cost with invalid cues can be seen clearly. The reaction time to neutrally cued stimuli lies between these values. Note the asymmetry between the reaction time benefit of a valid cue and the cost of an invalid cue; this asymmetry is evident in behavioral data and is an emergent property of the non-linearities inherent in this Bayes-optimal scheme.</p><p>Recall that the time course of the Posner effect depends on the slowly-decaying hidden states encoding precision (with a time constant of 32 in Eq. <xref ref-type="disp-formula" rid="E20">20</xref>). This reflects a formal prior that changes in precision show a temporal persistence at any location in visual space. This sort of prior means that attentional biasing will persist but decay monotonically following a cue. This effect manifests in reaction times as a slow decay of benefits and costs with valid and invalid cures respectively. Figure <xref ref-type="fig" rid="F5">5</xref> (left panel) shows the difference in reaction times following the three types of cue for various asynchronies between cue and stimulus onset (the &#x0201c;foreperiod&#x0201d;). The small benefit seen for neutral cues is due to a temporal alerting effect and reflects an increase in precision with no spatial bias (i.e., a small increase in precision at both locations). Note that cue-dependent effects emerge over 200&#x02009;ms, during which time conditional expectations accumulate evidence (see Figure <xref ref-type="fig" rid="F2">2</xref>; upper right panel). The ensuing profiles of reaction times are pleasing similar to empirical observations. The right panel of Figure <xref ref-type="fig" rid="F5">5</xref> shows the corresponding behavioral results reported in Posner et al. (<xref ref-type="bibr" rid="B104">1978</xref>). Note again that the asymmetry in costs and benefits, over different foreperiods, is an emergent property of the scheme used in the simulations.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Left panel: simulated reaction times showing the time course of the Posner effect over different delays (foreperiod) between the onset of the cue and the target increases</bold>. Right panel: empirical reaction time data, redrawn from Posner et al. (<xref ref-type="bibr" rid="B104">1978</xref>). In both the simulated and empirical data, reaction time benefit and cost increase swiftly to a maximum and then decay slowly. This reflects the quick rise and slow decay of the inferred hidden states seen in Figures <xref ref-type="fig" rid="F2">2</xref> and <xref ref-type="fig" rid="F3">3</xref> (upper right panels). There is a slight reaction time benefit for neutral cues due to a temporal alerting effect. This was modeled by allowing neutral cues to induce a small rise in both the inferred hidden states. The simulated reaction times were taken as the time at which there was 80% confidence that the target was present. The simulated reaction times are shown to within an arbitrary constant (to accommodated unmodeled motor responses). The asymmetric difference between the cost for an invalid cue and the benefit for a valid cue is an emergent property of the simulations.</p></caption><graphic xlink:href="fnhum-04-00215-g005"/></fig><p>The speed-accuracy trade-off is a useful psychophysical function, which can also be interpreted in terms of relative accuracies at a fixed reaction time. In this example, at 360&#x02009;ms after the cue (about 50&#x02009;ms after the onset of the target), the posterior confidence about the presence of valid targets is about 98%, whereas it is only about 70% for invalid targets (Figure <xref ref-type="fig" rid="F4">4</xref>). The relative position and divergence of the speed-accuracy curves may provide a useful and quantitative link to empirical psychophysical data. In a subsequent paper, we will use the stimuli generated by Eq. <xref ref-type="disp-formula" rid="E20">20</xref> to elicit speed-accuracy performances from real subjects and use this performance to optimize the model and its parameters.</p></sec><sec><title>The electrophysiology of the Posner paradigm</title><p>In what follows, we attempt to explain the well characterized electrophysiological correlates of the Posner paradigm using simulated event-related activity evoked by target stimuli. Spatial cueing effects are expressed in the modulation of event-related potentials (ERPs) to valid and invalid cues (Mangun and Hillyard, <xref ref-type="bibr" rid="B84">1991</xref>; Eimer, <xref ref-type="bibr" rid="B41">1993</xref>; Perchet et al., <xref ref-type="bibr" rid="B98">2001</xref>). Generally, one sees an increase in P1 and N1 and a decrease in posterior P3 components in validly cued trials with respect to invalid ones. In other words, there is usually a validity-related enhancement of early components and an invalidity-related enhancement of late components. The P1 component is the earliest component showing attentional modulation and is considered to reflect attentional gain or the cost of attending to the wrong location (Luck et al., <xref ref-type="bibr" rid="B82">1990</xref>; Mangun and Hillyard, <xref ref-type="bibr" rid="B84">1991</xref>; Coull, <xref ref-type="bibr" rid="B25">1998</xref>). It is well known that the amplitude of the later P3 component is inversely related to the probability of stimuli (Donchin and Coles, <xref ref-type="bibr" rid="B38">1988</xref>). The anterior P3a is generally evoked by stimuli that deviate from expectations. Indeed, novel stimuli generate a higher-amplitude P3a component than deviant but repeated stimuli (Friedman et al., <xref ref-type="bibr" rid="B45">2001</xref>). The P3b is a late positive component with a parietal (posterior) distribution seen in oddball paradigms and is thought to represent a context-updating operation (Donchin and Coles, <xref ref-type="bibr" rid="B38">1988</xref>; Polich, <xref ref-type="bibr" rid="B100">2007</xref>). Increased P3 amplitudes during invalid trials, relative to valid trials, suggest that invalidly cued targets produce a novelty-like effect (P3a) and change the representation of probabilistic contingencies (P3b) or context (Vossel et al., <xref ref-type="bibr" rid="B134">2006</xref>; G&#x000f3;mez et al., <xref ref-type="bibr" rid="B55">2008</xref>). These hypotheses sit very comfortably with the formal scheme in this paper; in that sensory signals (prediction errors) evoked by valid targets will enjoy a selective gain, leading to enhanced early (P1 and N1) responses. Conversely, initial responses to invalid targets are suppressed until they revise the probabilistic context encoded by inferred hidden states. The prediction errors on the hidden states reflect (and drive) this revision and may contribute the later (P3) ERP components. The prediction errors on the hidden causes and states representing the content and context respectively are shown in Figure <xref ref-type="fig" rid="F6">6</xref>.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Simulated EEG data from our simulations (upper panels) and empirical EEG data (lower panel) from Mangun and Hillyard (<xref ref-type="bibr" rid="B84">1991</xref>)</bold>. The EEG traces were created from the prediction errors on the hidden causes (left) and states (right). The empirical data were recorded via EEG from the occipital cortex contralateral to the target (i.e., the cortex processing the target). The simulated data exhibits two important features of empirical studies: early in peristimulus time, stimulus-driven responses are greater for valid cues (upper left panel) relative to invalid cues. This is often attributed to a validity enhancement of early (e.g., N1) components. Conversely, later in peristimulus time, invalid responses are greater in amplitude. This can be related to novelty (and salience) responses usually associated with late waveform components (e.g., P3). In the simulations, this invalidity effect is explained simply by greater prediction errors on inferred hidden states encoding precision (upper right panel). It is these prediction errors that report a surprising or novel context, following the failure to predict invalidly cued stimuli in an optimal fashion.</p></caption><graphic xlink:href="fnhum-04-00215-g006"/></fig><p>Figure <xref ref-type="fig" rid="F6">6</xref> shows synthetic ERPs based on the simulations in Figures <xref ref-type="fig" rid="F2">2</xref> and <xref ref-type="fig" rid="F3">3</xref>. Here, we have made the simplifying assumption that electrophysiological signals represent the activity of superficial pyramidal cells (which we presume encode prediction error; Friston, <xref ref-type="bibr" rid="B48">2008</xref>). This means we can focus on the prediction error as a proxy for electrophysiological responses. The results in the top panels of Figure <xref ref-type="fig" rid="F6">6</xref> show the prediction errors on the sensory signals (<inline-formula><mml:math id="M76"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> &#x02013; left panel) and hidden states (<inline-formula><mml:math id="M77"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> &#x02013; right panel). The prediction errors for valid trials are shown as dotted lines and invalid trials as solid lines. These simulations show an early suppression of prediction error for an invalidly cued target, as its low precision fails to drive its representation to its veridical level. This violation of predictions causes prediction errors on the hidden states encoding context that are expressed later in peristimulus time and drive the hidden states to revise their conditional expectations (shown in Figures <xref ref-type="fig" rid="F2">2</xref> and <xref ref-type="fig" rid="F3">3</xref>). This double dissociation between validity effects in early and late peristimulus time is exactly the same as that observed by Mangun and Hillyard (<xref ref-type="bibr" rid="B84">1991</xref>). The empirical results of their ERP study are shown in the lower panel of Figure <xref ref-type="fig" rid="F6">6</xref> and are very similar to the simulations.</p></sec><sec><title>Summary</title><p>In summary, this section has applied the Bayes-optimal scheme established in the previous section to a minimal model of the Posner paradigm. This model provides a mechanistic if somewhat simplified explanation for some of the key psychophysical and electrophysiological aspects of the Posner effect, namely, validity effects on reaction times and the time course of these effects as stimulus onset asynchrony increases. Furthermore, the model exhibits an asymmetry in costs and benefits for invalid and valid trials respectively. Electrophysiologically, it suggests early attentional P1 enhancement can be attributed to a boosting or biasing of sensory signals (prediction errors) evoked by a target, while later P3 invalidity (cf, novelty) effects are mediated by prediction errors about the context in which targets appear.</p></sec></sec><sec><title>Simulating biased competition</title><p>In this final section, we revisit the simulations above but from the point of view of biased competition. Although the Posner paradigm considers a much greater spatial and temporal scale than the paradigms normally employed in a monkey electrophysiology, we can emulate similar phenomena by presenting both cued and non-cued targets simultaneously using the Posner model. We hoped to see a competitive interaction between stimuli that favored the cued target. Furthermore, we hoped to see responses to the unattended (invalid) target changed in the presence of an attended target. This is one of the hallmarks of biased competition and is usually attributed to lateral interactions among competing representations for stimuli, within a cell's receptive field (see <xref ref-type="sec" rid="s1">Attention, Biased Competition and the Posner Paradigm</xref>). Although our model is too simple to distinguish between stimuli presented inside and outside the classical receptive field (because we do not model the spatial support of sensory channels in this paper), we can assume that targets fall within the extraclassical receptive of field of units representing hidden causes. This is because the response to one target depends on the presence of the other, as we will see next.</p><p>Figure <xref ref-type="fig" rid="F7">7</xref> shows the results of presenting both stimuli simultaneously. Again the cue is in red, the valid target in green and the invalid (unattended) target in blue. It is immediately obvious that biased competition between the targets is profound, such that the response to the unattended target is about half of the response to the attended target. Furthermore, the conditional confidence about the unattended target is substantially less than that for the attended target (light and dark confidence tubes in the lower left panel). The lower right panel of Figure <xref ref-type="fig" rid="F7">7</xref> compares the conditional expectations and confidence intervals associated with the unattended (invalid) target presented with and without the attended (valid) target. The latter response is exactly the same as the data presented in the lower left of Figure <xref ref-type="fig" rid="F3">3</xref> simulating invalid cue responses. One can see that when the same stimulus is presented in conjunction with an attended target, its conditional expectation is attenuated by about 20% and the conditional confidence tubes are much wider (light with an attended distractor and dark without). In other words, the attended target has competed for attentional resources to subvert conditional confidence about the unattended target. This is despite the fact that both unattended targets were identical; they were just presented in a different context.</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>This figure uses the same format as Figures <xref ref-type="fig" rid="F2">2</xref> and <xref ref-type="fig" rid="F3">3</xref> but reports the results when both targets are presented simultaneously</bold>. The ensuing conditional responses can be compared with the responses in Figure <xref ref-type="fig" rid="F3">3</xref>, when the invalidly cued target was presented alone: when the valid target is also presented, it prevents the invalid target from reversing the precision bias established by the cue; i.e., it fails to capture attention resources. The lower right panel shows the conditional expectation and confidence regions for the invalid target, with and without the valid target, to show how the responses evoked are suppressed; i.e., biased competition.</p></caption><graphic xlink:href="fnhum-04-00215-g007"/></fig><p>This context is encoded by the expected hidden states and explains the biased competition for resources: in contrast with the hidden states inferred with the invalid target alone (see the equivalent panel in Figure <xref ref-type="fig" rid="F3">3</xref>) the partial reversal of contextual representations has been precluded by the presence of the valid target. This means that the invalid cue can no longer capture precision and consequently is never able to fully express itself, through precise prediction errors, on the conditional representation of its cause. It is this effect, and only this effect, that is needed to explain biased competition. Note that we have not needed to model lateral interactions or explicit competition among representations; competition emerges naturally in a Bayes-optimal fashion through the non-linear effects of precision encoded by the units representing context, where the influence of these units is mediated by top-down or lateral projections.</p><p>The results in Figure <xref ref-type="fig" rid="F7">7</xref> are strikingly similar to data obtained from electrophysiological studies. Figure <xref ref-type="fig" rid="F8">8</xref> (upper panel) shows the conditional expectations about valid (solid line) and invalid (dashed line) targets from Figure <xref ref-type="fig" rid="F7">7</xref>. The lower panel shows peristimulus histograms reported in Luck et al. (<xref ref-type="bibr" rid="B81">1997</xref>) following simultaneous presentation of two (effective and ineffective) stimuli averaged over V4 neurons that showed a significant attention effect. The solid line reports trials in which attention was directed to the effective stimulus (cf, responses to a valid target) and the dashed line when attention was directed to the ineffective stimulus (cf, responses to an invalid target). The quantitative agreement between these simulated and empirical responses is evident and speaks quantitatively to biased competition among stimuli.</p><fig id="F8" position="float"><label>Figure 8</label><caption><p><bold>This figure demonstrates how generalized predictive coding reproduces some quantitative aspects of biased competition</bold>. The simulation (upper panel) reproduces the conditional expectations in the previous figure about valid (solid line) and invalid (dashed line) targets, when presented simultaneously. These two responses resemble those reported in Luck et al. (<xref ref-type="bibr" rid="B81">1997</xref>). Lower panel: peristimulus histograms (over 20&#x02009;ms bins) redrawn from Luck et al. (<xref ref-type="bibr" rid="B81">1997</xref>), following simultaneous presentation of two (effective and ineffective) stimuli averaged over 29 V4 neurons that showed a significant attention effect. The solid line reports trials in which attention was directed to the effective stimulus (cf, responses to a valid target) and the dashed line when attention was directed to the ineffective stimulus (cf, responses to an invalid target). Note that the empirical data are non-negative spike counts, whereas the simulated activity represent firing rate deviations around baseline levels.</p></caption><graphic xlink:href="fnhum-04-00215-g008"/></fig><sec><title>Summary</title><p>Biased competition emerges naturally in Bayes-optimal schemes as a simple consequence of the fact that only one context can exist at a time. This unique aspect of context is encoded in the way that the representation of hidden states (context) modulates or distributes precision over sensory channels. Optimizing this representation leads to competition among stimuli to make the inferred context more consistent with their existence. This highlights the simplicity and usefulness of appealing to formal (Bayes-optimal) schemes, when trying to understand perception.</p></sec></sec></sec><sec sec-type="discussion"><title>Discussion</title><p>Our treatment of attention is one of many accounts that emphasize the role of probabilistic inference in sensory processing; including sensorimotor integration (Wolpert et al., <xref ref-type="bibr" rid="B140">1995</xref>; K&#x000f6;rding and Wolpert, <xref ref-type="bibr" rid="B78">2004</xref>), sensory integration (Jacobs, <xref ref-type="bibr" rid="B70">1999</xref>; Ernst and Banks, <xref ref-type="bibr" rid="B42">2002</xref>; Knill and Saunders, <xref ref-type="bibr" rid="B77">2003</xref>; Alais and Burr, <xref ref-type="bibr" rid="B2">2004</xref>), salience and value estimation (Trommershauser et al., <xref ref-type="bibr" rid="B131">2003b</xref>; Seydell et al., <xref ref-type="bibr" rid="B117">2008</xref>; Whiteley and Sahani, <xref ref-type="bibr" rid="B138">2008</xref>) and perception (Langer and Bulthoff, <xref ref-type="bibr" rid="B79">2001</xref>; Adams et al., <xref ref-type="bibr" rid="B1">2004</xref>). There have been some notable Bayesian accounts of attention using formal models (Rao, <xref ref-type="bibr" rid="B106">2005</xref>; Spratling, <xref ref-type="bibr" rid="B121">2008</xref>, <xref ref-type="bibr" rid="B122">2010</xref>). Others have tried to define statistical measures of saliency, i.e., that which draws our attention (Duncan and Humphreys, <xref ref-type="bibr" rid="B39">1989</xref>; Bruce and Tsotsos, <xref ref-type="bibr" rid="B15">2009</xref>; Itti and Baldi, <xref ref-type="bibr" rid="B69">2009</xref>). We now discuss these developments in the light of the more general free-energy formulation used in this paper.</p><p>The free-energy formulation is a generalization of information theoretic treatments that subsumes Bayesian schemes by assuming the brain is trying to optimize the evidence for its model of the world. This optimization involves changing the model to better account for sensory samples or by selectively sampling sensations that can be accounted for by the model (cf, perception and action). Attention can be viewed as a selective sampling of sensory data that have high-precision (signal to noise) in relation to the model's predictions. Crucially, the model is also trying to predict precision. It is this (state-dependent) prediction we associate with attention. In short, perception, attention and action are trying to suppress free-energy, which is an upper bound on (Shannon) surprise (or the negative log-evidence for the brain's model of the world). Under some simplifying assumptions, free-energy is just the amount of prediction error, which means free-energy minimization can be cast as predictive coding. So how does this relate to other formal treatments?</p><sec><title>Attention and surprise</title><p>Rao (<xref ref-type="bibr" rid="B106">2005</xref>) has introduced a compelling model of visual attention using Bayesian belief propagation. However, although consistent with Bayesian (free-energy) principles, belief propagation schemes rest on (discrete) representations of hidden causes and states, which are not compatible with the dimensionality of states in the real world (Friston, <xref ref-type="bibr" rid="B49">2009</xref>). Using a more descriptive approach, Itti and Baldi (<xref ref-type="bibr" rid="B68">2006</xref>; <xref ref-type="bibr" rid="B69">2009</xref>) proposed that many factors, which influence visual salience, can be integrated with prior expectations by calculating <italic>Bayesian surprise (</italic>Baldi and Itti, <xref ref-type="bibr" rid="B4">2010</xref><italic>)</italic>. This is (heuristically) related to another measure of saliency, proposed by Bruce and Tsotsos (<xref ref-type="bibr" rid="B15">2009</xref>), who suggest that visual searches are attracted to areas of the visual field which maximize the information sampled. Crucially, reducing free-energy or (Shannon) surprise increases Bayesian surprise and increases the changes in the conditional representations afforded by sensory information. This is because Bayesian surprise is the difference (Kullback&#x02013;Leibler divergence) between the posterior (conditional) and prior densities on hidden causes or states. This difference reports the change in the conditional density after sampling new information. It is also called <italic>complexity</italic> in the Bayesian model comparison literature. Free-energy can be expressed as complexity minus accuracy (Friston, <xref ref-type="bibr" rid="B49">2009</xref>). This means that minimizing (Shannon) surprise by updating conditional representations to increase accuracy (decrease prediction errors), necessarily entails an increase in complexity (Bayesian surprise). In short, increases in Bayesian surprise are necessarily associated with decreases in free-energy (they are the complexity cost of reducing prediction errors) but Bayesian surprise <italic>per se</italic> is not optimized in Bayes-optimal schemes.</p></sec><sec><title>Biased competition and predictive coding</title><p>It is becoming increasingly clear that estimates of the precision play an important role in sensory inference. Whiteley and Sahani (<xref ref-type="bibr" rid="B138">2008</xref>) demonstrated very neatly that the brain possesses (and uses) a model of sensory uncertainty (i.e., precision) in decision-making, and that this model is available even under intermittent feedback, showing that is estimated internally rather than learnt. Thinking of attention as optimizing representations of uncertainty or precision resolves any potential conflict between biased competition and predictive coding schemes: Spratling (<xref ref-type="bibr" rid="B121">2008</xref>) noted the potential difficulty in reconciling these two theories and proposed a variant of predictive coding, in which representations compete via negative feedback. Specifically, he showed that a particular implementation of the biased competition model, in which nodes compete via inhibition that targets the inputs to a cortical region, is mathematically equivalent to linear predictive coding. This scheme relies on a rather complex neural architecture and employs non-linear modifications to prevent cells from having a negative firing rate. These modifications are interesting and relate to important theories based on divisive normalization (Heeger, <xref ref-type="bibr" rid="B62">1993</xref>). This form of (divisive) predictive coding can explain a remarkable range of classical and extraclassical receptive field properties in V1 (see Spratling, <xref ref-type="bibr" rid="B122">2010</xref>).</p><p>The formulation in this paper reaffirms that there is no tension between biased competition and predictive coding: it demonstrates that the characteristic behaviors of biased competition emerge naturally under predictive coding. They key thing that reconciles these two theories is to realize that predictive coding can be generalized to cover both states and precisions and that (state-dependent) precision is itself optimized. This leads to non-linear interactions among states implicit in the precision-weighting of prediction errors and provides a simple explanation for attentional gain effects. It will be interesting to relate the ensuing bias or weighting of sensory signals (prediction errors) by precision to the divisive schemes above (e.g., Heeger, <xref ref-type="bibr" rid="B62">1993</xref>; Spratling, <xref ref-type="bibr" rid="B122">2010</xref>).</p></sec><sec><title>Baseline shifts and precision</title><p>In this paper, we have focussed on reaction time and event-related responses to targets. However, many electrophysiological and neuroimaging studies of attentional paradigms (e.g., Chelazzi et al., <xref ref-type="bibr" rid="B22">1993</xref>; Chawla et al., <xref ref-type="bibr" rid="B21">1999b</xref>; Kastner et al., <xref ref-type="bibr" rid="B75">1999</xref>; Stokes et al., <xref ref-type="bibr" rid="B124">2009</xref>) have demonstrated cue-related increases in the basal firing rate of cells, whose receptive fields correspond to the attended location. A non-invasive electrophysiological correlate of these baseline shifts is called the Contingent Negative Variation component (CNV), which follows a cue that furnishes information about subsequent (imperative) target stimuli (Walter et al., <xref ref-type="bibr" rid="B137">1964</xref>; Rockstroh et al., <xref ref-type="bibr" rid="B112">1982</xref>). Crucially, the cortical sources generating the CNV can include those responsible for processing the stimuli (G&#x000f3;mez et al., <xref ref-type="bibr" rid="B54">2001</xref>). These baseline shifts may be accounted for, in the computational scheme, by the dynamics of expected hidden states, shown in the top left panels of Figures <xref ref-type="fig" rid="F2">2</xref> and <xref ref-type="fig" rid="F3">3</xref>. These accumulate evidence from cues and represent changes in context that persist over time. It is possible that the activity of these representational units could contribute to the CNV or baseline shift directly. However, it is also possible that they could modulate baseline activity (caused by ambient sensory signals) in the prediction error-units they modulate. This would be consistent with baseline shifts seen with fMRI in retinotopically mapped areas of directed attention (e.g., Macaluso et al., <xref ref-type="bibr" rid="B83">2003</xref>), and the reduction in non-attended areas (Smith et al., <xref ref-type="bibr" rid="B119">2000</xref>). This suggests that baseline (endogenous) activity may be a quantitative proxy for the expected precision of sensory information in the corresponding sensory area (cf., Hesselmann et al., <xref ref-type="bibr" rid="B64">2008</xref>). This hypothesis was tested recently: using fMRI, Hesselmann et al. (<xref ref-type="bibr" rid="B65">2010</xref>) linked perceptual estimates of precision with baseline increases in activity; showing that baseline activity before a (subliminal) stimulus was correlated with the accuracy of deciding if the stimulus was present (and not whether the stimulus was present or absent). This means that baseline activity may reflect the inferred precision of sensory signals. Specifically, they found that neuronal activity in sensory areas (extrastriate visual and early auditory cortex) biases perceptual decisions toward correct inference and not toward a specific percept. They conclude: &#x0201c;In accord with predictive coding models and the free-energy principle, this observation suggests that cortical activity in sensory brain areas reflects the precision of prediction errors and not just the sensory evidence or prediction errors <italic>per se</italic>.&#x0201d;</p><p>The neurobiological (resp. computational) mechanisms that might underlie these effects tie several strands of evidence together rather neatly: as noted in the introduction the most plausible candidate for modulating activity-dependent (resp. state-dependent) synaptic gain (resp. precision) are fast synchronous interactions associated with attention (B&#x000f6;rgers et al., <xref ref-type="bibr" rid="B10">2005</xref>; Womelsdorf and Fries, <xref ref-type="bibr" rid="B141">2006</xref>; Fries et al., <xref ref-type="bibr" rid="B47">2008</xref>; Zeitler et al., <xref ref-type="bibr" rid="B147">2008</xref>). The associated increase in synchronous gain is necessarily accompanied by increased levels of population activity that are both supported by and support synchrony (Chawla et al., <xref ref-type="bibr" rid="B20">1999a</xref>; Salinas and Sejnowski, <xref ref-type="bibr" rid="B114">2001</xref>). These are manifest as high frequency (gamma) activity and elevated fMRI signals seen in attentional paradigms (Gruber et al., <xref ref-type="bibr" rid="B60">1999</xref>; Sokolov et al., <xref ref-type="bibr" rid="B120">1999</xref>; Steinmetz et al., <xref ref-type="bibr" rid="B123">2000</xref>; Bichot et al., <xref ref-type="bibr" rid="B9">2005</xref>; Pavlova et al., <xref ref-type="bibr" rid="B97">2006</xref>; Vidal et al., <xref ref-type="bibr" rid="B133">2006</xref>; Fries et al., <xref ref-type="bibr" rid="B47">2008</xref>).</p></sec><sec><title>Attention, gain and learning</title><p>In closing, we pre-empt a potentially interesting argument about the specificity of gain mechanisms and attention. The idea pursued in this paper is that attention corresponds to inference about uncertainty or precision and that this inference is encoded by dynamic changes in post-synaptic gain. However, non-linear (gain) post-synaptic responses are ubiquitous in the brain; so what is special about the non-linearities associated with attention? We suggest that attention is mediated by gain modulation of prediction error-units (forward or bottom-up information) in contradistinction to gain modulation of prediction units (backward, lateral or top-down information). In other words, non-linearities in the brain's generative model encoding context-sensitive expectations are distinct from non-linearities (gain) entailed by optimal recognition. The distinction may seem subtle but there is a fundamental difference between inferring the context-dependent contingencies and causes of sensations (perception) and their precision (attention). In this sense, there is an implicit distinction between inferring what is relevant for a task (as in classical attention tasks like dichotic listening) and the uncertainty about what is relevant. We have side-stepped this issue with the Posner task, because all cues are task relevant.</p><p>There is a final distinction that may be mechanistically important: we have focussed on activity-dependent optimization of gain but have not considered the (slower) learning of how and when this optimization should be deployed. For example, the latency of saccades to a target can be reduced if the target is more likely to appear on one side &#x02013; and this relationship can be learned in as few as 150 trials (Carpenter and Williams, <xref ref-type="bibr" rid="B18">1995</xref>; Anderson and Carpenter, <xref ref-type="bibr" rid="B3">2006</xref>; Brodersen et al., <xref ref-type="bibr" rid="B14">2008</xref>). This sort of learning corresponds to the optimization of the precision parameters in Eq. <xref ref-type="disp-formula" rid="E19">19</xref> and may involve modulatory neurotransmitters. We will pursue this elsewhere and try to relate this learning to the psychopharmacology of attention and related theories about uncertainty (e.g., Yu and Dayan, <xref ref-type="bibr" rid="B146">2005</xref>).</p></sec><sec><title>Conclusion</title><p>In this paper, we have tried to establish the face validity of optimizing the precision of sensory signals as an explanation for attention in perceptual inference. We started with an established scheme for perception based upon optimizing a free-energy bound on surprise or the log-evidence for a model of the world. Minimizing this bound, using gradient descent, furnishes recognition dynamics that are formally equivalent to evidence accumulation schemes. Under some simplifying assumptions, the free-energy reduces to prediction error and the scheme can be regarded as generalized predictive coding. The key thing that we have tried to demonstrate is that all the quantities required for making an inference have to be optimized. This includes the precisions that encode uncertainty or the amplitude of random fluctuations generating sensory information. By casting attention as inferring precision, we can explain several perspectives on attentional processing that fit comfortably with their putative neurobiological mechanisms. Furthermore, by considering how states of the world influence uncertainty, one arrives at a plausible architecture, in which conditional expectations about states modulate their own precision. This leads naturally to competition and other non-linear phenomena during perception. We have tried to illustrate these ideas in the context of a classical paradigm (the Posner paradigm) and relate the ensuing behavior to biased competition evident in electrophysiological responses recorded from awake, behaving monkeys. In future work, we will use the theoretical framework in this paper to model empirical psychophysical and electrophysiological data and pursue this hypothesis using formal model comparison.</p></sec></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ack><p>The Wellcome Trust funded this work. We would like to thank Marcia Bennett for helping prepare this manuscript. We are very grateful to Jon Driver and Kia Nobre for invaluable help in formulating these ideas.</p></ack><app-group><app id="A1"><title>Appendix</title><sec><title>Integrating the recognition dynamics (generalized filtering)</title><p>Generalized filtering (Friston et al., <xref ref-type="bibr" rid="B52">2010b</xref>) involves integrating the ordinary differential Eqs <xref ref-type="disp-formula" rid="E7">7</xref> and <xref ref-type="disp-formula" rid="E8">8</xref> to optimize the conditional means. We can simplify the numerics for hierarchical dynamic models by first collapsing over the hierarchy, then over generalized motion and finally over hidden causes and states: <disp-formula id="E21"><label>(A.1)</label><mml:math id="M78"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b7;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x022ee;</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This gives a simple form for the (Gibbs) energy that comprises a log-likelihood and prior <disp-formula id="E22"><label>(A.2)</label><mml:math id="M79"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>&#x02112;</mml:mtext><mml:mo>=</mml:mo><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003d5;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>|</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> with the following integration scheme <disp-formula id="E23"><label>(A.3)</label><mml:math id="M80"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x002d9;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:msup><mml:mover accent="true"><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mo>&#x003b8;</mml:mo></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mo>&#x003b3;</mml:mo></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext><mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>&#x02111;</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="script">D</mml:mi></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mi>I</mml:mi></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mi>I</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003ba;</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This system can be solved (integrated) using a local linearization (Ozaki, <xref ref-type="bibr" rid="B95">1992</xref>) with updates <inline-formula><mml:math id="M81"><mml:mrow><mml:mtext>&#x00394;</mml:mtext><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x00394;</mml:mtext><mml:mi>t</mml:mi><mml:mtext>&#x02111;</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>&#x02111;</mml:mtext><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002d9;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> over time steps &#x00394;<italic>t</italic>, where &#x1d575;(<italic>t</italic>) the filter's Jacobian. Note that we have omitted terms that mediate changes in the motion of state estimates due to changes in parameter estimates. This is because changes in parameter estimates are negligible at the time scale of changes in states. The requisite gradients (evaluated at the conditional expectation) are, with a slight abuse of notion when dealing with derivatives with respect to vectors <disp-formula id="E24"><label>(A.4)</label><mml:math id="M82"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mo>&#x003b3;</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x003a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a3;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mo>&#x003b3;</mml:mo></mml:msub><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mo>&#x003b8;</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x003a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mtext>&#x003bc;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mtext>&#x003b8;</mml:mtext></mml:msub><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The corresponding curvatures are (neglecting second-order terms involving states and parameters and second-order derivatives of the conditional entropy) <disp-formula id="E25"><label>(A.5)</label><mml:math id="M83"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x003a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x02248;</mml:mo><mml:msubsup><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mtext>&#x02131;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>&#x003a0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mtext>&#x003c0;</mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x000d7;</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x02297;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mtext>&#x003c0;</mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#x000d7;</mml:mo><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>&#x003c0;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Finally, the conditional precision and its derivatives are given by the curvature of the (Gibbs) energy <disp-formula id="E26"><label>(A.6)</label><mml:math id="M84"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mi mathvariant="script">C</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003bc;</mml:mo><mml:mo>&#x003bc;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b8;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mtext>&#x003b8;</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mtext>&#x02112;</mml:mtext><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mtext>&#x000a0;&#x000a0;</mml:mtext><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mtext>&#x003b8;</mml:mtext><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>3</mml:mn><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mtext>&#x003b8;</mml:mtext></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>&#x000a0;&#x000a0;</mml:mtext><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mo>&#x003b3;</mml:mo></mml:msub><mml:mo>&#x02248;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x003b3;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mtext>&#x003b8;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mover accent="true"><mml:mtext>&#x003a0;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo><mml:mo>&#x003b3;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mover accent="true"><mml:mtext>&#x003b5;</mml:mtext><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Note that we have simplified the numerics here by neglecting conditional dependencies between the precisions and the states or parameters. These equations may look complicated but can be evaluated automatically using numerical derivatives. All the simulations in this paper used just one routine &#x02013; <italic>spm_LAP.m</italic>. Demonstrations of this scheme are available as part of the SPM software (<uri xlink:type="simple" xlink:href="http://www.fil.ion.ion.ucl.ac.uk/spm;DEM_demo.m">http://www.fil.ion.ion.ucl.ac.uk/spm;DEM_demo.m</uri>) and reproduce the examples in the figures.</p></sec><sec><title>State-dependent noise and weber's law</title><p>Sensory signals are invariably registered as non-negative quantities (e.g., firing rates of photoreceptors). If we assume the sensory signals <italic>s</italic>&#x02009;&#x02248; ln&#x003c2; are an approximate log-transform of some non-negative variables &#x003c2;&#x02009;&#x02208; &#x1d57d;<sup>+</sup> sampled from a Poisson distribution with rate &#x003bb;, we have from Eq. <xref ref-type="disp-formula" rid="E9">9</xref> (and using a first-order Taylor expansion): <disp-formula id="E27"><label>(A.7)</label><mml:math id="M85"><mml:mtable><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>:</mml:mo><mml:mi>s</mml:mi><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mtext>&#x003bb;</mml:mtext><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>&#x003c2;</mml:mtext><mml:mo>&#x02212;</mml:mo><mml:mtext>&#x003bb;</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mtext>&#x003bb;</mml:mtext></mml:mfrac><mml:mo>&#x02248;</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mtext>&#x003c2;</mml:mtext><mml:mo>:</mml:mo><mml:mtext>&#x003c2;</mml:mtext><mml:mo>~</mml:mo><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mtext>&#x003bb;</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x021d2;</mml:mo><mml:mi>s</mml:mi><mml:mtext>~</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mtext>&#x003bb;</mml:mtext><mml:mo>,</mml:mo><mml:msup><mml:mtext>&#x003bb;</mml:mtext><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x021d2;</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mtext>&#x003bb;</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mtext>&#x003a3;</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mtext>&#x003bb;</mml:mtext><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This means that as the expected amplitude of the sensory input increases, <italic>f</italic><sup>(<italic>v</italic>)</sup>&#x02009;=&#x02009;ln&#x02009;&#x003bb;, so does its precision &#x003c0;<sup>(<italic>v</italic>)</sup>&#x02009;=&#x02009;&#x003bb;&#x02009;=&#x02009;exp(<italic>f</italic><sup>(<italic>v</italic>)</sup>).</p></sec></app></app-group><glossary id="G1"><title>Glossary of Terms</title><def-list><def-item><term>Bayesian surprise:</term><def><p>A measure of salience based on the (Kullback&#x02013;Leibler) divergence between the recognition and prior densities. It measures the information in the data that can be recognized.</p></def></def-item><def-item><term>Conditional density:</term><def><p>Conditional density or posterior density is the probability distribution of causes or model parameters, given some data; i.e., a probabilistic mapping from observed data (consequences) to causes.</p></def></def-item><def-item><term>(Kullback&#x02013;Leibler) Divergence:</term><def><p>Information divergence, information gain or relative entropy is a non-commutative measure of the difference between two probability distributions.</p></def></def-item><def-item><term>Empirical prior:</term><def><p>Priors that are induced by hierarchical models; they provide constraints on the recognition density is the usual way but depend on the data.</p></def></def-item><def-item><term>Entropy:</term><def><p>The average surprise of outcomes sampled from a probability distribution or density. A density with low entropy means, on average, the outcome is relatively predictable (certain).</p></def></def-item><def-item><term>Free-energy:</term><def><p>An information theory measure that bounds (is greater than) the surprise on sampling some data, given a generative model.</p></def></def-item><def-item><term>Generalized coordinates:</term><def><p>Generalized coordinates of motion cover the value of a variable, its motion, acceleration, jerk and higher orders of motion. A point in generalized coordinates corresponds to a path or trajectory over time.</p></def></def-item><def-item><term>Generative model:</term><def><p>Generative model or forward model is a probabilistic mapping from causes to observed consequences (data). It is usually specified in terms of the likelihood of getting some data given their causes (parameters of a model) and priors on the parameters.</p></def></def-item><def-item><term>Gradient descent:</term><def><p>An optimization scheme that finds a minimum of a function by changing its arguments in proportion to the negative of the gradient of the function at the current value.</p></def></def-item><def-item><term>Helmholtz (inference) machine:</term><def><p>Device or scheme that uses a generative model to furnish a recognition density. They learn hidden structure in data by optimizing the parameters of generative models.</p></def></def-item><def-item><term>Precision:</term><def><p>(In general statistical usage) means the inverse variance or dispersion of a random variable. The precision matrix of several variables is also called a concentration matrix. It quantifies the degree of certainty about the variables.</p></def></def-item><def-item><term>Prior:</term><def><p>The probability distribution or density on the causes of data that encode beliefs about those causes prior to observing the data.</p></def></def-item><def-item><term>Recognition density:</term><def><p>Recognition density or approximating conditional density is a probability distribution over the causes of data. It is the product of (approximate) inference or inverting a generative model. It is sometimes referred to as a proposal or ensemble density in machine learning.</p></def></def-item><def-item><term>Surprise:</term><def><p>Surprisal or self-information is the negative log-probability of an outcome. An improbable outcome is therefore surprising.</p></def></def-item><def-item><term>Stochastic:</term><def><p>The successive states of stochastic processes are governed by random effects.</p></def></def-item><def-item><term>Uncertainty:</term><def><p>A measure of unpredictability or expected surprise (cf, entropy). The uncertainly about a variable is often quantified with its variance (inverse precision).</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>W. J.</given-names></name><name><surname>Graf</surname><given-names>E. W.</given-names></name><name><surname>Ernst</surname><given-names>M. O.</given-names></name></person-group> (<year>2004</year>). <article-title>Experience can change the &#x02018;light-from-above&#x02019; prior</article-title>. <source>Nat. Neurosci.</source><volume>7</volume>, <fpage>1057</fpage>&#x02013;<lpage>1058</lpage><pub-id pub-id-type="pmid">15361877</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alais</surname><given-names>D.</given-names></name><name><surname>Burr</surname><given-names>D.</given-names></name></person-group> (<year>2004</year>). <article-title>The ventriloquist effect results from near-optimal bimodal integration</article-title>. <source>Curr. Biol.</source><volume>14</volume>, <fpage>257</fpage>&#x02013;<lpage>262</lpage><pub-id pub-id-type="pmid">14761661</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>A. J.</given-names></name><name><surname>Carpenter</surname><given-names>R. H. S.</given-names></name></person-group> (<year>2006</year>). <article-title>Changes in expectation consequent on experience, modeled by a simple, forgetful neural circuit</article-title>. <source>J. Vis.</source><volume>6</volume>, <fpage>822</fpage>&#x02013;<lpage>835</lpage><pub-id pub-id-type="pmid">16895461</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldi</surname><given-names>P.</given-names></name><name><surname>Itti</surname><given-names>L.</given-names></name></person-group> (<year>2010</year>). <article-title>Of bits and wows: a Bayesian theory of surprise with applications to attention</article-title>. <source>Neural Netw.</source><volume>23</volume>, <fpage>649</fpage>&#x02013;<lpage>666</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2009.12.007</pub-id><pub-id pub-id-type="pmid">20080025</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ballard</surname><given-names>D. H.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name><name><surname>Sejnowski</surname><given-names>T. J.</given-names></name></person-group> (<year>1983</year>). <article-title>Parallel visual computation</article-title>. <source>Nature</source><volume>306</volume>, <fpage>21</fpage>&#x02013;<lpage>26</lpage><pub-id pub-id-type="doi">10.1038/306021a0</pub-id><pub-id pub-id-type="pmid">6633656</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartolomeo</surname><given-names>P.</given-names></name><name><surname>Caroline Decaix</surname><given-names>C.</given-names></name><name><surname>Si&#x000e9;roff</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>The phenomenology of endogenous orienting</article-title>. <source>Conscious. Cogn.</source><volume>16</volume>, <fpage>144</fpage>&#x02013;<lpage>161</lpage><pub-id pub-id-type="pmid">16527491</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauer</surname><given-names>F.</given-names></name><name><surname>Cheadle</surname><given-names>S. W.</given-names></name><name><surname>Parton</surname><given-names>A.</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>H. J.</given-names></name><name><surname>Usher</surname><given-names>M.</given-names></name></person-group> (<year>2009</year>). <article-title>Gamma flicker triggers attentional selection without awareness</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>106</volume>, <fpage>1666</fpage>&#x02013;<lpage>1671</lpage><pub-id pub-id-type="pmid">19124766</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname><given-names>D. M.</given-names></name><name><surname>Kastner</surname><given-names>S.</given-names></name></person-group> (<year>2005</year>). <article-title>Stimulus context modulates competition in human extrastriate cortex</article-title>. <source>Nat. Neurosci.</source><volume>8</volume>, <fpage>1110</fpage>&#x02013;<lpage>1116</lpage><pub-id pub-id-type="pmid">16007082</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bichot</surname><given-names>N. P.</given-names></name><name><surname>Rossi</surname><given-names>A. F.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>2005</year>). <article-title>Parallel and serial neural mechanisms for visual search in macaque area V4</article-title>. <source>Science</source><volume>308</volume>, <fpage>529</fpage>&#x02013;<lpage>534</lpage><pub-id pub-id-type="doi">10.1126/science.1109676</pub-id><pub-id pub-id-type="pmid">15845848</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>B&#x000f6;rgers</surname><given-names>C.</given-names></name><name><surname>Epstein</surname><given-names>S.</given-names></name><name><surname>Kopell</surname><given-names>N. J.</given-names></name></person-group> (<year>2005</year>). <article-title>Background gamma rhythmicity and attention in cortical local circuits: a computational study</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source><volume>102</volume>, <fpage>7002</fpage>&#x02013;<lpage>7007</lpage><pub-id pub-id-type="pmid">15870189</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broadbent</surname><given-names>D. E.</given-names></name></person-group> (<year>1952a</year>). <article-title>Listening to one of two synchronous messages</article-title>. <source>J. Exp. Psychol.</source><volume>44</volume>, <fpage>51</fpage>&#x02013;<lpage>55</lpage><pub-id pub-id-type="doi">10.1037/h0056491</pub-id><pub-id pub-id-type="pmid">14955590</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broadbent</surname><given-names>D. E.</given-names></name></person-group> (<year>1952b</year>). <article-title>Failures of attention in selective listening</article-title>. <source>J. Exp. Psychol.</source><volume>44</volume>, <fpage>428</fpage>&#x02013;<lpage>433</lpage><pub-id pub-id-type="doi">10.1037/h0057163</pub-id><pub-id pub-id-type="pmid">13000090</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Broadbent</surname><given-names>D. E.</given-names></name></person-group> (<year>1958</year>). <article-title>Perception and Communication</article-title>. <publisher-loc>New York</publisher-loc>: <publisher-name>Pergamon Press</publisher-name><pub-id pub-id-type="doi">10.1037/10037-003</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brodersen</surname><given-names>K. H.</given-names></name><name><surname>Penny</surname><given-names>W. D.</given-names></name><name><surname>Harrison</surname><given-names>L. M.</given-names></name><name><surname>Daunizeau</surname><given-names>J.</given-names></name><name><surname>Ruff</surname><given-names>C. C.</given-names></name><name><surname>Duzel</surname><given-names>E.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Stephan</surname><given-names>K. E.</given-names></name></person-group> (<year>2008</year>). <article-title>Integrated Bayesian models of learning and decision making for saccadic eye movements</article-title>. <source>Neural Netw.</source><volume>21</volume>, <fpage>1247</fpage>&#x02013;<lpage>1260</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2008.08.007</pub-id><pub-id pub-id-type="pmid">18835129</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruce</surname><given-names>N. D.</given-names></name><name><surname>Tsotsos</surname><given-names>J. K.</given-names></name></person-group> (<year>2009</year>). <article-title>Saliency, attention, and visual search: an information theoretic approach</article-title>. <source>J. Vis.</source><volume>9</volume>, <fpage>1</fpage>&#x02013;<lpage>24</lpage><pub-id pub-id-type="pmid">19757944</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buhl</surname><given-names>E. H.</given-names></name><name><surname>Tam&#x000e1;s</surname><given-names>G.</given-names></name><name><surname>Fisahn</surname><given-names>A.</given-names></name></person-group> (<year>1998</year>). <article-title>Cholinergic activation and tonic excitation induce persistent gamma oscillations in mouse somatosensory cortex in vitro</article-title>. <source>J. Physiol.</source><volume>513</volume>, <fpage>117</fpage>&#x02013;<lpage>126</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7793.1998.117by.x</pub-id><pub-id pub-id-type="pmid">9782163</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buia</surname><given-names>C.</given-names></name><name><surname>Tiesinga</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>). <article-title>Attentional modulation of firing rate and synchrony in a model cortical network</article-title>. <source>J. Comput. Neurosci.</source><volume>20</volume>, <fpage>247</fpage>&#x02013;<lpage>264</lpage><pub-id pub-id-type="pmid">16683206</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname><given-names>R. H. S.</given-names></name><name><surname>Williams</surname><given-names>M. L.</given-names></name></person-group> (<year>1995</year>). <article-title>Neural computation of log likelihood in control of saccadic eye movements</article-title>. <source>Nature</source><volume>377</volume>, <fpage>59</fpage>&#x02013;<lpage>62</lpage><pub-id pub-id-type="doi">10.1038/377059a0</pub-id><pub-id pub-id-type="pmid">7659161</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cave</surname><given-names>C. R.</given-names></name><name><surname>Bichot</surname><given-names>N. P.</given-names></name></person-group> (<year>1999</year>). <article-title>Visuospatial attention: beyond a spotlight model</article-title>. <source>Psychon. Bull. Rev.</source><volume>6</volume>, <fpage>204</fpage>&#x02013;<lpage>223</lpage><pub-id pub-id-type="pmid">12199208</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chawla</surname><given-names>D.</given-names></name><name><surname>Lumer</surname><given-names>E. D.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>1999a</year>). <article-title>The relationship between synchronization among neuronal populations and their mean activity levels</article-title>. <source>Neural Comput.</source><volume>11</volume>, <fpage>1389</fpage>&#x02013;<lpage>1411</lpage><pub-id pub-id-type="doi">10.1162/089976699300016287</pub-id><pub-id pub-id-type="pmid">10423500</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chawla</surname><given-names>D.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>1999b</year>). <article-title>The physiological basis of attentional modulation in extrastriate visual areas</article-title>. <source>Nat. Neurosci.</source><volume>2</volume>, <fpage>671</fpage>&#x02013;<lpage>676</lpage><pub-id pub-id-type="doi">10.1038/10230</pub-id><pub-id pub-id-type="pmid">10404202</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chelazzi</surname><given-names>L.</given-names></name><name><surname>Miller</surname><given-names>E. K.</given-names></name><name><surname>Duncan</surname><given-names>J.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1993</year>). <article-title>A neural basis for visual search in inferior temporal cortex</article-title>. <source>Nature</source><volume>363</volume>, <fpage>345</fpage>&#x02013;<lpage>347</lpage><pub-id pub-id-type="doi">10.1038/363345a0</pub-id><pub-id pub-id-type="pmid">8497317</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chikkerur</surname><given-names>S.</given-names></name><name><surname>Serre</surname><given-names>T.</given-names></name><name><surname>Tan</surname><given-names>C.</given-names></name><name><surname>Poggio</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>What and where: a Bayesian inference theory of attention</article-title>. <source>Vision Res</source>. <volume>50</volume>, <fpage>2223</fpage>&#x02013;<lpage>2247</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.05.013</pub-id><pub-id pub-id-type="pmid">20034510</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>C. R.</given-names></name><name><surname>Geffen</surname><given-names>G. M.</given-names></name><name><surname>Geffen</surname><given-names>L. B.</given-names></name></person-group> (<year>1989</year>). <article-title>Catecholamines and the covert orientation of attention in humans</article-title>. <source>Neuropsychologia</source><volume>27</volume>, <fpage>131</fpage>&#x02013;<lpage>139</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(89)90166-8</pub-id><pub-id pub-id-type="pmid">2538773</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coull</surname><given-names>J. T.</given-names></name></person-group> (<year>1998</year>). <article-title>Neural correlates of attention and arousal: insights from electrophysiology, functional neuroimaging and psychopharmacology</article-title>. <source>Prog. Neurobiol.</source><volume>55</volume>, <fpage>343</fpage>&#x02013;<lpage>361</lpage><pub-id pub-id-type="pmid">9654384</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crick</surname><given-names>F.</given-names></name></person-group> (<year>1984</year>). <article-title>Function of the thalamic reticular complex: the searchlight hypothesis</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>81</volume>, <fpage>4586</fpage>&#x02013;<lpage>4590</lpage><pub-id pub-id-type="pmid">6589612</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalley</surname><given-names>J. W.</given-names></name><name><surname>McGaughy</surname><given-names>J.</given-names></name><name><surname>O'Connell</surname><given-names>M. T.</given-names></name><name><surname>Cardinal</surname><given-names>R. N.</given-names></name><name><surname>Levita</surname><given-names>L.</given-names></name><name><surname>Robbins</surname><given-names>T. W.</given-names></name></person-group> (<year>2001</year>). <article-title>Distinct changes in cortical acetylcholine and noradrenaline efflux during contingent and noncontingent performance of a visual attentional task</article-title>. <source>J. Neurosci.</source><volume>21</volume>, <fpage>4908</fpage>&#x02013;<lpage>4914</lpage><pub-id pub-id-type="pmid">11425918</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daunizeau</surname><given-names>J.</given-names></name><name><surname>David</surname><given-names>O.</given-names></name><name><surname>Stephan</surname><given-names>K. E.</given-names></name></person-group> (<year>2009</year>). <article-title>Dynamic causal modelling: a critical review of the biophysical and statistical foundations</article-title>. <source>Neuroimage</source> [Epub ahead of print].<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.11.062</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>M. C.</given-names></name><name><surname>Marrocco</surname><given-names>R. T.</given-names></name></person-group> (<year>2000</year>). <article-title>Local infusion of scopolamine into intraparietal cortex slows covert orienting in rhesus monkeys</article-title>. <source>J. Neurophysiol.</source><volume>83</volume>, <fpage>1536</fpage>&#x02013;<lpage>1549</lpage><pub-id pub-id-type="pmid">10712478</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name><name><surname>Neal</surname><given-names>R. M.</given-names></name></person-group> (<year>1995</year>). <article-title>The Helmholtz machine</article-title>. <source>Neural Comput.</source><volume>7</volume>, <fpage>889</fpage>&#x02013;<lpage>904</lpage><pub-id pub-id-type="doi">10.1162/neco.1995.7.5.889</pub-id><pub-id pub-id-type="pmid">7584891</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decaix</surname><given-names>C.</given-names></name><name><surname>Si&#x000e9;roff</surname><given-names>E.</given-names></name><name><surname>Bartolomeo</surname><given-names>P.</given-names></name></person-group> (<year>2002</year>). <article-title>How voluntary is &#x02018;voluntary&#x02019; orienting of attention?</article-title><source>Cortex</source><volume>38</volume>, <fpage>841</fpage>&#x02013;<lpage>845</lpage><pub-id pub-id-type="doi">10.1016/S0010-9452(08)70053-4</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deco</surname><given-names>G.</given-names></name><name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>2005</year>). <article-title>Neurodynamics of biased competition and cooperation for attention: a model with spiking neurons</article-title>. <source>J. Neurophysiol.</source><volume>94</volume>, <fpage>295</fpage>&#x02013;<lpage>313</lpage><pub-id pub-id-type="doi">10.1152/jn.01095.2004</pub-id><pub-id pub-id-type="pmid">15703227</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1996</year>). <article-title>Neural mechanisms for visual memory and their role in attention</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>93</volume>, <fpage>13494</fpage>&#x02013;<lpage>13499</lpage><pub-id pub-id-type="pmid">8942962</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1998</year>). <article-title>Visual attention mediated by biased competition in extrastriate visual cortex</article-title>. <source>Philos. Trans. R. Soc. Lond. B</source><volume>353</volume>, <fpage>1245</fpage>&#x02013;<lpage>1255</lpage><pub-id pub-id-type="pmid">9770219</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Duncan</surname><given-names>J.</given-names></name></person-group> (<year>1995</year>). <article-title>Neural mechanisms of selective visual attention</article-title>. <source>Annu. Rev. Neurosci.</source><volume>18</volume>, <fpage>193</fpage>&#x02013;<lpage>222</lpage><pub-id pub-id-type="pmid">7605061</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Gross</surname><given-names>C. G.</given-names></name></person-group> (<year>1979</year>). <article-title>Visual areas in the temporal cortex of the macaque</article-title>. <source>Brain Res.</source><volume>178</volume>, <fpage>363</fpage>&#x02013;<lpage>380</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(79)90699-1</pub-id><pub-id pub-id-type="pmid">116712</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deutsch</surname><given-names>J. A.</given-names></name><name><surname>Deutsch</surname><given-names>D.</given-names></name></person-group> (<year>1963</year>). <article-title>Attention: some theoretical considerations</article-title>. <source>Psychol. Rev.</source><volume>70</volume>, <fpage>80</fpage>&#x02013;<lpage>90</lpage><pub-id pub-id-type="pmid">14027390</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donchin</surname><given-names>E.</given-names></name><name><surname>Coles</surname><given-names>M. G. H.</given-names></name></person-group> (<year>1988</year>). <article-title>Is the P300 component a manifestation of context updating?</article-title><source>Behav Brain Sci.</source><volume>11</volume>, <fpage>355</fpage>&#x02013;<lpage>372</lpage><pub-id pub-id-type="doi">10.1017/S0140525X00058027</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>J.</given-names></name><name><surname>Humphreys</surname><given-names>G. W.</given-names></name></person-group> (<year>1989</year>). <article-title>Visual search and stimulus similarity</article-title>. <source>Psychol. Rev.</source><volume>96</volume>, <fpage>433</fpage>&#x02013;<lpage>458</lpage><pub-id pub-id-type="pmid">2756067</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>M. P.</given-names></name><name><surname>Shimozaki</surname><given-names>S. S.</given-names></name><name><surname>Abbey</surname><given-names>C. K.</given-names></name></person-group> (<year>2002</year>). <article-title>The footprints of visual attention in the Posner cueing paradigm revealed by classification images</article-title>. <source>J. Vis.</source><volume>2</volume>, <fpage>25</fpage>&#x02013;<lpage>45</lpage><pub-id pub-id-type="pmid">12678595</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eimer</surname><given-names>M.</given-names></name></person-group> (<year>1993</year>). <article-title>Spatial cueing, sensory gating and selective response preparation: an ERP study on visuo-spatial orienting</article-title>. <source>Electroencephalogr. Clin. Neurophysiol.</source><volume>88</volume>, <fpage>408</fpage>&#x02013;<lpage>420</lpage><pub-id pub-id-type="pmid">7691565</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ernst</surname><given-names>M. O.</given-names></name><name><surname>Banks</surname><given-names>M. S.</given-names></name></person-group> (<year>2002</year>). <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source><volume>415</volume>, <fpage>429</fpage>&#x02013;<lpage>433</lpage><pub-id pub-id-type="doi">10.1038/415429a</pub-id><pub-id pub-id-type="pmid">11807554</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandez-Duque</surname><given-names>D.</given-names></name><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>1997</year>). <article-title>Relating the mechanisms of orienting and alerting</article-title>. <source>Neuropsychologia</source><volume>35</volume>, <fpage>477</fpage>&#x02013;<lpage>486</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(96)00103-0</pub-id><pub-id pub-id-type="pmid">9106276</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Formankiewicz</surname><given-names>M. A.</given-names></name><name><surname>Mollon</surname><given-names>J. D.</given-names></name></person-group> (<year>2009</year>). <article-title>The psychophysics of detecting binocular discrepancies of luminance</article-title>. <source>Vision Res.</source><volume>49</volume>, <fpage>1929</fpage>&#x02013;<lpage>1938</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2009.05.001</pub-id><pub-id pub-id-type="pmid">19460400</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>D.</given-names></name><name><surname>Cycowicz</surname><given-names>Y. M.</given-names></name><name><surname>Gaeta</surname><given-names>H.</given-names></name></person-group> (<year>2001</year>). <article-title>The novelty P3: an event-related brain potential (ERP) sign of the brain's evaluation of novelty</article-title>. <source>Neurosci. Biobehav. Rev.</source><volume>25</volume>, <fpage>355</fpage>&#x02013;<lpage>373</lpage><pub-id pub-id-type="pmid">11445140</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>A mechanism for cognitive dynamics: neuronal communication through neuronal coherence</article-title>. <source>Trends Cogn. Sci.</source><volume>9</volume>, <fpage>474</fpage>&#x02013;<lpage>480</lpage><pub-id pub-id-type="pmid">16150631</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname><given-names>P.</given-names></name><name><surname>Womelsdorf</surname><given-names>T.</given-names></name><name><surname>Oostenveld</surname><given-names>R.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>The effects of visual stimulation and selective visual attention on rhythmic neuronal synchronization in macaque area V4</article-title>. <source>J. Neurosci.</source><volume>28</volume>, <fpage>4823</fpage>&#x02013;<lpage>4835</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4499-07.2008</pub-id><pub-id pub-id-type="pmid">18448659</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Hierarchical models in the brain</article-title>. <source>PLoS Comput. Biol.</source><volume>4</volume>: <fpage>e1000211</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000211</pub-id><pub-id pub-id-type="pmid">18989391</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name></person-group> (<year>2009</year>). <article-title>The free-energy principle: a rough guide to the brain?</article-title><source>Trends Cogn. Sci.</source><volume>13</volume>, <fpage>293</fpage>&#x02013;<lpage>301</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.04.005</pub-id><pub-id pub-id-type="pmid">19559644</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name><name><surname>Kiebel</surname><given-names>S.</given-names></name></person-group> (<year>2009</year>). <article-title>Predictive coding under the free-energy principle</article-title>. <source>Philos. Trans. R. Soc. Lond. B Biol. Sci.</source><volume>364</volume>, <fpage>1211</fpage>&#x02013;<lpage>1221</lpage><pub-id pub-id-type="pmid">19528002</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Daunizeau</surname><given-names>J.</given-names></name><name><surname>Kilner</surname><given-names>J.</given-names></name><name><surname>Kiebel</surname><given-names>S. J.</given-names></name></person-group> (<year>2010a</year>). <article-title>Action and behavior: a free-energy formulation</article-title>. <source>Biol. Cybern.</source><volume>102</volume>, <fpage>227</fpage>&#x02013;<lpage>260</lpage><pub-id pub-id-type="doi">10.1007/s00422-010-0364-z</pub-id><pub-id pub-id-type="pmid">20148260</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name><name><surname>Stephan</surname><given-names>K. E.</given-names></name><name><surname>Li</surname><given-names>B.</given-names></name><name><surname>Daunizeau</surname><given-names>J.</given-names></name></person-group> (<year>2010b</year>). <article-title>Generalised filtering</article-title>. <source>Math. Probl. Eng.</source> 2010, Article ID 621670.<pub-id pub-id-type="doi">10.1155/2010/621670</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fr&#x000fc;nd</surname><given-names>I.</given-names></name><name><surname>Busch</surname><given-names>N. A.</given-names></name><name><surname>Schadow</surname><given-names>J.</given-names></name><name><surname>K&#x000f6;rner</surname><given-names>U.</given-names></name><name><surname>Herrmann</surname><given-names>C. S.</given-names></name></person-group> (<year>2007</year>). <article-title>From perception to action: phase-locked gamma oscillations correlate with reaction times in a speeded response task</article-title>. <source>BMC Neurosci.</source><volume>8</volume>, <fpage>27</fpage><pub-id pub-id-type="doi">10.1186/1471-2202-8-27</pub-id><pub-id pub-id-type="pmid">17439642</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f3;mez</surname><given-names>C. M.</given-names></name><name><surname>Delinte</surname><given-names>A.</given-names></name><name><surname>Vaquero</surname><given-names>E.</given-names></name><name><surname>Cardoso</surname><given-names>M. J.</given-names></name><name><surname>Vazquez</surname><given-names>M.</given-names></name><name><surname>Crommelynck</surname><given-names>M.</given-names></name><name><surname>Roucoux</surname><given-names>A.</given-names></name></person-group> (<year>2001</year>). <article-title>Current source density analysis of CNV during temporal gap paradigm</article-title>. <source>Brain Topogr.</source><volume>13</volume>, <fpage>149</fpage>&#x02013;<lpage>159</lpage><pub-id pub-id-type="doi">10.1023/A:1007816201345</pub-id><pub-id pub-id-type="pmid">11302395</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f3;mez</surname><given-names>C. M.</given-names></name><name><surname>Flores</surname><given-names>A.</given-names></name><name><surname>Digiacomo</surname><given-names>M. R.</given-names></name><name><surname>Ledesma</surname><given-names>A.</given-names></name><name><surname>Gonz&#x000e1;lez-Rosa</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>P3a and P3b components associated to the neurocognitive evaluation of invalidly cued targets</article-title>. <source>Neurosci. Lett</source>. <volume>430</volume>, <fpage>181</fpage>&#x02013;<lpage>185</lpage><pub-id pub-id-type="pmid">18063304</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>I. E.</given-names></name></person-group> (<year>1967</year>). <article-title>Stimulus probability and simple reaction time</article-title>. <source>Nature</source><volume>215</volume>, <fpage>895</fpage>&#x02013;<lpage>896</lpage><pub-id pub-id-type="doi">10.1038/215895a0</pub-id><pub-id pub-id-type="pmid">6049759</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregory</surname><given-names>R. L.</given-names></name></person-group> (<year>1968</year>). <article-title>Perceptual illusions and brain models</article-title>. <source>Proc. R. Soc. Lond. B</source><volume>171</volume>, <fpage>179</fpage>&#x02013;<lpage>196</lpage></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregory</surname><given-names>R. L.</given-names></name></person-group> (<year>1980</year>). <article-title>Perceptions as hypotheses</article-title>. <source>Philos. Trans. R. Soc. Lond. B</source><volume>290</volume>, <fpage>181</fpage>&#x02013;<lpage>197</lpage><pub-id pub-id-type="pmid">6106237</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>C. G.</given-names></name><name><surname>Rocha-Miranda</surname><given-names>C. E.</given-names></name><name><surname>Bender</surname><given-names>D. B.</given-names></name></person-group> (<year>1972</year>). <article-title>Visual properties of neurons in inferotemporal cortex of the macaque</article-title>. <source>J. Neurophysiol.</source><volume>35</volume>, <fpage>96</fpage>&#x02013;<lpage>111</lpage><pub-id pub-id-type="pmid">4621506</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruber</surname><given-names>T.</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>M. M.</given-names></name><name><surname>Keil</surname><given-names>A.</given-names></name><name><surname>Elbert</surname><given-names>T.</given-names></name></person-group> (<year>1999</year>). <article-title>Selective visual-spatial attention alters induced gamma band responses in the human EEG</article-title>. <source>Clin. Neurophysiol</source>. <volume>110</volume>, <fpage>2074</fpage>&#x02013;<lpage>2085</lpage><pub-id pub-id-type="doi">10.1016/S1388-2457(99)00176-5</pub-id><pub-id pub-id-type="pmid">10616112</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>M. E.</given-names></name><name><surname>Giocomo</surname><given-names>L. M.</given-names></name></person-group> (<year>2006</year>). <article-title>Cholinergic modulation of cortical function</article-title>. <source>J. Mol. Neurosci.</source><volume>30</volume>, <fpage>133</fpage>&#x02013;<lpage>135</lpage><pub-id pub-id-type="pmid">17192659</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>D. J.</given-names></name></person-group> (<year>1993</year>). <article-title>Modeling simple-cell direction selectivity with normalized, half-squared, linear operators</article-title>. <source>J. Neurophysiol.</source><volume>70</volume>, <fpage>1885</fpage>&#x02013;<lpage>1898</lpage><pub-id pub-id-type="pmid">8294961</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrero</surname><given-names>J. L.</given-names></name><name><surname>Roberts</surname><given-names>M. J.</given-names></name><name><surname>Delicato</surname><given-names>L. S.</given-names></name><name><surname>Gieselmann</surname><given-names>M. A.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name><name><surname>Thiele</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Acetylcholine contributes through muscarinic receptors to attentional modulation in V1</article-title>. <source>Nature</source><volume>454</volume>, <fpage>1110</fpage>&#x02013;<lpage>1114</lpage><pub-id pub-id-type="doi">10.1038/nature07141</pub-id><pub-id pub-id-type="pmid">18633352</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesselmann</surname><given-names>G.</given-names></name><name><surname>Kell</surname><given-names>C. A.</given-names></name><name><surname>Kleinschmidt</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Ongoing activity fluctuations in hMT+ bias the perception of coherent visual motion</article-title>. <source>J. Neurosci.</source><volume>28</volume>, <fpage>14481</fpage>&#x02013;<lpage>14485</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4398-08.2008</pub-id><pub-id pub-id-type="pmid">19118182</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesselmann</surname><given-names>G.</given-names></name><name><surname>Sadaghiani</surname><given-names>S.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Kleinschmidt</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>Predictive coding or evidence accumulation? False inference and neuronal fluctuations</article-title>. <source>PLoS ONE</source><volume>5</volume>, <fpage>e9926</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0009926</pub-id><pub-id pub-id-type="pmid">20369004</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirayama</surname><given-names>J.</given-names></name><name><surname>Yoshimoto</surname><given-names>J.</given-names></name><name><surname>Ishii</surname><given-names>S.</given-names></name></person-group> (<year>2004</year>). <article-title>Bayesian representation learning in the cortex regulated by acetylcholine</article-title>. <source>Neural Netw</source>. <volume>17</volume>, <fpage>1391</fpage>&#x02013;<lpage>1400</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2004.06.006</pub-id><pub-id pub-id-type="pmid">15541942</pub-id></mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hommel</surname><given-names>B.</given-names></name><name><surname>Pratt</surname><given-names>J.</given-names></name><name><surname>Colzato</surname><given-names>L.</given-names></name><name><surname>Godijn</surname><given-names>R.</given-names></name></person-group> (<year>2001</year>). <article-title>Symbolic control of visual attention</article-title>. <source>Psychol. Sci.</source><volume>12</volume>, <fpage>360</fpage>&#x02013;<lpage>365</lpage><pub-id pub-id-type="pmid">11554667</pub-id></mixed-citation></ref><ref id="B68"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L.</given-names></name><name><surname>Baldi</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>). <article-title>&#x0201c;Bayesian surprise attracts human attention,&#x0201d;</article-title> in <source>Advances in Neural Information Processing Systems</source>, Vol.<volume>18</volume>, eds <person-group person-group-type="editor"><name><surname>Weiss</surname><given-names>Y.</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B.</given-names></name><name><surname>Platt</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>1</fpage>&#x02013;<lpage>8</lpage></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L.</given-names></name><name><surname>Baldi</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>Bayesian surprise attracts human attention</article-title>. <source>Vision Res.</source><volume>49</volume>, <fpage>1295</fpage>&#x02013;<lpage>1306</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.09.007</pub-id><pub-id pub-id-type="pmid">18834898</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>R. A.</given-names></name></person-group> (<year>1999</year>). <article-title>Optimal integration of texture and motion cues to depth</article-title>. <source>Vision Res.</source><volume>39</volume>, <fpage>3621</fpage>&#x02013;<lpage>3629</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(99)00088-7</pub-id><pub-id pub-id-type="pmid">10746132</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>W.</given-names></name></person-group> (<year>1890</year>). <source>The Principles of Psychology</source>, Vol.<volume>1</volume> <publisher-loc>New York</publisher-loc>: <publisher-name>Henry Holt</publisher-name>, <fpage>403</fpage>&#x02013;<lpage>404</lpage></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaramillo</surname><given-names>S.</given-names></name><name><surname>Pearlmutter</surname><given-names>B. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Optimal coding predicts attentional modulation of activity in neural systems</article-title>. <source>Neural Comput.</source><volume>19</volume>, <fpage>1295</fpage>&#x02013;<lpage>1312</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.5.1295</pub-id><pub-id pub-id-type="pmid">17381267</pub-id></mixed-citation></ref><ref id="B73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S.</given-names></name><name><surname>De Weerd</surname><given-names>P.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Ungerleider</surname><given-names>L. G.</given-names></name></person-group> (<year>1998</year>). <article-title>Mechanisms of directed attention in the human extrastriate cortex as revealed by functional MRI</article-title>. <source>Science</source><volume>282</volume>, <fpage>108</fpage>&#x02013;<lpage>111</lpage><pub-id pub-id-type="doi">10.1126/science.282.5386.108</pub-id><pub-id pub-id-type="pmid">9756472</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S.</given-names></name><name><surname>De Weerd</surname><given-names>P.</given-names></name><name><surname>Pinsk</surname><given-names>M. A.</given-names></name><name><surname>Elizondo</surname><given-names>M. I.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Ungerleider</surname><given-names>L. G.</given-names></name></person-group> (<year>2001</year>). <article-title>Modulation of sensory suppression: implications for receptive fields sizes in the human visual cortex</article-title>. <source>J. Neurophysiol.</source><volume>86</volume>, <fpage>1398</fpage>&#x02013;<lpage>1411</lpage><pub-id pub-id-type="pmid">11535686</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kastner</surname><given-names>S.</given-names></name><name><surname>Pinsk</surname><given-names>M. A.</given-names></name><name><surname>De Weerd</surname><given-names>P.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name><name><surname>Ungerleider</surname><given-names>L. G.</given-names></name></person-group> (<year>1999</year>). <article-title>Increased activity in human visual cortex during directed attention in the absence of visual stimulation</article-title>. <source>Neuron</source><volume>22</volume>, <fpage>751</fpage>&#x02013;<lpage>761</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80734-5</pub-id><pub-id pub-id-type="pmid">10230795</pub-id></mixed-citation></ref><ref id="B76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiebel</surname><given-names>S. J.</given-names></name><name><surname>von Kriegstein</surname><given-names>K.</given-names></name><name><surname>Daunizeau</surname><given-names>J.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Recognizing sequences of sequences</article-title>. <source>PLoS Comput. Biol.</source><volume>5</volume>, <fpage>e1000464</fpage><pub-id pub-id-type="doi">10.1371/journal pcbi 1000464</pub-id><pub-id pub-id-type="pmid">19680429</pub-id></mixed-citation></ref><ref id="B77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knill</surname><given-names>D. C.</given-names></name><name><surname>Saunders</surname><given-names>J. A.</given-names></name></person-group> (<year>2003</year>). <article-title>Do humans optimally integrate stereo and texture information for judgments of surface slant?</article-title><source>Vision Res.</source><volume>43</volume>, <fpage>2539</fpage>&#x02013;<lpage>2558</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(03)00458-9</pub-id><pub-id pub-id-type="pmid">13129541</pub-id></mixed-citation></ref><ref id="B78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000f6;rding</surname><given-names>K. P.</given-names></name><name><surname>Wolpert</surname><given-names>D. M.</given-names></name></person-group> (<year>2004</year>). <article-title>Bayesian integration in sensorimotor learning</article-title>. <source>Nature</source><volume>427</volume>, <fpage>244</fpage>&#x02013;<lpage>247</lpage><pub-id pub-id-type="doi">10.1038/nature02169</pub-id><pub-id pub-id-type="pmid">14724638</pub-id></mixed-citation></ref><ref id="B79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langer</surname><given-names>M. S.</given-names></name><name><surname>Bulthoff</surname><given-names>H. H.</given-names></name></person-group> (<year>2001</year>). <article-title>A prior for global convexity in local shape-from-shading</article-title>. <source>Perception</source><volume>30</volume>, <fpage>403</fpage>&#x02013;<lpage>410</lpage><pub-id pub-id-type="doi">10.1068/p3178</pub-id><pub-id pub-id-type="pmid">11383189</pub-id></mixed-citation></ref><ref id="B80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavie</surname><given-names>N.</given-names></name></person-group> (<year>1995</year>). <article-title>Perceptual load as a necessary condition for selective attention</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source><volume>21</volume>, <fpage>451</fpage>&#x02013;<lpage>468</lpage><pub-id pub-id-type="pmid">7790827</pub-id></mixed-citation></ref><ref id="B81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luck</surname><given-names>S. J.</given-names></name><name><surname>Chelazzi</surname><given-names>L.</given-names></name><name><surname>Hillyard</surname><given-names>S. A.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1997</year>). <article-title>Neural mechanisms of spatial selective attention in areas V1, V2, and V4 of macaque visual cortex</article-title>. <source>J. Neurophysiol.</source><volume>77</volume>, <fpage>24</fpage>&#x02013;<lpage>42</lpage><pub-id pub-id-type="pmid">9120566</pub-id></mixed-citation></ref><ref id="B82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luck</surname><given-names>S. J.</given-names></name><name><surname>Heinze</surname><given-names>H. J.</given-names></name><name><surname>Mangun</surname><given-names>G. R.</given-names></name><name><surname>Hillyard</surname><given-names>S. A.</given-names></name></person-group> (<year>1990</year>). <article-title>Visual event-related potentials index focused attention within bilateral stimulus arrays. II. Functional dissociation of P1 and N1 components</article-title>. <source>Electroencephalogr. Clin. Neurophysiol.</source><volume>75</volume>, <fpage>528</fpage>&#x02013;<lpage>542</lpage><pub-id pub-id-type="pmid">1693897</pub-id></mixed-citation></ref><ref id="B83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macaluso</surname><given-names>E.</given-names></name><name><surname>Eimer</surname><given-names>M.</given-names></name><name><surname>Frith</surname><given-names>C. D.</given-names></name><name><surname>Driver</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>Preparatory states in crossmodal spatial attention: spatial specificity and possible control mechanisms</article-title>. <source>Exp. Brain Res.</source><volume>149</volume>, <fpage>62</fpage>&#x02013;<lpage>74</lpage><pub-id pub-id-type="pmid">12592504</pub-id></mixed-citation></ref><ref id="B84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mangun</surname><given-names>G. R.</given-names></name><name><surname>Hillyard</surname><given-names>S. A.</given-names></name></person-group> (<year>1991</year>). <article-title>Modulations of sensory-evoked brain potentials indicate changes in perceptual processing during visual-spatial priming</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source><volume>17</volume>, <fpage>1057</fpage>&#x02013;<lpage>1074</lpage><pub-id pub-id-type="pmid">1837297</pub-id></mixed-citation></ref><ref id="B85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marrocco</surname><given-names>R. T.</given-names></name><name><surname>Witte</surname><given-names>E. A.</given-names></name><name><surname>Davidson</surname><given-names>M. C.</given-names></name></person-group> (<year>1994</year>). <article-title>Arousal systems</article-title>. <source>Curr. Opin. Neurobiol.</source><volume>4</volume>, <fpage>166</fpage>&#x02013;<lpage>170</lpage><pub-id pub-id-type="pmid">7913640</pub-id></mixed-citation></ref><ref id="B86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maunsell</surname><given-names>J. H.</given-names></name><name><surname>Treue</surname><given-names>S.</given-names></name></person-group> (<year>2006</year>). <article-title>Feature-based attention in visual cortex</article-title>. <source>Trends Neurosci.</source><volume>29</volume>, <fpage>317</fpage>&#x02013;<lpage>322</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2006.04.001</pub-id><pub-id pub-id-type="pmid">16697058</pub-id></mixed-citation></ref><ref id="B87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazurek</surname><given-names>M. E.</given-names></name><name><surname>Roitman</surname><given-names>J. D.</given-names></name><name><surname>Ditterich</surname><given-names>J.</given-names></name><name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2003</year>). <article-title>A role for neural integrators in perceptual decision making</article-title>. <source>Cereb. Cortex.</source><volume>13</volume>, <fpage>1257</fpage>&#x02013;<lpage>1269</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhg097</pub-id><pub-id pub-id-type="pmid">14576217</pub-id></mixed-citation></ref><ref id="B88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname><given-names>D. A.</given-names></name><name><surname>Prince</surname><given-names>D. A.</given-names></name></person-group> (<year>1985</year>). <article-title>Two types of muscarinic response to acetylcholine in mammalian cortical neurons</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source><volume>82</volume>, <fpage>6344</fpage>&#x02013;<lpage>6348</lpage><pub-id pub-id-type="pmid">3862134</pub-id></mixed-citation></ref><ref id="B89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname><given-names>D. A.</given-names></name><name><surname>Prince</surname><given-names>D. A.</given-names></name></person-group> (<year>1986</year>). <article-title>Mechanisms of action of acetylcholine in the guinea-pig cerebral cortex in vitro</article-title>. <source>J. Physiol.</source><volume>375</volume>, <fpage>169</fpage>&#x02013;<lpage>194</lpage><pub-id pub-id-type="pmid">2879035</pub-id></mixed-citation></ref><ref id="B90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname><given-names>J.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1985</year>). <article-title>Selective attention gates visual processing in the extrastriate cortex</article-title>. <source>Science</source><volume>229</volume>, <fpage>782</fpage>&#x02013;<lpage>784</lpage><pub-id pub-id-type="doi">10.1126/science.4023713</pub-id><pub-id pub-id-type="pmid">4023713</pub-id></mixed-citation></ref><ref id="B91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moray</surname><given-names>N.</given-names></name></person-group> (<year>1959</year>). <article-title>Attention in dichotic listening: affective cues and the influence of instructions</article-title>. <source>Q. J. Exp. Psychol.</source><volume>11</volume>, <fpage>56</fpage>&#x02013;<lpage>60</lpage></mixed-citation></ref><ref id="B92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>D.</given-names></name></person-group> (<year>1992</year>). <article-title>On the computational architecture of the neocortex. II. The role of cortico-cortical loops</article-title>. <source>Biol. Cybern.</source><volume>66</volume>, <fpage>241</fpage>&#x02013;<lpage>251</lpage><pub-id pub-id-type="doi">10.1007/BF00198477</pub-id><pub-id pub-id-type="pmid">1540675</pub-id></mixed-citation></ref><ref id="B93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname><given-names>A.</given-names></name><name><surname>Correa</surname><given-names>A.</given-names></name><name><surname>Coull</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>The hazards of time</article-title>. <source>Curr. Opin. Neurobiol.</source><volume>17</volume>, <fpage>465</fpage>&#x02013;<lpage>470</lpage><pub-id pub-id-type="pmid">17709239</pub-id></mixed-citation></ref><ref id="B94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connor</surname><given-names>D. H.</given-names></name><name><surname>Fukui</surname><given-names>M. M.</given-names></name><name><surname>Pinsk</surname><given-names>M. A.</given-names></name><name><surname>Kastner</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>). <article-title>Attention modulates responses in the human lateral geniculate nucleus</article-title>. <source>Nat. Neurosci.</source><volume>5</volume>, <fpage>1203</fpage>&#x02013;<lpage>1209</lpage><pub-id pub-id-type="pmid">12379861</pub-id></mixed-citation></ref><ref id="B95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozaki</surname><given-names>T.</given-names></name></person-group> (<year>1992</year>). <article-title>A bridge between nonlinear time-series models and nonlinear stochastic dynamical systems: a local linearization approach</article-title>. <source>Stat. Sin.</source><volume>2</volume>, <fpage>113</fpage>&#x02013;<lpage>135</lpage></mixed-citation></ref><ref id="B96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parikh</surname><given-names>V.</given-names></name><name><surname>Kozak</surname><given-names>R.</given-names></name><name><surname>Martinez</surname><given-names>V.</given-names></name><name><surname>Sarter</surname><given-names>M.</given-names></name></person-group> (<year>2007</year>). <article-title>Prefrontal acetylcholine release controls cue detection on multiple timescales</article-title>. <source>Neuron</source><volume>56</volume>, <fpage>141</fpage>&#x02013;<lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.08.025</pub-id><pub-id pub-id-type="pmid">17920021</pub-id></mixed-citation></ref><ref id="B97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlova</surname><given-names>M.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Sokolov</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>Attentional modulation of cortical neuromagnetic gamma response to biological movement</article-title>. <source>Cereb. Cortex</source><volume>16</volume>, <fpage>321</fpage>&#x02013;<lpage>327</lpage><pub-id pub-id-type="pmid">15901655</pub-id></mixed-citation></ref><ref id="B98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perchet</surname><given-names>C.</given-names></name><name><surname>Revol</surname><given-names>O.</given-names></name><name><surname>Fourneret</surname><given-names>P.</given-names></name><name><surname>Maugui&#x000e8;re</surname><given-names>F.</given-names></name><name><surname>Garcia-Larrea</surname><given-names>L.</given-names></name></person-group> (<year>2001</year>). <article-title>Attention shifts and anticipatory mechanisms in hyperactive children: an ERP study using the Posner paradigm</article-title>. <source>Biol. Psychiatry</source><volume>50</volume>, <fpage>44</fpage>&#x02013;<lpage>57</lpage><pub-id pub-id-type="pmid">11457423</pub-id></mixed-citation></ref><ref id="B99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname><given-names>L.</given-names></name><name><surname>Kastner</surname><given-names>S.</given-names></name><name><surname>Ungerleider</surname><given-names>L. G.</given-names></name></person-group> (<year>2002</year>). <article-title>Attentional control of the processing of neutral and emotional stimuli</article-title>. <source>Cogn. Brain Res</source>. <volume>15</volume>, <fpage>31</fpage>&#x02013;<lpage>45</lpage></mixed-citation></ref><ref id="B100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polich</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>Updating P300: an integrative theory of P3a and P3b</article-title>. <source>Clin. Neurophysiol.</source><volume>118</volume>, <fpage>2128</fpage>&#x02013;<lpage>2148</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2007.04.019</pub-id><pub-id pub-id-type="pmid">17573239</pub-id></mixed-citation></ref><ref id="B101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>1980</year>). <article-title>Orienting of attention</article-title>. <source>Q. J. Exp. Psychol.</source><volume>32</volume>, <fpage>3</fpage>&#x02013;<lpage>25</lpage><pub-id pub-id-type="pmid">7367577</pub-id></mixed-citation></ref><ref id="B102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>M. I.</given-names></name></person-group> (<year>2008</year>). <article-title>Measuring alertness</article-title>. <source>Ann. N. Y. Acad. Sci.</source><volume>1129</volume>, <fpage>193</fpage>&#x02013;<lpage>199</lpage><pub-id pub-id-type="pmid">18591480</pub-id></mixed-citation></ref><ref id="B103"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>M. I.</given-names></name><name><surname>Cohen</surname><given-names>Y.</given-names></name></person-group> (<year>1984</year>). <article-title>&#x0201c;Components of visual orienting,&#x0201d;</article-title> in <source>Attention and Performance</source>, Vol.<volume>10</volume>, eds <person-group person-group-type="editor"><name><surname>Bouma</surname><given-names>H.</given-names></name><name><surname>Bouwhuis</surname><given-names>D. G.</given-names></name></person-group> (<publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Erlbaum</publisher-name>), <fpage>531</fpage>&#x02013;<lpage>556</lpage></mixed-citation></ref><ref id="B104"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>M. I.</given-names></name><name><surname>Nissen</surname><given-names>M. J.</given-names></name><name><surname>Ogden</surname><given-names>W. C.</given-names></name></person-group> (<year>1978</year>). <article-title>&#x0201c;Attended and unattended processing modes: the role of set for spatial location,&#x0201d;</article-title> in <source>Modes of Perceiving and Processing Information</source>, eds <person-group person-group-type="editor"><name><surname>Pick</surname><given-names>H. L.</given-names></name><name><surname>Saltzman</surname><given-names>N. J.</given-names></name></person-group> (<publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name>).</mixed-citation></ref><ref id="B105"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rafal</surname><given-names>R. D.</given-names></name><name><surname>Calabresi</surname><given-names>P. A.</given-names></name><name><surname>Brennan</surname><given-names>C. W.</given-names></name><name><surname>Sciolto</surname><given-names>T. K.</given-names></name></person-group> (<year>1989</year>). <article-title>Saccade preparation inhibits reorienting to recently attended locations</article-title>. <source>J. Exp. Psychol Hum. Percept. Perform.</source><volume>15</volume>, <fpage>673</fpage>&#x02013;<lpage>685</lpage><pub-id pub-id-type="pmid">2531204</pub-id></mixed-citation></ref><ref id="B106"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>R. P.</given-names></name></person-group> (<year>2005</year>). <article-title>Bayesian inference and attentional modulation in the visual cortex</article-title>. <source>Neuroreport</source><volume>16</volume>, <fpage>1843</fpage>&#x02013;<lpage>1848</lpage><pub-id pub-id-type="doi">10.1097/01.wnr.0000183900.92901.fc</pub-id><pub-id pub-id-type="pmid">16237339</pub-id></mixed-citation></ref><ref id="B107"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>R. P.</given-names></name><name><surname>Ballard</surname><given-names>D. H.</given-names></name></person-group> (<year>1998</year>). <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive field effects</article-title>. <source>Nat. Neurosci.</source><volume>2</volume>, <fpage>79</fpage>&#x02013;<lpage>87</lpage><pub-id pub-id-type="pmid">10195184</pub-id></mixed-citation></ref><ref id="B108"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Recanzone</surname><given-names>G. H.</given-names></name><name><surname>Wurtz</surname><given-names>R. H.</given-names></name><name><surname>Schwarz</surname><given-names>U.</given-names></name></person-group> (<year>1997</year>). <article-title>Responses of MT and MST neurons to one and two moving objects in the receptive field</article-title>. <source>J. Neurophysiol.</source><volume>78</volume>, <fpage>2904</fpage>&#x02013;<lpage>2915</lpage><pub-id pub-id-type="pmid">9405511</pub-id></mixed-citation></ref><ref id="B109"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>J. H.</given-names></name><name><surname>Chelazzi</surname><given-names>L.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>1999</year>). <article-title>Competitive mechanisms subserve attention in macaque areas V2 and V4</article-title>. <source>J. Neurosci.</source><volume>19</volume>, <fpage>1736</fpage>&#x02013;<lpage>1753</lpage><pub-id pub-id-type="pmid">10024360</pub-id></mixed-citation></ref><ref id="B110"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>J. H.</given-names></name><name><surname>Heeger</surname><given-names>D. J.</given-names></name></person-group> (<year>2009</year>). <article-title>The normalization model of attention</article-title>. <source>Neuron</source><volume>61</volume>, <fpage>168</fpage>&#x02013;<lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id><pub-id pub-id-type="pmid">19186161</pub-id></mixed-citation></ref><ref id="B111"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Risko</surname><given-names>E. F.</given-names></name><name><surname>Stolz</surname><given-names>J. A.</given-names></name></person-group> (<year>2010</year>). <article-title>The proportion valid effect in covert orienting: strategic control or implicit learning?</article-title><source>Conscious. Cogn.</source><volume>19</volume>, <fpage>432</fpage>&#x02013;<lpage>442</lpage><pub-id pub-id-type="pmid">20189414</pub-id></mixed-citation></ref><ref id="B112"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rockstroh</surname><given-names>B.</given-names></name><name><surname>Elbert</surname><given-names>T.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Lutzenberger</surname><given-names>W.</given-names></name></person-group> (<year>1982</year>). <source>Slow Brain Potentials and Behavior</source>. <publisher-loc>Baltimore-Munich</publisher-loc>: <publisher-name>Urban and Schwarzenberg</publisher-name></mixed-citation></ref><ref id="B113"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>E. T.</given-names></name><name><surname>Tovee</surname><given-names>M. J.</given-names></name></person-group> (<year>1995</year>). <article-title>The responses of single neurons in the temporal visual cortical areas of the macaque when more than one stimulus is present in the receptive field</article-title>. <source>Exp. Brain Res.</source><volume>103</volume>, <fpage>409</fpage>&#x02013;<lpage>420</lpage><pub-id pub-id-type="pmid">7789447</pub-id></mixed-citation></ref><ref id="B114"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salinas</surname><given-names>E.</given-names></name><name><surname>Sejnowski</surname><given-names>T. J.</given-names></name></person-group> (<year>2001</year>). <article-title>Gain modulation in the central nervous system: where behavior, neurophysiology, and computation meet</article-title>. <source>Neuroscientist</source><volume>7</volume>, <fpage>430</fpage>&#x02013;<lpage>440</lpage><pub-id pub-id-type="doi">10.1177/107385840100700512</pub-id><pub-id pub-id-type="pmid">11597102</pub-id></mixed-citation></ref><ref id="B115"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sara</surname><given-names>S. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Learning by neurones: role of attention, reinforcement and behaviour</article-title>. <source>C. R. Acad. Sci. III, Sci. Vie</source><volume>321</volume>, <fpage>193</fpage>&#x02013;<lpage>198</lpage><pub-id pub-id-type="pmid">9759340</pub-id></mixed-citation></ref><ref id="B116"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname><given-names>C. E.</given-names></name><name><surname>Mehta</surname><given-names>A. D.</given-names></name><name><surname>Foxe</surname><given-names>J. J.</given-names></name></person-group> (<year>2001</year>). <article-title>Determinants and mechanisms of attentional modulation of neural processing</article-title>. <source>Front. Biosci.</source><volume>6</volume>, <fpage>D672</fpage>&#x02013;<lpage>D684</lpage><pub-id pub-id-type="doi">10.2741/Schroed</pub-id><pub-id pub-id-type="pmid">11333209</pub-id></mixed-citation></ref><ref id="B117"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seydell</surname><given-names>A.</given-names></name><name><surname>McCann</surname><given-names>B. C.</given-names></name><name><surname>Trommershauser</surname><given-names>J.</given-names></name><name><surname>Knill</surname><given-names>D. C.</given-names></name></person-group> (<year>2008</year>). <article-title>Learning stochastic reward distributions in a speeded pointing task</article-title>. <source>J. Neurosci.</source><volume>28</volume>, <fpage>4356</fpage>&#x02013;<lpage>4367</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0647-08.2008</pub-id><pub-id pub-id-type="pmid">18434514</pub-id></mixed-citation></ref><ref id="B118"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shulman</surname><given-names>G. L.</given-names></name><name><surname>Remington</surname><given-names>R. W.</given-names></name><name><surname>McLean</surname><given-names>J. P.</given-names></name></person-group> (<year>1979</year>). <article-title>Moving attention through visual space</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source><volume>3</volume>, <fpage>522</fpage>&#x02013;<lpage>526</lpage><pub-id pub-id-type="pmid">528957</pub-id></mixed-citation></ref><ref id="B119"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>A. T.</given-names></name><name><surname>Singh</surname><given-names>K. D.</given-names></name><name><surname>Greenlee</surname><given-names>M. W.</given-names></name></person-group> (<year>2000</year>). <article-title>Attentional suppression of activity in the human visual cortex</article-title>. <source>Neuroreport</source><volume>11</volume>, <fpage>271</fpage>&#x02013;<lpage>277</lpage><pub-id pub-id-type="doi">10.1097/00001756-200002070-00010</pub-id><pub-id pub-id-type="pmid">10674469</pub-id></mixed-citation></ref><ref id="B120"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokolov</surname><given-names>A.</given-names></name><name><surname>Lutzenberger</surname><given-names>W.</given-names></name><name><surname>Pavlova</surname><given-names>M.</given-names></name><name><surname>Preissl</surname><given-names>H.</given-names></name><name><surname>Braun</surname><given-names>C.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name></person-group> (<year>1999</year>). <article-title>Gamma-band MEG activity to coherent motion depends on task-driven attention</article-title>. <source>Neuroreport</source><volume>10</volume>, <fpage>1997</fpage>&#x02013;<lpage>2000</lpage><pub-id pub-id-type="doi">10.1097/00001756-199907130-00001</pub-id><pub-id pub-id-type="pmid">10424663</pub-id></mixed-citation></ref><ref id="B121"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spratling</surname><given-names>M. W.</given-names></name></person-group> (<year>2008</year>). <article-title>Predictive-coding as a model of biased competition in visual attention</article-title>. <source>Vision Res.</source><volume>48</volume>, <fpage>1391</fpage>&#x02013;<lpage>1408</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.03.009</pub-id><pub-id pub-id-type="pmid">18442841</pub-id></mixed-citation></ref><ref id="B122"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spratling</surname><given-names>M. W.</given-names></name></person-group> (<year>2010</year>). <article-title>Predictive coding as a model of response properties in cortical area V1</article-title>. <source>J. Neurosci.</source><volume>30</volume>, <fpage>3531</fpage>&#x02013;<lpage>3543</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4911-09.2010</pub-id><pub-id pub-id-type="pmid">20203213</pub-id></mixed-citation></ref><ref id="B123"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>P. N.</given-names></name><name><surname>Roy</surname><given-names>A.</given-names></name><name><surname>Fitzgerald</surname><given-names>P. J.</given-names></name><name><surname>Hsiao</surname><given-names>S. S.</given-names></name><name><surname>Johnson</surname><given-names>K. O.</given-names></name><name><surname>Niebur</surname><given-names>E.</given-names></name></person-group> (<year>2000</year>). <article-title>Attention modulates synchronized neuronal firing in primate somatosensory cortex</article-title>. <source>Nature</source><volume>404</volume>, <fpage>187</fpage>&#x02013;<lpage>190</lpage><pub-id pub-id-type="doi">10.1038/35004588</pub-id><pub-id pub-id-type="pmid">10724171</pub-id></mixed-citation></ref><ref id="B124"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>M.</given-names></name><name><surname>Thompson</surname><given-names>R.</given-names></name><name><surname>Nobre</surname><given-names>A. C.</given-names></name><name><surname>Duncan</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <article-title>Shape-specific preparatory activity mediates attention to targets in human visual cortex</article-title>. <source>Proc. Natl. Acad. Sci. U S A.</source><volume>106</volume>, <fpage>19569</fpage>&#x02013;<lpage>19574</lpage><pub-id pub-id-type="doi">10.1073/pnas.0905306106</pub-id><pub-id pub-id-type="pmid">19887644</pub-id></mixed-citation></ref><ref id="B125"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theeuwes</surname><given-names>J.</given-names></name></person-group> (<year>1991</year>). <article-title>Exogenous and endogenous control of attention: the effect of visual onsets and offsets</article-title>. <source>Percept. Psychophys.</source><volume>49</volume>, <fpage>83</fpage>&#x02013;<lpage>90</lpage><pub-id pub-id-type="pmid">2011456</pub-id></mixed-citation></ref><ref id="B126"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>A.</given-names></name></person-group> (<year>1964</year>). <article-title>Verbal cues, language and meaning in selective attention</article-title>. <source>Am. J. Psychol.</source><volume>77</volume>, <fpage>206</fpage>&#x02013;<lpage>209</lpage><pub-id pub-id-type="pmid">14141474</pub-id></mixed-citation></ref><ref id="B127"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>A.</given-names></name></person-group> (<year>1998</year>). <article-title>Feature binding, attention and object perception</article-title>. <source>Philos. Trans. R. Soc.Lond. B</source><volume>353</volume>, <fpage>1295</fpage>&#x02013;<lpage>1306</lpage><pub-id pub-id-type="pmid">9770223</pub-id></mixed-citation></ref><ref id="B128"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>A.</given-names></name><name><surname>Gelade</surname><given-names>G.</given-names></name></person-group> (<year>1980</year>). <article-title>A feature-integration theory of attention</article-title>. <source>Cogn. Psychol.</source><volume>12</volume>, <fpage>97</fpage>&#x02013;<lpage>136</lpage><pub-id pub-id-type="pmid">7351125</pub-id></mixed-citation></ref><ref id="B129"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treisman</surname><given-names>A.</given-names></name><name><surname>Schmidt</surname><given-names>H.</given-names></name></person-group> (<year>1982</year>). <article-title>Illusory conjunctions in the perception of objects</article-title>. <source>Cogn. Psychol.</source><volume>14</volume>, <fpage>107</fpage>&#x02013;<lpage>141</lpage><pub-id pub-id-type="pmid">7053925</pub-id></mixed-citation></ref><ref id="B130"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treue</surname><given-names>S.</given-names></name><name><surname>Maunsell</surname><given-names>J. H. R.</given-names></name></person-group> (<year>1996</year>). <article-title>Attentional modulation of visual motion processing in cortical areas MT and MST</article-title>. <source>Nature</source><volume>382</volume>, <fpage>539</fpage>&#x02013;<lpage>541</lpage><pub-id pub-id-type="doi">10.1038/382539a0</pub-id><pub-id pub-id-type="pmid">8700227</pub-id></mixed-citation></ref><ref id="B131"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trommershauser</surname><given-names>J.</given-names></name><name><surname>Maloney</surname><given-names>L. T.</given-names></name><name><surname>Landy</surname><given-names>M. S.</given-names></name></person-group> (<year>2003b</year>). <article-title>Statistical decision theory and the selection of rapid, goal-directed movements</article-title>. <source>J. Opt. Soc. Am. A</source><volume>20</volume>, <fpage>1419</fpage>&#x02013;<lpage>1433</lpage><pub-id pub-id-type="doi">10.1167/3.9.129</pub-id></mixed-citation></ref><ref id="B132"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vibell</surname><given-names>J.</given-names></name><name><surname>Klinge</surname><given-names>C.</given-names></name><name><surname>Zampini</surname><given-names>M.</given-names></name><name><surname>Spence</surname><given-names>C.</given-names></name><name><surname>Nobre</surname><given-names>A. C.</given-names></name></person-group> (<year>2007</year>). <article-title>Temporal order is coded temporally in the brain: early event-related potential latency shifts underlying prior entry in a cross-modal temporal order judgment task</article-title>. <source>J. Cogn. Neurosci.</source><volume>19</volume>, <fpage>109</fpage>&#x02013;<lpage>120</lpage><pub-id pub-id-type="pmid">17214568</pub-id></mixed-citation></ref><ref id="B133"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidal</surname><given-names>J. R.</given-names></name><name><surname>Chaumon</surname><given-names>M.</given-names></name><name><surname>O'Regan</surname><given-names>J. K.</given-names></name><name><surname>Tallon-Baudry</surname><given-names>C.</given-names></name></person-group> (<year>2006</year>). <article-title>Visual grouping and the focusing of attention induce gamma-band oscillations at different frequencies in human magnetoencephalogram signals</article-title>. <source>J. Cogn. Neurosci.</source><volume>18</volume>, <fpage>1850</fpage>&#x02013;<lpage>1862</lpage><pub-id pub-id-type="pmid">17069476</pub-id></mixed-citation></ref><ref id="B134"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vossel</surname><given-names>S.</given-names></name><name><surname>Thiel</surname><given-names>C. M.</given-names></name><name><surname>Fink</surname><given-names>G. R.</given-names></name></person-group> (<year>2006</year>). <article-title>Cue validity modulates the neural correlates of covert endogenous orienting of attention in parietal and frontal cortex</article-title>. <source>Neuroimage</source><volume>32</volume>, <fpage>1257</fpage>&#x02013;<lpage>1264</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.05.019</pub-id><pub-id pub-id-type="pmid">16846742</pub-id></mixed-citation></ref><ref id="B135"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vossel</surname><given-names>S.</given-names></name><name><surname>Thiel</surname><given-names>C. M.</given-names></name><name><surname>Fink</surname><given-names>G. R.</given-names></name></person-group> (<year>2008</year>). <article-title>Behavioral and neural effects of nicotine on visuospatial attentional reorienting in non-smoking subjects</article-title>. <source>Neuropsychopharmacology</source><volume>33</volume>, <fpage>731</fpage>&#x02013;<lpage>738</lpage><pub-id pub-id-type="doi">10.1038/sj.npp.1301469</pub-id><pub-id pub-id-type="pmid">17551539</pub-id></mixed-citation></ref><ref id="B136"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voytko</surname><given-names>M. L.</given-names></name><name><surname>Olton</surname><given-names>D. S.</given-names></name><name><surname>Richardson</surname><given-names>R. T.</given-names></name><name><surname>Gorman</surname><given-names>L. K.</given-names></name><name><surname>Tobin</surname><given-names>J. R.</given-names></name><name><surname>Price</surname><given-names>D. L.</given-names></name></person-group> (<year>1994</year>). <article-title>Basal forebrain lesions in monkeys disrupt attention but not learning and memory</article-title>. <source>J. Neurosci.</source><volume>14</volume>, <fpage>167</fpage>&#x02013;<lpage>186</lpage><pub-id pub-id-type="pmid">8283232</pub-id></mixed-citation></ref><ref id="B137"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walter</surname><given-names>W. G.</given-names></name><name><surname>Cooper</surname><given-names>R.</given-names></name><name><surname>Aldridge</surname><given-names>W. J.</given-names></name><name><surname>McCallum</surname><given-names>W. C.</given-names></name></person-group> (<year>1964</year>). <article-title>Contingent negative variation: an electrophysiological sign of sensoriomotor association and expectancy in the human brain</article-title>. <source>Nature</source><volume>203</volume>, <fpage>380</fpage>&#x02013;<lpage>384</lpage><pub-id pub-id-type="doi">10.1038/203380a0</pub-id><pub-id pub-id-type="pmid">14197376</pub-id></mixed-citation></ref><ref id="B138"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whiteley</surname><given-names>L.</given-names></name><name><surname>Sahani</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Implicit knowledge of visual uncertainty guides decisions with asymmetric outcomes</article-title>. <source>J. Vis.</source><volume>8</volume>, <fpage>2.1</fpage>&#x02013;<lpage>15</lpage><pub-id pub-id-type="doi">10.1167/8.3.2</pub-id><pub-id pub-id-type="pmid">18484808</pub-id></mixed-citation></ref><ref id="B139"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witte</surname><given-names>E. A.</given-names></name><name><surname>Davidson</surname><given-names>M. C.</given-names></name><name><surname>Marrocco</surname><given-names>R. T.</given-names></name></person-group> (<year>1997</year>). <article-title>Effects of altering brain cholinergic activity on covert orienting of attention: comparison of monkey and human performance</article-title>. <source>Psychopharmacology (Berl.)</source><volume>132</volume>, <fpage>324</fpage>&#x02013;<lpage>334</lpage><pub-id pub-id-type="pmid">9298509</pub-id></mixed-citation></ref><ref id="B140"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>D. M.</given-names></name><name><surname>Ghahramani</surname><given-names>Z.</given-names></name><name><surname>Jordan</surname><given-names>M. I.</given-names></name></person-group> (<year>1995</year>). <article-title>An internal model for sensorimotor integration</article-title>. <source>Science</source><volume>269</volume>, <fpage>1880</fpage>&#x02013;<lpage>1882</lpage><pub-id pub-id-type="doi">10.1126/science.7569931</pub-id><pub-id pub-id-type="pmid">7569931</pub-id></mixed-citation></ref><ref id="B141"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Womelsdorf</surname><given-names>T.</given-names></name><name><surname>Fries</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>). <article-title>Neuronal coherence during selective attentional processing and sensory-motor integration</article-title>. <source>J. Physiol. (Paris)</source><volume>100</volume>, <fpage>182</fpage>&#x02013;<lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2007.01.005</pub-id><pub-id pub-id-type="pmid">17317118</pub-id></mixed-citation></ref><ref id="B142"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Womelsdorf</surname><given-names>T.</given-names></name><name><surname>Fries</surname><given-names>P.</given-names></name><name><surname>Mitra</surname><given-names>P. P.</given-names></name><name><surname>Desimone</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>Gamma-band synchronization in visual cortex predicts speed of change detection</article-title>. <source>Nature</source><volume>439</volume>, <fpage>733</fpage>&#x02013;<lpage>736</lpage><pub-id pub-id-type="doi">10.1038/nature04258</pub-id><pub-id pub-id-type="pmid">16372022</pub-id></mixed-citation></ref><ref id="B143"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wonnacott</surname><given-names>S.</given-names></name></person-group> (<year>1997</year>). <article-title>Presynaptic nicotinic ACh receptors</article-title>. <source>Trends Neurosci.</source><volume>20</volume>, <fpage>92</fpage>&#x02013;<lpage>98</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(96)10073-4</pub-id><pub-id pub-id-type="pmid">9023878</pub-id></mixed-citation></ref><ref id="B144"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiang</surname><given-names>Z.</given-names></name><name><surname>Huguenard</surname><given-names>J. R.</given-names></name><name><surname>Prince</surname><given-names>D. A.</given-names></name></person-group> (<year>1998</year>). <article-title>Cholinergic switching within neocortical inhibitory networks</article-title>. <source>Science</source><volume>28</volume>, <fpage>985</fpage>&#x02013;<lpage>988</lpage><pub-id pub-id-type="doi">10.1126/science.281.5379.985</pub-id><pub-id pub-id-type="pmid">9703513</pub-id></mixed-citation></ref><ref id="B145"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yantis</surname><given-names>S.</given-names></name><name><surname>Jonides</surname><given-names>J.</given-names></name></person-group> (<year>1984</year>). <article-title>Abrupt visual onsets and selective attention: evidence from visual search</article-title>. <source>J. Exp. Psychol Hum. Percept. Perform.</source><volume>10</volume>, <fpage>601</fpage>&#x02013;<lpage>621</lpage><pub-id pub-id-type="pmid">6238122</pub-id></mixed-citation></ref><ref id="B146"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>A. J.</given-names></name><name><surname>Dayan</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Uncertainty, neuromodulation and attention</article-title>. <source>Neuron</source><volume>46</volume>, <fpage>681</fpage>&#x02013;<lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></mixed-citation></ref><ref id="B147"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeitler</surname><given-names>M.</given-names></name><name><surname>Fries</surname><given-names>P.</given-names></name><name><surname>Gielen</surname><given-names>S.</given-names></name></person-group> (<year>2008</year>). <article-title>Biased competition through variations in amplitude of gamma-oscillations</article-title>. <source>J. Comput. Neurosci.</source><volume>25</volume>, <fpage>89</fpage>&#x02013;<lpage>107</lpage><pub-id pub-id-type="pmid">18293071</pub-id></mixed-citation></ref><ref id="B148"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zilles</surname><given-names>K.</given-names></name><name><surname>Palomero-Gallagher</surname><given-names>N.</given-names></name><name><surname>Schleicher</surname><given-names>A.</given-names></name></person-group> (<year>2004</year>). <article-title>Transmitter receptors and functional anatomy of the cerebral cortex</article-title>. <source>J. Anat.</source><volume>205</volume>, <fpage>417</fpage>&#x02013;<lpage>432</lpage><pub-id pub-id-type="doi">10.1111/j.0021-8782.2004.00357.x</pub-id><pub-id pub-id-type="pmid">15610391</pub-id></mixed-citation></ref></ref-list></back></article>
