<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">bioRxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title-group><journal-title>bioRxiv</journal-title></journal-title-group><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">36909656</article-id><article-id pub-id-type="pmc">PMC10002629</article-id><article-id pub-id-type="doi">10.1101/2023.02.24.529975</article-id><article-version-alternatives><article-version article-version-type="status">preprint</article-version><article-version article-version-type="number">1</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>PIFiA: Self-supervised Approach for Protein Functional Annotation from Single-Cell Imaging Data</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Razdaibiedina</surname><given-names>Anastasia</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="A2" ref-type="aff">2</xref><xref rid="A4" ref-type="aff">4</xref></contrib><contrib contrib-type="author"><name><surname>Brechalov</surname><given-names>Alexander</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Friesen</surname><given-names>Helena</given-names></name><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Usaj</surname><given-names>Mojca Mattiazzi</given-names></name><xref rid="A2" ref-type="aff">2</xref><xref rid="FN1" ref-type="author-notes">*</xref></contrib><contrib contrib-type="author"><name><surname>Masinas</surname><given-names>Myra Paz David</given-names></name><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Suresh</surname><given-names>Harsha Garadi</given-names></name><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Kyle</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="A2" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name><surname>Boone</surname><given-names>Charles</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="A2" ref-type="aff">2</xref><xref rid="A5" ref-type="aff">5</xref><xref rid="CR1" ref-type="corresp">&#x02020;</xref></contrib><contrib contrib-type="author"><name><surname>Ba</surname><given-names>Jimmy</given-names></name><xref rid="A3" ref-type="aff">3</xref><xref rid="A4" ref-type="aff">4</xref><xref rid="CR1" ref-type="corresp">&#x02020;</xref></contrib><contrib contrib-type="author"><name><surname>Andrews</surname><given-names>Brenda</given-names></name><xref rid="A1" ref-type="aff">1</xref><xref rid="A2" ref-type="aff">2</xref><xref rid="CR1" ref-type="corresp">&#x02020;</xref></contrib></contrib-group><aff id="A1"><label>1.</label> Department of Molecular Genetics, University of Toronto, Toronto ON, Canada</aff><aff id="A2"><label>2.</label> The Donnelly Centre, University of Toronto, Toronto ON, Canada</aff><aff id="A3"><label>3.</label> Department of Computer Science, University of Toronto, Toronto ON, Canada</aff><aff id="A4"><label>4.</label> Vector Institute for Artificial Intelligence, Toronto ON, Canada</aff><aff id="A5"><label>5.</label> RIKEN Center for Sustainable Resource Science, 2-1 Hirosawa, Wako, Saitama, Japan.</aff><author-notes><fn fn-type="present-address" id="FN1"><label>*</label><p id="P1">current address: Department of Chemistry and Biology, Toronto Metropolitan University, Toronto, ON, Canada</p></fn><fn id="FN2"><p id="P2">Author contributions</p><p id="P3">A.R. developed the PIFiA pipeline and performed the computational experiments. A.B. designed components of the downstream data analysis. M.M.U. and H.F. performed biological analysis and interpretation of the derived clusters. M.P.D.M. developed the PIFiA visualization tool for the CellVision website. H.G.S. constructed and imaged the modified yeast GFP collection. K.W. performed the co-localization experiments. A.R., H.F., A.B., M.M.U., C.B., J.B. and B.A. wrote the manuscript. B.A., C.B. and J.B. conceived and supervised the project.</p></fn><corresp id="CR1"><label>&#x02020;</label>corresponding authors</corresp></author-notes><pub-date pub-type="epub"><day>27</day><month>2</month><year>2023</year></pub-date><elocation-id>2023.02.24.529975</elocation-id><permissions><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This work is licensed under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</ext-link>, which allows reusers to copy and distribute the material in any medium or format in unadapted form only, for noncommercial purposes only, and only so long as attribution is given to the creator.</license-p></license></permissions><self-uri content-type="pdf">nihpp-2023.02.24.529975.pdf</self-uri><abstract id="ABS1"><p id="P4">Fluorescence microscopy data describe protein localization patterns at single-cell resolution and have the potential to reveal whole-proteome functional information with remarkable precision. Yet, extracting biologically meaningful representations from cell micrographs remains a major challenge. Existing approaches often fail to learn robust and noise-invariant features or rely on supervised labels for accurate annotations. We developed PIFiA, (<bold>P</bold>rotein <bold>I</bold>mage-based <bold>F</bold>unct<bold>i</bold>onal <bold>A</bold>nnotation), a self-supervised approach for protein functional annotation from single-cell imaging data. We imaged the global yeast ORF-GFP collection and applied PIFiA to generate protein feature profiles from single-cell images of fluorescently tagged proteins. We show that PIFiA outperforms existing approaches for molecular representation learning and describe a range of downstream analysis tasks to explore the information content of the feature profiles. Specifically, we cluster extracted features into a hierarchy of functional organization, study cell population heterogeneity, and develop techniques to distinguish multi-localizing proteins and identify functional modules. Finally, we confirm new PIFiA predictions using a colocalization assay, suggesting previously unappreciated biological roles for several proteins. Paired with a fully interactive website (<ext-link xlink:href="https://thecellvision.org/pifia/" ext-link-type="uri">https://thecellvision.org/pifia/</ext-link>), PIFiA is a resource for the quantitative analysis of protein organization within the cell.</p></abstract></article-meta></front><body><sec id="S1"><title>Introduction</title><p id="P5">Recent progress in high-throughput microscopy and computational image analysis has catalyzed large-scale efforts to quantitatively describe single-cell biology<sup><xref rid="R1" ref-type="bibr">1</xref>&#x02013;<xref rid="R6" ref-type="bibr">6</xref></sup>. Advances in quantitative analysis of large-scale image datasets have been driven by the development of algorithms for protein localization prediction, which have been used for automated drug screening, and extracting morphological profiles from cell images<sup><xref rid="R7" ref-type="bibr">7</xref>, <xref rid="R8" ref-type="bibr">8</xref></sup>. Computational methods enable efficient analysis of millions of single-cell images by extracting morphological information in an unbiased quantitative form. However, generating meaningful numerical features from single-cell images remains a significant challenge. Cells in micrographs typically exhibit a variety of shapes and positions, while noise levels and pixel intensities can also vary between images, making it difficult to develop algorithms that extract functionally rich patterns while ignoring irrelevant information<sup><xref rid="R8" ref-type="bibr">8</xref></sup>. For instance, early machine learning approaches relied on hand-engineered feature sets extracted from images, such as cell texture and shape, which were often difficult to select and not transferable to other datasets or tasks<sup><xref rid="R2" ref-type="bibr">2</xref></sup>. Ideally, a computational workflow would map single cells and proteins to robust numerical representations, enabling analysis of the spatial organization of the cell in an objective way.</p><p id="P6">More recently, single-cell images have been analyzed using deep learning methods, which overcome the limitations associated with hand-engineered feature sets by learning the optimal feature representations directly from pixel level data<sup><xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R9" ref-type="bibr">9</xref></sup>. Of particular relevance, we previously developed a deep convolutional neural network, DeepLoc<sup><xref rid="R8" ref-type="bibr">8</xref></sup>, for analysis of images of GFP-fusion proteins for each budding yeast open reading frame (ORF). The yeast ORF-GFP collection<sup><xref rid="R10" ref-type="bibr">10</xref></sup> consists of ~4,100 unique strains, each of which expresses a GFP signal above background in standard growth conditions, enabling systematic analysis of ~70% of the yeast proteome in living cells<sup><xref rid="R2" ref-type="bibr">2</xref>, <xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R10" ref-type="bibr">10</xref></sup>. DeepLoc was trained to accurately classify images from diverse datasets into 22 subcellular compartments, including images generated in different genetic backgrounds and by different laboratories<sup><xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R11" ref-type="bibr">11</xref></sup>. Similar approaches have been developed to analyze human cell datasets, such as the Human Protein Atlas, a collection of immunofluorescence images which covers ~65% of the human proteome<sup><xref rid="R12" ref-type="bibr">12</xref></sup>. While supervised approaches produce high-quality features, their success largely depends on the number of hand-labeled samples in the dataset<sup><xref rid="R13" ref-type="bibr">13</xref>, <xref rid="R14" ref-type="bibr">14</xref></sup>. For example, the Human Atlas Project leveraged crowd-sourcing to accelerate label collection on a large scale, involving thousands of video games players for image annotation<sup><xref rid="R12" ref-type="bibr">12</xref></sup>. However, manual label assignment is not practical for imaging datasets containing millions of single-cell micrographs. In addition, human-labeled standards may reflect the biases of an individual annotator and can preclude identification of subtle or incompletely penetrant phenotypes<sup><xref rid="R14" ref-type="bibr">14</xref>,<xref rid="R15" ref-type="bibr">15</xref></sup>.</p><p id="P7">An emerging alternative to supervised methods for biological image analysis involves self-supervised approaches, which do not require manually assigned categories during training<sup><xref rid="R16" ref-type="bibr">16</xref>&#x02013;<xref rid="R18" ref-type="bibr">18</xref></sup>. Instead, self-supervised learning models define a training objective, or pretext task, using structural information from the data itself<sup><xref rid="R18" ref-type="bibr">18</xref>&#x02013;<xref rid="R20" ref-type="bibr">20</xref></sup>. In the context of self-supervised training, features learned with the pretext task should encapsulate information from the images that is useful for downstream applications, such as the discovery of common localization patterns by clustering analysis<sup><xref rid="R15" ref-type="bibr">15</xref></sup>. Recently, self-supervised methods based on auto-encoders have been used for representation learning on cellular data<sup><xref rid="R21" ref-type="bibr">21</xref>&#x02013;<xref rid="R23" ref-type="bibr">23</xref></sup>. Autoencoder-based models are trained by compressing an image into the latent space (encoding), and subsequent image reconstruction (decoding)<sup><xref rid="R24" ref-type="bibr">24</xref></sup>. The encoding of the image in the latent space is then used as its representation. For instance, Paired Cell Inpainting<sup><xref rid="R15" ref-type="bibr">15</xref></sup>, a self-supervised approach developed for analysis of yeast fluorescent micrographs, encodes several imaging channels to predict the appearance of a fluorescently-tagged protein in a target cell. Another autoencoder-based method developed for human cell data, <italic toggle="yes">cytoself</italic><sup><xref rid="R22" ref-type="bibr">22</xref></sup>, trains a vector-quantized variational autoencoder<sup><xref rid="R24" ref-type="bibr">24</xref>, <xref rid="R25" ref-type="bibr">25</xref></sup> (VQ-VAE) to reconstruct fluorescent signals of tagged proteins. Self-supervised learning with autoencoder-based approaches has also been applied for the analysis of human microglia data<sup><xref rid="R21" ref-type="bibr">21</xref></sup>, and extraction of feature profiles predictive of cell metastatic potential<sup><xref rid="R23" ref-type="bibr">23</xref></sup>. A disadvantage of autoencoders is that they often learn features that are not relevant to protein morphology and localization, such as cell position, imaging artifacts and noise<sup><xref rid="R15" ref-type="bibr">15</xref></sup>. Also, pixel-level reconstruction is computationally expensive and often unnecessary for representation learning. These issues reflect the autoencoder&#x02019;s training objective, which targets identical reconstruction of the input. In this study, we asked whether other characteristics of microscopy data could be leveraged as self-supervised objectives to learn high-quality image representations.</p><p id="P8">Another challenge related to learning image-based features lies in their downstream analysis and interpretation. Current approaches typically extract representations with various machine learning methods and perform downstream analysis using clustering and tSNE/UMAP projections<sup><xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R15" ref-type="bibr">15</xref>, <xref rid="R22" ref-type="bibr">22</xref></sup>. However, there are no clear rules for more nuanced biological analysis, including analysis of extracted features for different levels of cellular organization, or high-confidence identification of protein functional modules. In general, data-backed guidelines on hyperparameter selection, which enable biologically meaningful clustering and consider the scale of cellular organization, are needed. Also, current molecular representation learning approaches generally lack methodologies that can characterize protein function by quantifying cell-to-cell variability in individual protein behavior. In summary, a gap remains in the image analysis field, requiring approaches that could (1) learn biologically meaningful features without human annotations, (2) produce universal features useful for studying subcellular organization at different scales, and (3) provide techniques for a wide range of downstream feature analyses.</p><p id="P9">Here, we present PIFiA (<bold>P</bold>rotein <bold>I</bold>mage-based <bold>F</bold>unct<bold>i</bold>onal <bold>A</bold>nnotation), a self-supervised approach for protein functional annotation derived from single-cell imaging data. PIFiA is coupled with a range of feature exploratory techniques for biological discovery. The representation learning component of PIFiA is performed by a convolutional neural network (CNN), which was trained with the objective of predicting protein identity directly from its fluorescently-labeled input image. This objective does not depend on pre-existing annotations or human labels and, unlike autoencoder-based models, PIFiA is robust to learning non-relevant information in the image, such as cell position, multiple cells in a crop, input noise or imaging defects. In addition to the CNN component, the PIFiA workflow includes a set of downstream analysis steps for quantitative exploration of feature profiles extracted from single-cell imaging data. We applied PIFiA to ~3,000,000 live-cell confocal images of the budding yeast open reading frame (ORF)-GFP fusion collection<sup><xref rid="R10" ref-type="bibr">10</xref></sup>. We compare PIFiA to existing approaches for protein representation learning and show that PIFiA outperforms previous methods on four different standards of protein function. We explore PIFiA feature profiles for use in a variety of downstream tasks, which are designed for the discovery of functional groups across different scales of cellular organization. Solely using distinct localization patterns of each protein, PIFiA can make remarkably precise functional predictions, identifying highly specific subcellular localization and distinct functional modules to reveal new biological insights.</p></sec><sec id="S2"><title>Results</title><sec id="S3"><title>PIFiA architecture, feature profiles and proteome-scale image dataset</title><p id="P10">PIFiA is a self-supervised deep learning approach designed to derive functional information about proteins from microscopy data without using any pre-existing annotations (<xref rid="F1" ref-type="fig">Fig. 1</xref>). The PIFiA workflow consists of a feature extraction step performed by a deep neural network (<xref rid="F1" ref-type="fig">Fig. 1a</xref>,<xref rid="F1" ref-type="fig">b</xref>), as well as subsequent analysis steps on the extracted feature profiles (<xref rid="F1" ref-type="fig">Fig. 1c</xref>,<xref rid="F1" ref-type="fig">d</xref>,<xref rid="F1" ref-type="fig">e</xref>). The downstream analysis enables prediction of protein localization and the identification of functional modules or subsets of proteins with related cellular roles, such as protein complexes and their associated regulators. The feature profiles can be used for multiple downstream tasks, including construction of a hierarchical map of subcellular organization (<xref rid="F1" ref-type="fig">Fig. 1c</xref>), predicting protein function (<xref rid="F1" ref-type="fig">Fig. 1d</xref>), identifying localization heterogeneity at a cell population level (<xref rid="F1" ref-type="fig">Fig. 1e</xref>), and finding functional modules.</p><p id="P11">The deep learning backbone of PIFiA is a CNN consisting of eight convolutional blocks and three fully-connected (FC) layers, which was trained to predict a protein identifier associated with an input image (i.e. one out of 4,049 classes (<xref rid="F1" ref-type="fig">Fig. 1a</xref>)). The CNN produces a feature profile (or a representation profile) from the input image, which is unique to a particular image. Feature profiles are 64-dimensional real valued vectors extracted from the second FC layer, which is followed by a classification layer (<xref rid="SD1" ref-type="supplementary-material">Fig. S1a</xref>). These feature profiles encapsulate condensed information about each protein&#x02019;s identity, based solely on its localization pattern. Over the course of training, the model first learns straightforward characteristics, such as patterns of different cellular compartments, then it subsequently learns more subtle morphological features that may distinguish individual proteins (<xref rid="SD1" ref-type="supplementary-material">Fig. S1b</xref>). To achieve the best accuracy and simplicity trade-off, we searched for the optimal architecture, network depth/width and related hyperparameters based on the validation set (<xref rid="SD1" ref-type="supplementary-material">Fig. S1c</xref>,<xref rid="SD1" ref-type="supplementary-material">d</xref>) (see <xref rid="S12" ref-type="sec">Methods</xref>). We found that more complex architectures, such as DenseNets<sup><xref rid="R26" ref-type="bibr">26</xref></sup>, did not improve performance but increased the training time, hence we chose a simpler architecture that could achieve comparable performance. Similarly, we searched for optimal feature profile dimensionality and found that accuracy of protein identity prediction stabilized around a 64-dimensional feature profile (<xref rid="SD1" ref-type="supplementary-material">Fig. S1d</xref>).</p><p id="P12">To train PIFiA, we produced a comprehensive dataset of 3,058,961 live-cell images of individual strains expressing both a unique fusion gene from the yeast ORF-GFP collection<sup><xref rid="R10" ref-type="bibr">10</xref></sup> and spatial markers of cell cycle position<sup><xref rid="R10" ref-type="bibr">10</xref>, <xref rid="R14" ref-type="bibr">14</xref>, <xref rid="R27" ref-type="bibr">27</xref></sup>, which provide cellular context for computational analysis of protein localization. In particular, we used automated yeast genetics<sup><xref rid="R28" ref-type="bibr">28</xref></sup> to engineer a new version of the ORF-GFP collection, in which the resultant strains also carried fluorescent markers of the nucleus (td-Tomato-NLS) and cytoplasm (E2-Crimson). In total, images of 4,049 unique strains were obtained using an automated confocal microscope. Cell images were derived from two biological replicates, each of which had four fields of view for each ORF-GFP strain. The images acquired for the GFP channel were cropped into 64&#x000d7;64 pixels crops (median of 778 crops per tagged protein, see <xref rid="S12" ref-type="sec">Methods</xref>), and each crop contained at least one cell at its center. The crops for each GFP-tagged protein were then split into training, validation and test subsets (8:1:1 ratios).</p><p id="P13">After CNN training was completed, we extracted feature profiles of the individual single-cell crops from the test set to produce single-cell feature profiles (scFPs) (<xref rid="F1" ref-type="fig">Fig. 1b</xref>). We then averaged the scFPs for each protein to create its average feature profile (aFP) (<xref rid="F1" ref-type="fig">Fig. 1b</xref>). An aFP and scFP for an individual protein have the same dimensions, but they describe different levels of information: scFPs encapsulate the localization pattern of one cell, while aFPs describe the general spatial distribution of a protein. Below, we first use PIFiA aFPs to broadly explore protein localization and function. We then use scFPs to explore cell-to-cell heterogeneity, localization changes, and complex protein localization patterns (<xref rid="F1" ref-type="fig">Fig. 1c</xref>&#x02013;<xref rid="F1" ref-type="fig">e</xref>).</p></sec><sec id="S4"><title>Comparison of PIFiA performance to other self-supervised and supervised approaches</title><p id="P14">We compared aFPs produced by PIFiA to the representations from three computational methods, each of which has been used previously to analyze images of the yeast ORF-GFP collection<sup><xref rid="R10" ref-type="bibr">10</xref></sup>: CellProfiler<sup><xref rid="R7" ref-type="bibr">7</xref></sup>, a feature-extraction tool; DeepLoc<sup><xref rid="R8" ref-type="bibr">8</xref></sup>, a supervised deep-learning model; and Paired Cell Inpainting<sup><xref rid="R15" ref-type="bibr">15</xref></sup>, a self-supervised autoencoder-based approach. We consider a model to have good performance if protein pairs with higher correlation between their aFPs are more likely to be functionally related. We evaluated feature profiles (aFPs) using three metrics: F-score and average precision (AP), both measures of feature relevance, and adjusted mutual information (AMI), an information theoretic metric to assess clustering quality (see <xref rid="S12" ref-type="sec">Methods</xref>). PIFiA features showed superior performance on most evaluation criteria using four functional benchmarks: Gene Ontology<sup><xref rid="R29" ref-type="bibr">29</xref></sup> (GO) Cellular Components (CC), GO Slim Bioprocesses (GO BP slim), Kyoto Encyclopedia of Genes and Genomes<sup><xref rid="R30" ref-type="bibr">30</xref></sup> (KEGG) pathways and European Bioinformatics Institute (EBI) Protein Complexes<sup><xref rid="R31" ref-type="bibr">31</xref>, <xref rid="R32" ref-type="bibr">32</xref></sup> (<xref rid="F2" ref-type="fig">Fig. 2</xref>).</p><p id="P15">PIFiA reached better performance than the supervised method DeepLoc in predicting protein subcellular localization (DeepLoc&#x02019;s target task), as indicated by higher values of F-score, AP, and AMI scores, on the GO CC standard. (<xref rid="F2" ref-type="fig">Fig. 2</xref>). PIFiA also outperformed DeepLoc based on other functional standards, with the biggest performance gain in protein complex discovery. This result confirms the utility of the PIFiA training objective which targets identification of individual tagged proteins, the most detailed level of functional information present in the image. Although the objective does not directly focus on localization prediction, over the course of training the CNN implicitly learns a variety of localization patterns needed to successfully differentiate individual proteins. Thus, PIFiA self-supervised feature profiles can be used for exploratory analysis of protein localization instead of representations from a supervised method such as DeepLoc, bypassing the need for manual annotation while improving performance.</p><p id="P16">PIFiA also demonstrated better performance than Paired Cell Inpainting, another self-supervised method, achieving 1.2, 1.7, 2.2 and 10.4-fold improvements in terms of mean average precision using cellular components, bioprocesses, pathways and protein complex standards, respectively. Compared to all other approaches examined, PIFiA representations resulted in substantial improvement in clustering quality measured by AMI scores, with an average 5-fold AMI improvement over Paired Cell Inpainting (<xref rid="F2" ref-type="fig">Fig. 2a</xref>). The significant improvement on the protein complex standard is again explained by PIFiA&#x02019;s novel self-supervised objective, which forces the network to detect the most comprehensive morphological patterns while ignoring individual image artifacts, which contrasts with autoencoder-based objectives that learn features by naive image reconstruction.</p></sec><sec id="S5"><title>Evaluation of the functional information associated with PIFiA average feature profiles</title><p id="P17">To further assess the biological information associated with the aFPs of each protein, we used hierarchical clustering of aFPs as an unsupervised approach to discover feature profile similarities<sup><xref rid="R33" ref-type="bibr">33</xref></sup>. We performed agglomerative hierarchical clustering of the whole-proteome aFPs (4049 proteins in total) using a correlation metric and average linkage. We surveyed the resulting dendrogram at different thresholds to explore whether aFPs are suitable for studying the spatial architecture of the cell at different scales of its organization (<xref rid="F3" ref-type="fig">Fig. 3a</xref>, <xref rid="SD1" ref-type="supplementary-material">S2a</xref>&#x02013;<xref rid="SD1" ref-type="supplementary-material">f</xref>). The hierarchical clustering results are shown in <xref rid="F3" ref-type="fig">Fig. 3a</xref>, with 4,049 proteins on the X-axis clustered according to the similarity of their feature profiles (each column is a 64-dimensional aFP). To determine optimal cutoff thresholds, we tracked AMI scores<sup><xref rid="R34" ref-type="bibr">34</xref></sup> at different correlation thresholds for three functional standards: GO Cellular Component, GO Slim Bioprocess and Protein Complexes (<xref rid="SD1" ref-type="supplementary-material">Fig. S2b</xref>) (see <xref rid="S12" ref-type="sec">Methods</xref>).</p><p id="P18">First, we determined an optimal threshold (0.72) corresponding to the most general level of cellular organization - GO Cellular Component annotations (<xref rid="F3" ref-type="fig">Fig. 3a</xref>). The nine clusters produced at this threshold were enriched for proteins with relatively broad cell component annotations: nucleus, mitochondrion, Golgi apparatus, cytoplasm, endoplasmic reticulum (ER), actin patches, nucleolus and cytosolic ribosome (all p-value&#x0003c;10e-20 except cluster 4 with p-value&#x0003c;10e-5; <xref rid="F3" ref-type="fig">Fig. 3a</xref>,<xref rid="F3" ref-type="fig">b</xref>; <bold>Table S1</bold>; examples of cell images from each cluster are shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S2a</xref>). At this level of feature profile similarity, proteins annotated to subcellular components with visually distinct morphologies, such as organelles, tend to be in a single cluster, whereas proteins annotated to more heterogeneous cellular compartments are found in multiple clusters. For example, proteins with a <italic toggle="yes">nucleus</italic> GO cellular component annotation are enriched only in cluster 1, whereas proteins with a <italic toggle="yes">cytoplasm</italic> annotation were enriched in clusters 4, 8, and 9 (<xref rid="F3" ref-type="fig">Fig. 3a</xref>,<xref rid="F3" ref-type="fig">b</xref>). Detailed visual image inspection revealed that some clusters reflect protein localization to both the cytoplasm and another compartment, such as cluster 4 which contains subsets of proteins localized to the cytoplasm and cell surface proteins. Other clusters likely reflect differences in protein abundance, such as cluster 8, which includes a number of highly abundant proteins, including ribosomal proteins.</p><p id="P19">Next, we derived optimal correlation thresholds on our dendrogram corresponding to two additional, more detailed biological standards: GO Slim Bioprocess and Protein Complexes (<xref rid="SD1" ref-type="supplementary-material">Fig. S2b</xref>). We obtained 21 clusters for GO Slim Bioprocesses (0.64 AMI distance threshold), 20 of which were functionally enriched (GO enrichments are shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S2c</xref>; median p-value of 5e-10 across all enriched clusters; clusters&#x02019; entropies in terms of present localizations are shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S2d</xref>). Similarly, 205 clusters were found at the dendrogram cutoff corresponding to a protein complex standard (0.29 AMI, <xref rid="SD1" ref-type="supplementary-material">Fig. S2b</xref>), which had 11-fold median enrichment in protein complex predictions across all clusters (distribution of the per-cluster enrichments at 0.29 AMI cutoff is shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S2e</xref>,<xref rid="SD1" ref-type="supplementary-material">f</xref>). Hence, aFPs present robust and memory-efficient representations of protein features, which allow detection of clusters with functionally related proteins at various levels of cellular organization, with the highest functional resolution at more general levels of the hierarchy (<xref rid="SD1" ref-type="supplementary-material">Fig. S2f</xref>).</p></sec><sec id="S6"><title>Adaptation of PIFiA features to external annotations for protein localization and function</title><p id="P20">Our unsupervised clustering analysis showed that PIFiA aFPs capture information from cell images that enables label-free resolution of cellular spatial organization, grouping proteins by shared localization and biological function (<xref rid="F3" ref-type="fig">Fig. 3a</xref>,<xref rid="F3" ref-type="fig">b</xref>). We have investigated another useful property of feature profiles - adaptability for subsequent supervised training. One of our goals was to create a model that produces universal feature profiles that can be used without the requirement to re-train a full neural network from scratch on a specific task. To evaluate the adaptability of feature profiles, we used the widely adopted linear evaluation protocol<sup><xref rid="R16" ref-type="bibr">16</xref></sup>, where a linear classifier is trained on top of the representations extracted from the network, and test accuracy is used as a measure of representation quality.</p><p id="P21">We first evaluated how PIFiA features can be adapted to protein localization labels, which is the largest labeled functional standard available<sup><xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R10" ref-type="bibr">10</xref></sup>. This analysis enables assessment of whether information contained in self-supervised PIFiA features matches the content of the original images, when extracted with a supervised method. We trained a multinomial logistic regression (LR) using PIFiA scFPs from 2415 proteins manually annotated to localize to a single subcellular localization<sup><xref rid="R10" ref-type="bibr">10</xref></sup> (see <xref rid="S12" ref-type="sec">Methods</xref>). We compared the final performance of the LR trained on PIFiA scFPs to DeepLoc, a supervised neural network specifically trained to classify protein localization from images of the yeast ORF-GFP collection. To match the training protocol of DeepLoc, we used scFPs derived from the single-cell images in DeepLoc&#x02019;s training set<sup><xref rid="R8" ref-type="bibr">8</xref></sup>. We report AP scores on the same single-cell crops from the test set across the full roster of 2415 single-localized proteins (<xref rid="SD1" ref-type="supplementary-material">Fig. S3a</xref>). Remarkably, PIFiA self-supervised scFPs that were paired with LR yielded a comparable performance to the supervised network DeepLoc, even though PIFiA feature profiles are self-supervised and were fitted to localization labels solely using LR. This finding suggests that PIFiA feature profiles have rich functional content, and we can use them to predict functional protein attributes without training a full network from scratch.</p><p id="P22">To visualize adaptation of PIFiA feature profiles to the supervised localization labels, we transformed the 64-dimensional aFPs into 2-dimensional space using t-SNE<sup><xref rid="R35" ref-type="bibr">35</xref></sup> and colored them according to LR localization predictions (<xref rid="F3" ref-type="fig">Fig. 3c</xref>). Each aFP on the t-SNE projection was annotated with the localization category corresponding to the maximal LR prediction across all scFPs. In this visualization, the morphological similarity of proteins encapsulated in the aFPs was translated into proximity on the 2D t-SNE map, highlighting that the separation of self-supervised aFPs on the map was driven by subcellular localization signals. We compared the aFP localization assignments with the assignments made using supervised machine learning methods or manual annotations trained to specifically assign proteins to subcellular localizations (<xref rid="SD1" ref-type="supplementary-material">Fig. S3b</xref>). Ultimately, we observed higher quality of linear localization annotation compared to subcellular localization standards produced by other approaches<sup><xref rid="R2" ref-type="bibr">2</xref>, <xref rid="R8" ref-type="bibr">8</xref></sup> (<xref rid="SD1" ref-type="supplementary-material">Fig S3a</xref>).</p><p id="P23">These analyses show that PIFiA feature profiles can be adapted to the objective of a supervised neural network, which confirms the high information content of PIFiA features. Such adaptable feature profiles may accelerate training by replacing various task-specific supervised neural networks with one multi-purpose self-supervised approach, which yields universally applicable representations.</p></sec><sec id="S7"><title>Experimental validation of PIFiA predictions of sub-compartmental organization of the cell</title><p id="P24">We explored more specific functional information associated with PIFiA aFPs. We used Gaussian kernel density estimates<sup><xref rid="R36" ref-type="bibr">36</xref></sup> (KDEs) (see <xref rid="S12" ref-type="sec">Methods</xref>) to annotate our whole proteome 2D tSNE projection of aFPs with Gene Ontology bioprocess terms. For illustration, we selected terms from different subcellular components that had the lowest variance on the t-SNE map. This annotation showed that PIFiA features distinguished biological processes within cellular compartments (<xref rid="F3" ref-type="fig">Fig. 3d</xref>). For example, regions of the tSNE map corresponding to the cytoplasm (<xref rid="F3" ref-type="fig">Fig. 3c</xref>) had distinct regions enriched for translation initiation and elongation, P-body assembly, pentose-phosphate shunt and glycogen metabolic process (<xref rid="F3" ref-type="fig">Fig. 3d</xref>). This analysis illustrates that GFP-tagged proteins with similar biological roles have distinguishable appearances in cell images, and that PIFiA learns feature profiles that can be used to discover protein functional groups across different levels of subcellular organization, including organelles and possible sub-compartmental structures.</p><p id="P25">To further explore information in PIFiA profiles related to the sub-compartmental organization of the cell, we clustered aFPs of proteins that mapped to the same localization category to produce 15 per-compartment hierarchical trees (derived from the 15 categories defined by LR; <xref rid="F3" ref-type="fig">Fig. 3c</xref>). We selected a sub-compartmental clustering threshold of 0.5 based on the highest morphological similarity within clusters and maximal separation between clusters, measured by a Silhouette score (<xref rid="SD1" ref-type="supplementary-material">Fig. S2e</xref>). We identified 30 clusters, which are indicated on the tSNE projection of PIFiA feature profiles in <xref rid="F3" ref-type="fig">Fig. 3e</xref>, with example images of cells from each group shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S4</xref> (see also <bold>Table S2</bold> for GO enrichment and other information). We refer to these clusters using their localization category and associated group number (e.g., nuc-1 corresponds to the first sub-compartmental group in the nucleus). We provide an interactive version of the t-SNE plot from <xref rid="F3" ref-type="fig">Fig. 3e</xref> on the PIFiA website (<ext-link xlink:href="https://thecellvision.org/pifia/" ext-link-type="uri">https://thecellvision.org/pifia/</ext-link>), where each point on the plot is clickable and allows the user to explore the micrographs corresponding to the GFP-tagged protein, find its nearest neighbours and perform enrichment analysis based on the closest aFPs.</p><p id="P26">Several general features associated with the clusters in <xref rid="F3" ref-type="fig">Fig. 3e</xref> suggest that they are functionally meaningful and reflect sub-compartmental organization. First, proteins localizing to compartments which tend to be more homogeneous in their morphological patterns were typically seen in a single cluster (e.g., peroxisome, spindle pole, vacuolar membrane, nuclear periphery), while proteins associated with large or heterogeneous compartments, such as the nucleus, cytoplasm and mitochondria, defined more than one sub-compartment cluster (<xref rid="F3" ref-type="fig">Fig. 3e</xref>, <bold>Table S2a</bold>). Second, 16 of 32 groups showed &#x0003e;2-fold enrichment for a GO annotation category (<bold>Table S2b</bold>, P&#x0003c;0.01). For example, the nucleus region of the whole-proteome map was divided into five clusters, enriched in GO bioprocesses such as small molecule metabolic process, chromatin remodeling and RNA polymerase II activity, mitotic nuclear division and proteolysis (<xref rid="F3" ref-type="fig">Fig 3e</xref>, <bold>Table S2</bold>). Third, as expected, some of the groupings appeared to be based on protein features that were easily discernible. For example, <italic toggle="yes">nuc</italic>-1 clustering likely resulted from high protein abundance, and it included histones and metabolic enzymes (median GFP intensity <italic toggle="yes">nuc</italic>-1 proteins=5834&#x000b1;2103 vs median for all <italic toggle="yes">nuc</italic> proteins=745&#x000b1;793) (<bold>Table S2</bold>). For some of the other groups, clustering appeared to result from differences in the spatial distribution of pixels in a region. For example, <italic toggle="yes">cyto</italic>-3 proteins all had a prominent cytosolic signal overlaid with a punctate morphology, and most had roles in Golgi vesicle transport (<bold>Table S2</bold>, <xref rid="SD1" ref-type="supplementary-material">Fig. S4</xref>). Similarly, <italic toggle="yes">cyto</italic>-8 contained only seven proteins with no obvious functional overlap, but by visual inspection, all the proteins localized to the cytoplasm and to one or more foci (<xref rid="SD1" ref-type="supplementary-material">Fig. S4</xref>). Thus, a fraction of sub-compartmental groups could be explained by distinct protein localization features, which may correspond to coherent functionality.</p><p id="P27">For many sub-compartmental groups, however, the features driving the clustering were less obvious. To ask if we could manually identify differences between proteins from different PIFiA sub-compartments with the same overall localization, we used a more sensitive colocalization assay. We chose pairs of proteins with similar abundances, tagged them with two fluorescent proteins, mNeonGreen and mScarlet, imaged cells containing both tagged proteins, and manually assessed images (<xref rid="F3" ref-type="fig">Fig. 3f</xref>, <bold>Table S2d</bold>). Using colocalization, we observed subtle differences in most of the pairs from different sub-compartmental groups; specifically, we identified differences in 39/52 (75%) protein pairs from distinct groups, but in only 7/24 (29%) pairs from the same group (<bold>Table S2d</bold>). For example, among nuclear sub-compartmental groups, we identified a distinct localization for <italic toggle="yes">nuc</italic>-5 proteins, which were 13.5-fold enriched for components of the proteasome (P=7.78E-22). The localization of <italic toggle="yes">nuc-5</italic> proteins overlapped extensively with that of other nuclear proteins, but <italic toggle="yes">nuc-5</italic> proteins additionally localized to the nuclear periphery (<xref rid="F3" ref-type="fig">Fig. 3f</xref>, top row). We detected the nuclear periphery localization of <italic toggle="yes">nuc-5</italic> proteins when we looked at different proteasome components from nuc-5 in colocalization assays with proteins from different sub-compartmental <italic toggle="yes">nuc</italic> groups (<xref rid="SD1" ref-type="supplementary-material">Fig. S5</xref>).</p><p id="P28">In another example, we performed co-localization analysis with proteins assigned to different cell periphery (CP) groups. We examined cells expressing both a high-affinity iron transporter, Ftr1, from the <italic toggle="yes">CP</italic>-1 group, and Tcb2, a protein involved in ER-plasma membrane tethering, from the <italic toggle="yes">CP</italic>-2 group (<xref rid="F3" ref-type="fig">Fig. 3f</xref>, middle row). Ftr1, tagged with mScarlet, and Tcb2, tagged with mNeonGreen, localized to distinct regions of the cell periphery. Ftr1 localized specifically to the mother cell periphery but was absent from the bud, whereas Tcb2 was present at both the mother and daughter cell peripheries. Indeed, by visual inspection, we found that all the <italic toggle="yes">CP</italic>-1 proteins had mother-specific localization, like Ftr1. In total, the <italic toggle="yes">CP</italic>-1 group contains 21 proteins, and included 7 of the 8 proteins found previously to localize asymmetrically to mother cells, all of which are members of the MDR (multidrug resistance) transporter family: Fui1, Hip1, Hnm1, Pdr5, Snq2, Tpo1, Yor1<sup><xref rid="R37" ref-type="bibr">37</xref>, <xref rid="R38" ref-type="bibr">38</xref></sup>.</p><p id="P29">In addition to the MDR transporters, the <italic toggle="yes">CP</italic>-1 group contains 14 novel mother-specific proteins, including several other transporter proteins (Atr1, Ftr1, Hxt6, Mep1, Mep3, Qdr2, and Qdr3), proteins with roles in signaling (Gpa2, Mid2, Psr1), and three relatively uncharacterized proteins, including Ybr016w, which is a tail-anchored plasma membrane protein that is orthologous to human CYSTM1 (cysteine rich transmembrane module containing 1), Ina1, an uncharacterized protein whose paralog protein, Fat3, is required for fatty acid uptake<sup><xref rid="R39" ref-type="bibr">39</xref></sup>, and Crp1, an uncharacterized protein whose paralog protein, Mdg1, appears to modulate pheromone-mediated signaling and cell polarization<sup><xref rid="R40" ref-type="bibr">40</xref></sup> (<bold>Table S2b</bold>).</p><p id="P30">In a third test, we looked at colocalization of two proteins whose ORF-GFP fusions shows some ER localization, including Ubx2, a protein from the <italic toggle="yes">ER-3</italic> cluster involved in ER-associated protein degradation<sup><xref rid="R41" ref-type="bibr">41</xref></sup>, and Kre1, a protein from the <italic toggle="yes">ER-5</italic> cluster that normally functions as a cell wall glycoprotein<sup><xref rid="R42" ref-type="bibr">42</xref></sup><italic toggle="yes">.</italic> The <italic toggle="yes">ER-5</italic> protein, Kre1, shows an ER localization but it also concentrates more discretely at the cell periphery compared to Ubx2 (<xref rid="F3" ref-type="fig">Fig. 3f</xref>, bottom row). This localization difference was observed in other members of the sub-compartmental groups, with <italic toggle="yes">ER-3</italic> proteins, which tended generally to have a more diffuse localization than proteins in <italic toggle="yes">ER-5</italic> (<xref rid="SD1" ref-type="supplementary-material">Fig. S4</xref>).</p><p id="P31">In summary, our data show that within a compartment, PIFiA features can distinguish groups of proteins with subtle differences in localization that often have different biological roles. Many of these groups are enriched for proteins that perform biological functions not previously associated with distinctive localization patterns.</p></sec><sec id="S8"><title>Analysis of proteins with multi-compartment localization using PIFiA single-cell feature profiles</title><p id="P32">The single cell feature profiles (scFPs) produced by the PIFiA CNN provide an opportunity to explore more nuanced protein behaviors, including proteins localizing across multiple compartments. Previous analyses of the yeast ORF-GFP collection showed that a large fraction of the proteome localizes to two or more compartments in the same cell<sup><xref rid="R2" ref-type="bibr">2</xref>, <xref rid="R8" ref-type="bibr">8</xref>, <xref rid="R10" ref-type="bibr">10</xref></sup>. These studies used average statistics for cell populations, precluding differentiation of proteins that localize to multiple compartments, or those that shuttle between compartments. We annotated scFPs of every protein with localization categories using LR classification scores, and then we investigated the distribution of each protein&#x02019;s single-cell localization scores, focusing on the two most probable localizations (see <xref rid="S12" ref-type="sec">Methods</xref>). Using this strategy, we found that most (3424) proteins have a homogeneous localization (localizing to a single compartment), while 652 proteins exhibit localization heterogeneity (localizing to two or more compartments) (<xref rid="F4" ref-type="fig">Fig. 4a</xref>). We classified the proteins with heterogeneous localization into two categories: (1) 396 proteins that localize to more than one compartment in a single cell, which we refer to as AND-proteins, and (2) 256 proteins that appear either in a primary or a secondary location but not in the same cell, which we refer to as OR-proteins (<xref rid="F4" ref-type="fig">Fig. 4b</xref>,<xref rid="F4" ref-type="fig">c</xref>,<xref rid="F4" ref-type="fig">d</xref>
<bold>Table S3</bold>). For most proteins the assigned localization probabilities are continuously distributed, but our classification summarizes the localization, indicating the compartments that the protein predominantly populates. For example, Pho85, is classified as an AND-protein with a mixed signal predominantly from nucleus and cytoplasm within single cells, consistent with its known biology<sup><xref rid="R43" ref-type="bibr">43</xref></sup> (<xref rid="F4" ref-type="fig">Fig. 4c</xref>). In contrast, Stb1 is a transcription factor whose nuclear localization is cell cycle regulated and it was classified by our analysis of scFPs as being either nuclear or cytoplasmic (OR-protein), as seen in previous studies<sup><xref rid="R44" ref-type="bibr">44</xref></sup> (<xref rid="F4" ref-type="fig">Fig. 4c</xref>).</p><p id="P33">We summarized overall AND-/OR-localizations across 15 localization categories, which clearly illustrated that a large fraction of these changes involved the nucleus and cytoplasm compartments. Among the 922 proteins with a high confidence nuclear localization, 708 were solely nuclear, 159 nuclear AND cytoplasmic, and 55 nuclear OR cytoplasmic (<xref rid="F4" ref-type="fig">Fig. 4e</xref>,<xref rid="F4" ref-type="fig">f</xref>). We asked how these classes were distributed in different bioprocesses involving the nucleus<sup><xref rid="R31" ref-type="bibr">31</xref></sup>. As expected, proteins with roles in RNA processing and chromatin organization tended to be solely nuclear (<bold>Table S3</bold>). The trends for proteins that have dual localization were also consistent with well-established biology. For example, proteins with roles in cell cycle progression were 4.1-fold enriched in nucleus OR cytoplasm (P=6.7E-05). Many cell cycle proteins, in particular many transcription factors, use localization to regulate protein activity<sup><xref rid="R46" ref-type="bibr">46</xref></sup>. Proteins with roles in DNA replication/repair and stress response were weakly enriched in nucleus AND cytoplasm (1.5-fold, P= 1.40E-03 and 1.9-fold, P=9.7E-04 respectively). DNA repair proteins often alter their relative localization in the presence of damage, either to initiate a repair response or to prevent catastrophic cell cycle events<sup><xref rid="R47" ref-type="bibr">47</xref></sup>. Because our cells were not experiencing DNA damage at the time of imaging, many of these proteins displayed both nuclear AND cytoplasmic localization in our data. Hence, while many protein groups that show different patterns were too small to perform consistent enrichment analysis, enrichments that were seen for nuclear-cytoplasmic groups, where there are enough proteins to assess, were consistent with known biology.</p><p id="P34">Finally, because proteins with roles in cell cycle progression were enriched among both the OR- and the AND-proteins, we used our scFPs to assess how cell cycle position could account for some of the protein localization heterogeneity. To do so, we took advantage of the nuclear and cytoplasmic markers (td-Tomato-NLS; E2-Crimson) in our GFP collection to explore the relationship between cell cycle position and protein abundance or localization heterogeneity. We first trained an ensemble of CNNs on the nuclear and cytoplasmic RFP channels to predict one of four cell cycle stages, and we subsequently mapped each single-cell crop to a cell cycle category: T/G1 (Telophase, Gap phase 1), S/G2 (DNA synthesis phase/Gap phase 2) or M/A (metaphase/anaphase) (see <xref rid="S12" ref-type="sec">Methods</xref>). We then compared the single-cell distributions of each cell cycle stage with the localization calls to discover relationships between protein localization and cell cycle (<bold>Table S3</bold>). In total, we identified 136 proteins with cell-cycle-dependent variation in PIFiA feature profiles, determined by Mann-Whitney U test<sup><xref rid="R48" ref-type="bibr">48</xref></sup> (p-value&#x0003c;1e-3, see <xref rid="S12" ref-type="sec">Methods</xref>). Our results are summarized in the connected heatmap shown in <xref rid="F4" ref-type="fig">Fig. 4g</xref>. As expected, some of the discovered localization changes reflected cell-cycle-dependent differences in the corresponding compartment. For example, most bud neck/cytoplasm AND-localizing proteins (14/23 proteins) were cytosolic in G1 before the bud neck had formed and localized to the bud neck later in the cell cycle (<bold>Table S3</bold>). However, many cell cycle regulated proteins moved between permanent compartments, including 66 moving between the nucleus and cytoplasm. Indeed, PIFiA identified 4 proteins not previously known to be cell cycle regulated, that localized to the cytoplasm and nucleus, but showed a predominantly cytoplasmic localization in M/A (Yel025c, Atc1, Bop3, and Cmg1).</p><p id="P35">Overall, scFPs derived from the self-supervised PIFiA workflow enable resolution of single-cell localization and are suitable for cell-to-cell variability analysis. Notably, PIFiA feature profiles contain enough functional information to distinguish compartments and sub-compartmental morphologies without pre-assigned labels, enabling analysis of protein localization heterogeneity in a data-driven way, which precludes propagating annotation errors.</p></sec><sec id="S9"><title>Prediction of functional modules using PIFiA single-cell feature profiles</title><p id="P36">AMI scores at different correlation thresholds allowed us to resolve functional information associated with hierarchical clustering of PIFiA aFPs (<xref rid="F2" ref-type="fig">Fig. 2a</xref>) and determine an optimal correlation threshold for discovering functional modules, such as protein complexes (<xref rid="SD1" ref-type="supplementary-material">Fig. S2a</xref>). However, averaging feature profiles leads to information loss, which is not optimal for more precise analysis. Hence, we explored the use of single-cell feature profiles for the identification of functional modules. In particular, we focused on protein complexes, which represent functional modules whose components are expected to colocalize within a single cell.</p><p id="P37">To visually investigate protein complex distributions with scFPs, we projected scFPs from the test set using 2D tSNE (<xref rid="F5" ref-type="fig">Fig. 5a</xref>). The scFPs of proteins from the same complex often localized together on the tSNE map, but they were typically intermingled and difficult to separate from each other, which is consistent with the resolution of light microscopy. Nevertheless, the scFPs corresponding to different protein complexes with the same subcellular localization were often separated on the tSNE map (e.g., Polymerase-II, Polymerase-III and RSC in the nucleus; EGO and V-ATPase in the vacuolar membrane) (<xref rid="F5" ref-type="fig">Fig. 5a</xref>).</p><p id="P38">To further explore the utility of scFPs for algorithmically identifying protein complexes, we developed a modified hierarchical clustering approach, called adaptive thresholding, that is designed to identify correlation thresholds on the hierarchical dendogram at which scFPs inside a cluster become indistinguishable, and thus might be expected to contain interacting proteins (see <xref rid="S12" ref-type="sec">Methods</xref>). We performed hierarchical clustering of test set scFPs using average linkage and a correlation metric. We then traced the number of unique proteins inside the cluster along with the divisions of the single-cell dendrogram to discover levels of the dendrogram at which the number of proteins in a cluster plateaus (<xref rid="F5" ref-type="fig">Fig. 5b</xref>). Such plateaus identify levels of the global scFPs dendrogram at which single-cell features are practically inseparable, a division threshold that we call a root cluster (see <xref rid="S12" ref-type="sec">Methods</xref>). For example, our adaptive thresholding method identified a root cluster corresponding to the nuclear pore complex, which distinguished it from other nuclear periphery proteins (<xref rid="F5" ref-type="fig">Fig 5b</xref>).</p><p id="P39">We compared the adaptive thresholding method to other clustering approaches from three different families - connectivity (hierarchical clustering<sup><xref rid="R33" ref-type="bibr">33</xref></sup>), centroid (k-means<sup><xref rid="R49" ref-type="bibr">49</xref></sup>) and density methods (DBSCAN<sup><xref rid="R50" ref-type="bibr">50</xref></sup>) (<xref rid="F5" ref-type="fig">Fig. 5c</xref>). For each of the methods used in our comparison, we tried a range of hyperparameters and selected the ones that maximized median F1-score (see <xref rid="S12" ref-type="sec">Methods</xref>). Evaluation was performed on a set of 140 protein complexes that contain at least three proteins included in the ORF-GFP localization dataset<sup><xref rid="R31" ref-type="bibr">31</xref></sup>. Our approach outperformed other methods in terms of four different scores - fold enrichment, F1 score, precision, and recall (<xref rid="F5" ref-type="fig">Fig. 5c</xref>). The distributions of scores highlight the advantages of our adaptive thresholding approach. Density-based clustering fails at the protein complex identification task due to the high density of the feature space. At the same time, k-means fails at the identification of larger protein complexes (more than 5 protein members), hence its violin plot has two peaks. Hierarchical clustering is a more advantageous approach for this task, yet it requires information on the distance threshold and lacks adaptability for the protein complex size and cellular compartment. In contrast, our adaptive thresholding approach finds an optimal distance threshold for each cluster and, hence, it can discover protein complexes of varying sizes.</p><p id="P40">Using the adaptive thresholding clustering approach, we constructed a list of 88 high-confidence clusters whose proteins were indistinguishable at the single cell level (<bold>Table S4</bold>, <xref rid="F5" ref-type="fig">Fig. 5d</xref>). We mapped each cluster to a protein complex with the maximal fold enrichment and saw a median fold enrichment of 36.5 across 88 clusters, which is a 3-fold improvement over our clustering of aFPs with an optimized cut-off (<xref rid="F2" ref-type="fig">Fig. 2</xref>). Of the 88 predicted clusters, 43 captured members of 32 different protein complexes distributed across 15 subcellular compartments (<bold>Table S4</bold>). The remaining clusters did not capture two or more members of the same protein complex, although in 25/45 cases they contained PPIs (as annotated in BioGrid<sup><xref rid="R51" ref-type="bibr">51</xref></sup>). By using proteins from the same localization as our background set to compute fold enrichment, we tested whether the clusters could differentiate a protein complex from others in the same subcellular location (see <xref rid="S12" ref-type="sec">Methods</xref>). We discovered that PIFiA confidently predicted members of protein complexes in multiple compartments, such as: [1] the proteasome and Ada2/Gcn5/Ada3 transcription activation complex in the nucleus; [2] LSM2&#x02013;7 complex, decapping complex and translation initiation factor 2B complex in the cytoplasm; [3] the oligosaccharyl transferase and Sec62-Sec63 complexes in the ER; [4] vacuolar proton translocating ATPase complex, phosphatidylinositol 3-kinase complex and iron exporter complex in the vacuolar membrane; [5] F-actin capping protein complex and PAN1 actin cytoskeleton-regulatory complex in the actin cytoskeleton; [6] Spc105 complex and NDC80 complex in the spindle pole; [7] retromer complex and SNX4-SNX41 sorting nexin complex in endosomes (see <bold>Table S4</bold>).</p><p id="P41">In some cases (17/44), we identified all members of a complex, together with some additional proteins, which may be previously unappreciated complex components or members of an extended functional module, such as regulators or target proteins. For example, cluster #6 contained all 4 subunits of the COMA complex, a kinetochore component that connects proteins bound to centromeric DNA with those bound to microtubules, as well as nine additional proteins, eight of which display protein-protein interactions (PPIs) with COMA members<sup><xref rid="R51" ref-type="bibr">51</xref></sup>. Other clusters identified proteins with the same biological role, that may participate in PPIs. For example, cluster #39 contained 26 proteins that localized to the nuclear periphery in a punctate fashion. This group contained the only two GFP-tagged members of the TREX-2 complex, which couples SAGA-dependent gene expression and transcription elongation to mRNA export at the nuclear pore complex. Cluster #39 also included 8 proteins reported to have PPIs with members of the TREX complex, suggesting they may function in concert with the complex<sup><xref rid="R51" ref-type="bibr">51</xref></sup>. Among the remaining proteins were members of a silencing complex, including Sir2, Sir3, Sir4 and the Sir4-interacting protein Esc1, which suppresses transcription at subtelomeric regions, tethering them to the nuclear periphery<sup><xref rid="R52" ref-type="bibr">52</xref></sup>. Thus cluster #39 identified proteins with roles in gene expression that localize to the nuclear periphery, some of which function to modulate each other&#x02019;s activity.</p><p id="P42">In summary, we have developed a novel approach for discovery of functional modules using solely the self-supervised feature profiles and leveraging the properties of microscopy data for optimal clustering, and prediction of molecular interactions.</p></sec><sec id="S10"><title>Interpretation of PIFiA features</title><p id="P43">Our analysis shows that PIFiA feature profiles contain condensed information about protein function at various levels of granularity. However, since deep neural networks function as &#x02018;black-box&#x02019; models, it is difficult to dissect feature profiles and explain how individual features are related to the input images. To attempt to interpret PIFiA features, we first quantified feature importance for 15 different localization categories covering a diverse set of subcellular morphological patterns. We used the LR model described earlier to derive importance scores for each feature; the coefficients of the trained LR quantify how much each feature is predictive of a certain localization (<xref rid="F6" ref-type="fig">Fig 6a</xref>). Most localizations had more than three strongly predictive features (LR coefficient value &#x0003e;5), suggesting that PIFiA learns to detect several distinctive patterns for each subcellular compartment. This confirms that PIFiA learns localization patterns with its convolutional filters, despite being trained on a completely different self-supervised objective. Also, the same feature could be predictive for several localizations (for example, features #3 and #28 recognize circular patterns corresponding to the vacuolar membrane and nuclear periphery), or react to some variation of visual patterns present in multiple localizations. Overall, larger and more complex compartments required more features to be confidently classified. To illustrate this finding, we plotted classification accuracy for the three largest compartments (cytoplasm, nucleus and mitochondria), as well as three homogeneous compartments (nucleolus, peroxisome and vacuolar membrane) with respect to the number of features used during LR training (see <xref rid="S12" ref-type="sec">Methods</xref>) (<xref rid="F6" ref-type="fig">Fig. 6b</xref>,<xref rid="F6" ref-type="fig">c</xref>, <xref rid="SD1" ref-type="supplementary-material">S7a</xref>). While larger localization categories required approximately 30 features to reach their best performance, smaller localizations reached a saturation point at around 10 features.</p><p id="P44">Another way to interpret features learned by a CNN is to find regions of the image that had a large influence on the final result<sup><xref rid="R53" ref-type="bibr">53</xref>, <xref rid="R54" ref-type="bibr">54</xref></sup>. Using gradient calculations, importance scores can be assigned to the input image pixels depending on the degree to which they affect the classification result or individual feature values (see <xref rid="S12" ref-type="sec">Methods</xref>). We used the SmoothGrad<sup><xref rid="R54" ref-type="bibr">54</xref>, <xref rid="R55" ref-type="bibr">55</xref></sup> approach to construct gradient maps for several features of the same protein image. We selected proteins representing five distinct subcellular localizations: Nup2 from nuclear periphery, Mcm2 from nucleus, Scs2 from ER, Ftr1 and Pst2 from cell periphery, and Pex3 from peroxisome. For each of the proteins, we used its scFPs to calculate 64 gradient maps for each of the individual features and selected four visually distinct gradient maps with the highest activation values for illustration purposes (<xref rid="F6" ref-type="fig">Fig. 6d</xref>, <xref rid="SD1" ref-type="supplementary-material">S7b</xref>). We observed that different features of the same image resulted in different gradient maps. For example, gradient maps of the Mcm2 protein highlighted the nuclear periphery region, focus points in the nucleus and nuclear background signal. Similarly, different features of Ftr1 reacted to various subregions of the cell periphery. Of note, the generated gradient maps showed that the region of network attention was always the single central cell of the crop even for crops containing more than one cell, confirming that per-crop feature profiles are in fact single-cell profiles (<xref rid="F6" ref-type="fig">Fig. 6d</xref>, with Mcm2, Ftr1 and Pst2 proteins containing multiple cells in their crop, <xref rid="SD1" ref-type="supplementary-material">S7b</xref>). Gradient-based interpretability approaches are useful to explain the relationship between individual features in the feature profile vector and input pixels in the image, and they constitute an important component of our downstream analysis pipeline. Hence, despite PIFiA&#x02019;s self-supervised training objective, we can visually understand what each learned feature represents in terms of the input image regions.</p></sec></sec><sec id="S11"><title>Discussion</title><p id="P45">We describe PIFiA, a self-supervised computational workflow that learns protein functional signatures from single-cell fluorescence microscopy data. Feature profiles learned by PIFiA show state-of-the-art performance on a variety of biological functional benchmarks, outperforming existing approaches for protein representation learning. Notably, our approach does not require any labels or annotations during training and uses only a single fluorescent channel. Hence, PIFiA can be easily applied to virtually any imaging dataset. We pre-trained PIFiA on a large-scale dataset encompassing over three million single-cell images of yeast cells expressing 4,049 GFP-fusion proteins &#x02013; a scale comparable to that of the commonly used computer vision dataset, ImageNet<sup><xref rid="R56" ref-type="bibr">56</xref></sup>. As with ImageNet, we show that the yeast ORF-GFP dataset is a source for high-quality representation learning, enabling PIFiA to learn universal feature profiles that can be used out-of-the-box or minimally fine-tuned to suit an external standard. Thus, PIFiA can accelerate the rate of supervised training on external tasks by producing feature profiles that can fit any downstream task with simple linear regression, replacing multiple task-specific convolutional networks.</p><p id="P46">The PIFiA workflow unites a self-supervised convolutional neural network with multiple techniques for downstream feature profile analysis. The key advantage of our self-supervised objective is its independence of human annotations and its ability to learn high-quality features and ignore imaging artifacts and cell positions<sup><xref rid="R15" ref-type="bibr">15</xref>, <xref rid="R22" ref-type="bibr">22</xref>, <xref rid="R57" ref-type="bibr">57</xref></sup>. To ensure that PIFiA remembers solely the biologically relevant patterns, yet ignores cell positioning and replicate noise, we require the network to learn the actual GFP-tagged protein by predicting its identify. Overall, we show that features learned by PIFiA outperform another self-supervised method, Paired Cell Inpainting<sup><xref rid="R15" ref-type="bibr">15</xref></sup>, that was used to analyze the yeast GFP collection and even reaches the performance of the supervised approach, DeepLoc<sup><xref rid="R8" ref-type="bibr">8</xref></sup>, in its target task.</p><p id="P47">We describe downstream analysis techniques that use PIFiA feature profiles to explore different levels of subcellular organization that span both protein-level and single-cell feature profiles. Of note, our analysis focuses not only on the construction of a whole-proteome hierarchical map, but also provides quantitative rules to obtain clusters corresponding to a specific level of cellular organization, such as sub-cellular localization or biological process, and to identify proteins with multiple localizations and interacting proteins. This type of unbiased analysis can reveal unexpected properties and potential functions of proteins that can be further explored experimentally. For example, we used PIFiA features taken from images of yeast cells expressing GFP-tagged proteins to identify sub-compartmental groups enriched for proteins with biological processes not previously known to have distinctive subcellular localization patterns (<xref rid="F3" ref-type="fig">Fig 3e</xref>,<xref rid="F3" ref-type="fig">f</xref>). For example, we found that in addition to the known pan-nuclear localization, proteasome components are also localized at the nuclear periphery, a result we confirmed with co-localization experiments (<xref rid="SD1" ref-type="supplementary-material">Fig. S5</xref>). Nuclear periphery localization of proteasomes has not been reported in yeast, but an in situ cryo-electron tomography study in <italic toggle="yes">Chlamydomonas</italic> found nuclear 26S proteasomes crowding around nuclear pore complexes<sup><xref rid="R58" ref-type="bibr">58</xref></sup>. The role of proteasomes at the nuclear periphery may be to regulate transcription and/or to degrade proteins transiting the nuclear pore complex<sup><xref rid="R58" ref-type="bibr">58</xref></sup>.</p><p id="P48">We also identified a group of proteins that localized specifically at the cell periphery of mother cells and were depleted from the growing bud. Budding yeast divide asymmetrically, with a replicative lifespan of 20&#x02013;30 generations, where each division gives rise to a daughter whose replicative lifespan is reset and a mother who continues to age<sup><xref rid="R59" ref-type="bibr">59</xref></sup>. Mother-specific cell periphery localization is achieved when three conditions are fulfilled<sup><xref rid="R37" ref-type="bibr">37</xref></sup>. First, mother-specific proteins lack diffusive mobility in the plasma membrane. Second, newly synthesized proteins are deposited specifically in the growing bud. Third, the genes encoding these mother-specific proteins are expressed late in the cell cycle, so for cells in S/G<sub>2</sub> (small-budded cells) protein is detectable only in the mother. These steps ensure that the new and old pools of these proteins become spatially segregated during asymmetric division. Indeed mother-specific localization of cell periphery proteins has been proposed to play a role in aging, with the daughter cell getting the newly synthesized copies of the protein, and the older and potentially more damaged copies inherited by the aging mother<sup><xref rid="R37" ref-type="bibr">37</xref></sup>. Our set of asymmetrically segregating proteins includes 7 proteins previously seen to have mother-specific localization, plus 14 novel mother-specific proteins, including other transporters, proteins with roles in signaling, and 3 uncharacterized cell surface proteins (<bold>Table S2</bold>). It is possible that accumulation of old and damaged versions of these newly identified proteins may also play a role in mother-specific aging.</p><p id="P49">We also applied PIFiA features for the identification of interacting proteins and members of protein complexes. To accomplish this, we used an adaptive thresholding method for single-cell clustering that exploits the biological properties of protein-protein interactions and microscopy data, outperforming conventional clustering methods for identifying members of protein complexes. We show that proteins whose single-cell PIFiA features are indistinguishable can be members of the same protein complex, have PPIs with each other, or have functionally related biological roles. A similar approach, <italic toggle="yes">cytoself</italic>, was used to visually separate protein complexes from different compartments in human cells on tSNE. We demonstrate that PIFiA can distinguish protein complexes from the same compartment in yeast cells, which are 5 to 30-fold smaller in size, providing a quantitative approach for downstream analysis and identification of functionally related proteins.</p><p id="P50">In summary, the PiFiA pipeline extracts high quality functional information about proteins from cell images in a quantitative form, without relying on a pre-existing labels or manual annotations. In essence, the approach performs <italic toggle="yes">in silico</italic> colocalization, and it can be used to identify novel properties of proteins, including similarity and variability, that have the potential to inspire new experiments to uncover novel biological insights.</p></sec><sec id="S12"><title>Methods</title><sec id="S13"><title>Construction of mutant arrays for Imaging</title><p id="P51">For imaging screens, BY5299 (<italic toggle="yes">MAT</italic>&#x003b1; <italic toggle="yes">his3&#x00394;1 leu2&#x00394;0 ura3&#x00394;0 met15&#x00394;0</italic> lyp1pr::TDH3pr-E2-Crimson::HPH::<italic toggle="yes">lyp1</italic>&#x00394; <italic toggle="yes">can1</italic>pr::TDH3pr-tdTomato-NLS::<italic toggle="yes">URA3</italic>::<italic toggle="yes">can1</italic>&#x00394;::STE2pr-<italic toggle="yes">LEU2)</italic> was used as the starting query strain. E2-Crimson and td-Tomato-NLS are used as cytosolic and nuclear markers respectively. The starting strain was crossed to the <italic toggle="yes">MAT</italic><bold>a</bold> ORF-GFP collection<sup><xref rid="R10" ref-type="bibr">10</xref></sup> and haploid strains carrying both the red fluorescent protein markers and the ORF-GFP were selected using the SGA method<sup><xref rid="R28" ref-type="bibr">28</xref></sup>. All SGA selection steps were conducted at 30&#x000b0;C, except sporulation, which was conducted at 22&#x000b0;C for 10 days. The screen was performed in two biological replicates.</p></sec><sec id="S14"><title>High-throughput microscopy</title><p id="P52">Yeast cultures were prepared for microscopy and imaged as previously described<sup><xref rid="R2" ref-type="bibr">2</xref>, <xref rid="R3" ref-type="bibr">3</xref>, <xref rid="R6" ref-type="bibr">6</xref>, <xref rid="R60" ref-type="bibr">60</xref></sup>. Briefly, haploid wild-type <italic toggle="yes">MAT</italic><bold>a</bold> strains expressing fluorescent protein fusions from SGA final selection plates were grown at 30&#x000b0;C in low fluorescence synthetic minimal medium with Geneticin (200&#x003bc;g/mL) and Noursoethricin (100&#x003bc;g/ml). Cells were transferred to 384-well PerkinElmer CellCarrier Ultra imaging plates and centrifuged for 1 minute at 500 g before imaging. Micrographs were obtained on an Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. All imaging was done with a 63&#x000d7; water immersion objective. GFP was excited using a 488 nm laser and emission collected through a 520/35 nm filter. tdTomato was excited using a 561 nm laser, and emission collected through a 600/40 nm filter. E2Crimson was excited using a 640 nm laser, and emission collected through a 690/50 nm filter.</p></sec><sec id="S15"><title>Image acquisition for co-localization experiments</title><p id="P53">Protein pairs were chosen for co-localization if they had similar abundance<sup><xref rid="R27" ref-type="bibr">27</xref></sup> and localized to the same general subcellular compartment. For each protein, C-terminal fusions to both mNeonGreen and mScarlet were constructed as previously described<sup><xref rid="R61" ref-type="bibr">61</xref></sup>. Haploid cells in both configurations were mated to construct <bold>a</bold>/&#x003b1; diploids containing proteins tagged with the two fluorescent proteins. Diploid cells were grown and imaged in low fluorescence synthetic minimal media<sup><xref rid="R62" ref-type="bibr">62</xref></sup> supplemented with Hygromycin B (300mg/mL), Geneticin (300mg/mL) and 2% glucose. Cells were grown at 30&#x000b0;C to mid-logarithmic phase and transferred to Concanavalin A-coated 384-well PerkinElmer CellCarrier Ultra imaging plates. Images were acquired at 22&#x000b0;C using the Opera Phenix (PerkinElmer) automated spinning disc confocal microscope. Three image fields of 5 Z-stacks of optical sections 0.7&#x003bc;m apart taken for each well. Each field contained 100&#x02013;150 cells, acquired using the 63x water immersion objective. mNeonGreen was excited using the 488 nM laser, with emissions collected through a 520/35 nm filter. mScarlet-I was excited using the 561 nm laser, with emissions collected through a 600/40 nm filter. Digital Phase Contrast was used for cell detection using LED bright field imaging. All images were assessed by visual inspection.</p></sec><sec id="S16"><title>Dataset overview and image preprocessing</title><p id="P54">Images of the 4049 strains expressing a GFP-tagged protein visible above background fluorescence were obtained using an automated confocal microscope as described above. Cell images were obtained from two biological replicates, each of which had four fields of view for each GFP-tagged strain.</p><p id="P55">As the first step of preprocessing, we computed cell centers&#x02019; coordinates across all images in the dataset using the nuclear channel. We obtained coordinates of the cells&#x02019; centers by segmenting the nuclear channel with a simple Watershed algorithm and computing x, y coordinates of the center of each cell&#x02019;s nucleus<sup><xref rid="R7" ref-type="bibr">7</xref></sup>. We ignored cells with centers too close to the crop&#x02019;s boundary (less than 10 pixels). Based on the cell center coordinates, we created single-cell crops of 64&#x000d7;64 pixels around those centers across all images in the dataset. We filtered crops that had GFP signal intensity less than the 5th percentile of the whole-proteome GFP intensity distribution, and crops dominated by the background noise (i.e., a uniform signal across the whole crop, with variance). After filtering low-quality crops, we dropped proteins with less than 10 cells, and we obtained 3,058,961 unique cells in the dataset. Then, the dataset was split into training, validation and test sets using 80%, 10% and 10% of the cells of each protein respectively. The training subset contained 2,450,801 single-cell crops, and validation and test subsets contained 304,080 single-cell crops each. Finally, we applied instance normalization by standardizing the raw pixel intensities of every crop to a mean of 0 and a variance of 1 (independently for each channel of each sample). PIFiA was trained on 64&#x000d7;64 pixel crops of the GFP channel. During training, we used random flipping (horizontal and vertical) and random rotation across {0, 90, 180, 270} degrees to augment the training data. Labels of the training set are one-hot class vectors of length 4049.</p></sec><sec id="S17"><title>Architecture and training</title><p id="P56">The architecture details are illustrated in <xref rid="SD1" ref-type="supplementary-material">Fig. S1a</xref>. The backbone of PIFiA consists of eight convolutional blocks followed by three fully-connected layers. Each convolutional block consists of a convolutional layer, batch normalization and rectified linear unit activation. Training was performed using Adam optimizer<sup><xref rid="R63" ref-type="bibr">63</xref></sup> with a learning rate of 1e-3 and cosine decay learning rate schedule (number of steps equal to the number of training updates during 30 epochs), with cross-entropy as an objective function (<italic toggle="yes">y</italic><sub><italic toggle="yes">i</italic></sub> and <inline-formula><mml:math id="M1" display="inline"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/></mml:math></inline-formula> are predicted probability and ground truth label of the protein i; N is the total number of classes, i.e.,4049 proteins):
<disp-formula id="FD1">
<mml:math id="M2" display="block"><mml:mi>L</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mspace width="0.25em"/></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">log</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>
</disp-formula>
To prevent overfitting, we applied dropout regularization<sup><xref rid="R64" ref-type="bibr">64</xref></sup> of 0.05 (5% dropout rate) after the second fully-connected layer (feature extraction layer). We performed hyperparameter optimization and selected the learning rate from {1e-4, 3e-4, 5e-4, 8e-4, 1e-3, 3e-3, 5e-3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5} based on maximal validation accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. To report the performance, we ran the model three times with different random weights initializations; each run was 30 epochs and model weights were saved after every epoch. All the experiments were performed in Python using Tensorflow. The model was trained on the computing cluster of the Vector Institute for Artificial Intelligence, using NVIDIA T4 GPU with 12GB of VRAM, and up to 32GB of system RAM (single CPU). Source code and usage examples are available at <ext-link xlink:href="https://github.com/arazd/pifia" ext-link-type="uri">https://github.com/arazd/pifia</ext-link>.</p><p id="P57">We used early stopping to select the final model<sup><xref rid="R65" ref-type="bibr">65</xref></sup>. We defined stopping criteria based on the model&#x02019;s test accuracy of proteins classification across 4049 protein classes. We stop at an epoch where a derivative of the test accuracy becomes smaller than a threshold of 0.5% for at least 3 epochs, i.e., a point at which accuracy starts to saturate (<xref rid="SD1" ref-type="supplementary-material">Fig. S1b</xref>). Our goal was to stop at the point when the model has already grasped the most important morphological patterns, yet highly related and interacting proteins are not distinguished from each other. This trend is further illustrated by plots of average precision, F-score and precision (we show 0.9 threshold) for protein complexes and pathways standards (<xref rid="SD1" ref-type="supplementary-material">Fig. S1b</xref>). With protein prediction accuracy increasing over the course of training, the precision improved, but after some epochs, AP and F-score either saturated or started to decline. We found that accuracy saturation thresholds between 0.2% and 0.7% yielded comparable and optimal solutions, though other stopping points can be used depending on the training schedule, as well as model applications and goals. The proposed early stopping strategy helped to prevent memorizing noise and unnecessary patterns, while retaining morphologically similar proteins close in the feature space.</p></sec><sec id="S18"><title>Benchmarking and baseline feature extraction</title><p id="P58">We compared performance of feature profiles learned by PIFiA to features from three other popular methods for protein representation learning / extraction - DeepLoc<sup><xref rid="R8" ref-type="bibr">8</xref></sup>, Paired Cell Inpainting<sup><xref rid="R15" ref-type="bibr">15</xref></sup> and CellProfiler<sup><xref rid="R7" ref-type="bibr">7</xref></sup>.</p><p id="P59">A classic modular feature extraction tool, Cell Profiler, was applied to the GFP and cytoplasmic channels of the test images across 4,049 GFP-tagged proteins. We obtained 433 pre-defined CellProfiler features that quantitatively measure cellular phenotypes, including intensity, shape and texture. Since some of the CellProfiler features can be repetitive, its representations are often post-processed with Principal Component Analysis<sup><xref rid="R66" ref-type="bibr">66</xref></sup> (PCA). In our work, we evaluated both the original CellProfiler representation with 433 individual features, and its PCA projection (37 individual features) that explains 99% of the variance.</p><p id="P60">We used the DeepLoc model by Kraus et. al.<sup><xref rid="R8" ref-type="bibr">8</xref></sup> as our supervised learning baseline. We trained DeepLoc from scratch on the GFP channel of the same training set images using 1,432,774 single-cell crops from 15 one-hot localization categories derived from Huh et. al.<sup><xref rid="R10" ref-type="bibr">10</xref></sup> We performed hyperparameter optimization and selected the most optimal learning rate from {1e-4, 3e-4, 5e-4, 8e-4, 1e-3, 3e-3, 5e-3} and dropout rate from {0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5}. We chose 3e-4 learning rate with cosine decay learning rate schedule and 0.05 dropout rate based on maximal validation accuracy. The model was trained with Adam optimizer for 30 epochs (model weights were saved every epoch for subsequent evaluation), with cross-entropy as an objective function, <inline-formula><mml:math id="M3" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M4" display="inline"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> are predicted probability and ground truth label of localization i, total N=15 localization classes):
<disp-formula id="FD2">
<mml:math id="M5" display="block"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>log</mml:mi><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math>
</disp-formula>
We also used early stopping to select the final DeepLoc model weights. DeepLoc model selection was based on maximal validation set accuracy. Network parameters were initialized using a truncated normal distribution function with a standard deviation of 0.1. We performed 3 runs with different random weights initializations and performed training with a batch size of 128. After training, we extracted features of the test set images from the last hidden layer of the DeepLoc model following previous studies<sup><xref rid="R15" ref-type="bibr">15</xref>, <xref rid="R67" ref-type="bibr">67</xref></sup>.</p><p id="P61">For our self-supervised learning baseline, we used the Paired Cell Inpainting method<sup><xref rid="R15" ref-type="bibr">15</xref></sup>. Contrary to other models, Paired Cell Inpainting requires two channels for training - cytoplasmic background and target protein; hence we performed training of Paired Cell Inpainting using the GFP and cytoplasmic channels of the test images across 4,049 GFP-tagged proteins. We used the exact same architecture and training objective described by Lu et. al. The objective function minimizes a standard pixel-wise mean-squared error loss between the predicted target protein <inline-formula><mml:math id="M6" display="inline"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mspace width="0.25em"/></mml:math></inline-formula> and the actual target protein <inline-formula><mml:math id="M7" display="inline"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (h and <italic toggle="yes">w</italic> are pixels across image width and height respectively):
<disp-formula id="FD3">
<mml:math id="M8" display="block"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math>
</disp-formula>
We performed hyperparameter optimilzation and selected an optimal learning rate of 1e-4 from {1e-4, 3e-4, 5e-4, 8e-4, 1e-3, 3e-3, 5e-3}. The Model was trained with Adam optimizer for 30 epochs (3 runs in total), and model weights were saved every epoch for subsequent evaluation. We selected the final model with early stopping based on the minimal validation set loss. After training, we extracted feature profiles of the test set images by maximum pooling the output of an intermediate convolutional layer, across spatial dimensions, as suggested by Lu et. al.<sup><xref rid="R15" ref-type="bibr">15</xref></sup></p></sec><sec id="S19"><title>Evaluation of aFPs</title><p id="P62">Functional benchmarks used for assessment of the quality of the resulting feature profiles were derived from Gene Ontology Cellular Component<sup><xref rid="R29" ref-type="bibr">29</xref></sup> (4045 protein annotations), Gene Ontology Slim Biological Process<sup><xref rid="R29" ref-type="bibr">29</xref></sup> (3968 protein annotations), KEGG pathways<sup><xref rid="R30" ref-type="bibr">30</xref></sup> (1422 protein annotations) and EMBL protein complexes<sup><xref rid="R31" ref-type="bibr">31</xref></sup> (1402 protein annotations). Dubious ORFs and proteins without annotations were left out during comparison. To evaluate resulting features without further fine-tuning, we used strategies from two distinct perspectives: information retrieval and clustering quality.</p><p id="P63">Following standard practice, we computed pairwise distances across all available aFPs (4049&#x000d7;4049 distances in total) and sorted them from highest to lowest. Then protein pairs (which were not left out) were marked as positive if they had the same annotations, or negative otherwise, and AP and F-scores were computed. For proteins to be considered a positive pair, we required an exact agreement between labels in case of pathways and protein complexes standards, while for GO annotations we required at least 50% of the labels to overlap (due to high quantity of assigned labels). Results reported in <xref rid="F2" ref-type="fig">Fig. 2b</xref>, <xref rid="F2" ref-type="fig">c</xref> are based on ranking aFP pairs with correlation distance, and we found similar trends when using euclidean and cosine distances. We chose to continue analyses with the correlation metric due its lower susceptibility to fluctuations in individual feature values, and hence higher tolerance to outliers, which is a desirable property for the PIFiA workflow. For the clustering-driven benchmark, we clustered aFPs and compared clusters to the sets of proteins annotated to a certain term, and for each standard (we required cluster size to be at least 2 to be informative). For comparison, we applied AMI<sup><xref rid="R34" ref-type="bibr">34</xref></sup> score between the resulting clusters and protein groups related to a certain term (with a higher score indicating more agreement between clusters and standard-defined categories). To obtain an AMI score for each method, we performed hierarchical clustering (with average linkage and correlation as a distance) of its per-protein representations and derived clusters across all similarity thresholds between 0.1 and 0.95 with a step of 0.05, and reported the maximal AMI across clusterings. For each deep learning model, feature profile evaluation was performed across 3 runs (results shown with bar plots in <xref rid="F2" ref-type="fig">Fig. 2</xref>).</p></sec><sec id="S20"><title>Visualization of PIFiA feature profiles (aFPs and scFPs)</title><p id="P64">We used t-SNE<sup><xref rid="R35" ref-type="bibr">35</xref></sup> for visualization of PIFiA feature profiles. We set the perplexity parameter to 40 for visualization of whole-proteome feature profiles averaged on the per-protein level (~4000 points) (<xref rid="F3" ref-type="fig">Fig. 3c</xref>,<xref rid="F3" ref-type="fig">d</xref>,<xref rid="F3" ref-type="fig">f</xref>), and to 200 for visualizing single-cell feature profiles from the test set (&#x0003e;100,000 points) (<xref rid="F5" ref-type="fig">Fig. 5a</xref>). We represented the distribution of fundamental GO bioprocesses with a kernel-density estimate (KDE) using Gaussian kernels<sup><xref rid="R36" ref-type="bibr">36</xref></sup> (<xref rid="F3" ref-type="fig">Fig. 3d</xref>). We applied outlier filtering by removing points that do not lie within two standard deviations from the mean (across x or y t-SNE coordinates). We used Scott&#x02019;s rule for KDE bandwidth selection<sup><xref rid="R68" ref-type="bibr">68</xref></sup>.</p></sec><sec id="S21"><title>Hierarchical clustering with aFPs</title><p id="P65">We performed agglomerative hierarchical clustering<sup><xref rid="R33" ref-type="bibr">33</xref></sup> of the whole-proteome aFPs (4049 in total) using correlation as a distance metric and average linkage. The optimal cut-off distance for the whole-proteome hierarchical clustering was determined using the AMI curve between clustering labels and provided standard annotations, following the diminishing returns principle to find the elbow point. At the optimal distance cutoff, the slope of the curve becomes negligible, indicating that the available clusters cover most of the standard&#x02019;s functional groups. In <xref rid="F3" ref-type="fig">Fig. 3</xref> we used GO Cellular Component<sup><xref rid="R29" ref-type="bibr">29</xref></sup> annotations as a standard and calculated clustering labels at different correlation thresholds between 0 and 1, with a step of 0.01. Clustering was performed on the whole-proteome feature profiles, and AMI scores were calculated on a subset of proteins that had a single annotation according to GO Cellular Component. We identified an optimal cut-off point when the derivative of the AMI curve (calculated over 20 steps, starting at correlation of 1) was less than a threshold of 0.1. The proposed strategy can be used on different standards, without requiring annotations to cover all proteins (<xref rid="SD1" ref-type="supplementary-material">Fig. S2a</xref>).</p></sec><sec id="S22"><title>Training logistic regression</title><p id="P66">To perform localization mapping, we trained a multinomial logistic regression (LR) using single-cell feature profiles obtained with PIFiA from the training set. We used supervised labels from 17 manually annotated localizations defined by Huh et. al.<sup><xref rid="R10" ref-type="bibr">10</xref></sup> (we left out &#x0201c;ambiguous&#x0201d; category and classes with 5 or less proteins), and limited our training set to proteins that had a single annotated localization. Overall, our training set consisted of 1,432,774 single-cell feature profiles and included 2415 proteins from mitochondrion (465), nucleus (472), cytoplasm (799), actin (27), ER (245), vacuole (95), bud neck (8), spindle pole (35), Golgi (15), peroxisome (20), vacuolar membrane (47), cell periphery (51), nuclear periphery (45), endosome (28), and nucleolus (63). We followed our previously described dataset split (each protein&#x02019;s single-cell crops were split into train, validation and test sets with 8:1:1 ratios). We used NVIDIA T4 GPU with 12GB of VRAM, and up to 16GB of system RAM on a single CPU to accelerate training; we trained LR for 5 epochs using Adam optimizer<sup><xref rid="R63" ref-type="bibr">63</xref></sup> (1e-3 learning rate) and cross-entropy as a training loss; LR weights were saved after every epoch and we selected the final LR model with early stopping based on maximal validation set accuracy. Of note, after 2 epochs LR predictions stabilized and the difference between subsequent models was minimal (less than 3% test accuracy deviations).</p><p id="P67">To evaluate the quality of LR predictions, we compared its test set performance with DeepLoc<sup><xref rid="R8" ref-type="bibr">8</xref></sup> (training procedure described in the benchmarking section). DeepLoc and LR were trained and evaluated on the sets of the same size and protein composition, with the only difference being DeepLoc used image crops for training, while LR using self-supervised scFPs from the pre-trained PIFiA model. Precision-recall curves for PIFiA LR and DeepLoc were generated on unseen scFPs and corresponding images from the test set of the single-localizing proteins (<xref rid="SD1" ref-type="supplementary-material">Fig. S3b</xref>).</p></sec><sec id="S23"><title>Sub-compartmental clustering with aFPs</title><p id="P68">We performed sub-compartmental clustering using single-localizing aFPs from the test set that were classified to the same localization by the previously described LR. For an aFP to be single-localizing, we required that its highest softmax probability was at least 0.6, and second-highest was no greater than 0.2 (more detailed analysis of single-localizing proteins and localization heterogeneity is described in the next section). We clustered aFPs of proteins that mapped to the same localization category and produced 15 per-compartment hierarchical trees (we used average linkage and correlation distance for clustering).</p><p id="P69">We calculated the Silhouette score<sup><xref rid="R69" ref-type="bibr">69</xref></sup> using scikit-learn library, as the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each aFP. The Silhouette coefficient for a sample is (b - a) / max(a, b); b is the distance between a sample and the nearest cluster that the sample is not a part of. We surveyed 15 per-localization hierarchical trees, clustered with average linkage and correlation metric, using correlation thresholds between 0.25 and 0.75, with a step of 0.05. Median of Silhouette scores across all localizations for a given threshold is shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S2e</xref>. We found that thresholds between 0.5 and 0.6 yield maximal Silhouette scores, and a distance threshold of 0.5 corresponded to maximal GO bioprocess AMI value for whole-proteome aFPs clustering. Hence, we chose a 0.5 threshold to cluster aFPs belonging to each per-localization tree, and obtained 30 clusters, which we subsequently called sub-compartmental groups.</p></sec><sec id="S24"><title>Analysis of localization heterogeneity with scFPs</title><p id="P70">We used scFPs from the test set to analyse whole-proteome localization heterogeneity patterns. First, we used the pre-trained LR on 17 localization categories (described in the previous section) to map each protein&#x02019;s test set scFPs to one of the 17 localization classes. We observed that the most probable localization class had an average 0.74 probability per protein (computed across all test set scFPs), while 2nd and 3rd classes scored 0.11 and 0.052 per-protein probabilities respectively. This motivated us to perform heterogeneity analysis with the two most probable localization categories, to avoid low scFPs quantities and potential noise effects. We then computed a mean probability across each localization class to determine the two most frequent localizations of the protein. Hence, for each protein <italic toggle="yes">X</italic> we obtained a distribution of 2-dimensional real valued probability vectors <inline-formula><mml:math id="M9" display="inline"><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mspace width="0.25em"/><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/></mml:math></inline-formula> with <inline-formula><mml:math id="M10" display="inline"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M11" display="inline"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mspace width="0.25em"/></mml:math></inline-formula> corresponding to the probabilities of the first and second most frequent Iocalization classes, <inline-formula><mml:math id="M12" display="inline"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M13" display="inline"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of test set scFPs of the protein <inline-formula><mml:math id="M14" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula>. Given this distribution, we could compute whether protein <inline-formula><mml:math id="M15" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> is single-localizing or has AND-type / OR-type localization heterogeneity. We filtered low-confidence scFPs <inline-formula><mml:math id="M16" display="inline"><mml:mi>i</mml:mi></mml:math></inline-formula> whose sum of probabilities was below a confidence threshold: <inline-formula><mml:math id="M17" display="inline"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mtext>&#x003b1;</mml:mtext><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (low confidence region). Next, based on a heterogeneity threshold &#x003b2;, we divided the rest of the scFPs into first localization if <inline-formula><mml:math id="M18" display="inline"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:mtext>&#x003b2;</mml:mtext></mml:mrow></mml:math></inline-formula>, second localization if <inline-formula><mml:math id="M19" display="inline"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow/><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mspace width="0.25em"/><mml:mtext>&#x003b2;</mml:mtext></mml:mrow></mml:math></inline-formula>, or mixed-localizing category otherwise. We varied values of <inline-formula><mml:math id="M20" display="inline"><mml:mrow><mml:msub><mml:mtext>&#x003b1;</mml:mtext><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> between 0.5 and 0.9, and values of <inline-formula><mml:math id="M21" display="inline"><mml:mtext>&#x003b2;</mml:mtext></mml:math></inline-formula> between 0.25 and 0.75 (with a step of 0.05), inspecting numbers of assignments into localization categories and low-confidence region, and selected <inline-formula><mml:math id="M22" display="inline"><mml:mrow><mml:msub><mml:mtext>&#x003b1;</mml:mtext><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M23" display="inline"><mml:mtext>&#x003b2;</mml:mtext></mml:math></inline-formula> as 0.5 based on elbow point analysis. Hence, scFPs of each protein were mapped into one of four classes - primary localization, secondary localization, mixed localization or low-confidence region (<xref rid="F4" ref-type="fig">Fig. 4d</xref>). If we assume that percentages of the corresponding categories for protein <inline-formula><mml:math id="M24" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> are <inline-formula><mml:math id="M25" display="inline"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>, then protein <inline-formula><mml:math id="M26" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> would be marked as AND-type localizing if mixed category had higher percentage of scFPs than primary and secondary localizations together <inline-formula><mml:math id="M27" display="inline"><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>; otherwise protein <inline-formula><mml:math id="M28" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> would be marked as OR-type if no less than 8% of scFPs belonged to the secondary localization <inline-formula><mml:math id="M29" display="inline"><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x0003e;</mml:mo><mml:mn>0.</mml:mn><mml:mspace width="0.25em"/><mml:mtext/><mml:mn>08</mml:mn></mml:mrow></mml:math></inline-formula> and single-localizing in the other case. We experimented with OR-type thresholds between 0.05 and 0.3 (with a step of 0.01), and found that the number of OR-type localizing proteins saturated between 0.07 and 0.1 thresholds. We selected 0.08 as an elbow point between <inline-formula><mml:math id="M30" display="inline"><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> value and number of category assignments. Thus, each protein was marked as single-localizing, OR-type, AND-type or undetermined (if too many scFPs were assigned as low-confidence).</p></sec><sec id="S25"><title>Cell cycle prediction and annotation with scFPs</title><p id="P71">We trained an ensemble of three CNNs for cell cycle classification using cytosolic and nuclear channels from our dataset. These two channels contained enough information to distinguish the cell cycle stage of a cell. The CNN contains four convolutional blocks followed by two fully-connected layers, and was trained to predict one of four cell cycle stages - G1, S, metaphase and anaphase (MA), or telophase (T) (<xref rid="SD1" ref-type="supplementary-material">Fig. S6a</xref>).</p><p id="P72">We manually labeled 800 crops of cells from 103 different proteins, corresponding to distinct cell cycle stages (with 200 crops from each class) and used heavy data augmentation during training to prevent overfitting:rotation by arbitrary angle, vertical and horizontal flips, image zoom within 0.02 range, and vertical and horizontal shifts of up to 9 pixels. We used three-fold cross-validation. The training was performed on 64&#x000d7;64&#x000d7;2 dimensional crops over 150 epochs using Adam optimizer, with loss being a categorical cross-entropy across 4 cell cycle categories. We performed hyperparameter optimization to select learning rate (5e-4) and dropout rate (0.05). We performed 3 independent runs with random weights initialization (using truncated normal distribution with a standard deviation of 0.1). Model weights were saved after every epoch, and final models for each run were selected with early stopping based on maximal validation accuracy. Training and test accuracy and categorical cross-entropy loss are shown in <xref rid="SD1" ref-type="supplementary-material">Fig. S6b</xref>. We created an ensemble of three CNNs (from epochs corresponding to minimal loss value), and subsequently mapped each single-cell crop to a 4-dimensional real valued vector of cell cycle probabilities. The cell cycle probability vector was computed as an average of three CNNs&#x02019; probability vectors of that crop. We subsequently joined T and G1 categories due to high cell density in certain crops, which could potentially lead to an incorrect cell cycle category assignment.</p><p id="P73">We applied Mann-Whitney U test<sup><xref rid="R48" ref-type="bibr">48</xref></sup> to identify proteins whose localization changes had cell cycle dependency. For each protein with localization heterogeneity, we annotated its single-cell crops from train, validation and test sets using both LR localization categories and cell cycle stages (via cell cycle classifier). We selected two primary annotated localizations, and compared cell cycle stage distribution of the corresponding crops. For each cell cycle stage, our null hypothesis was that the stage was equally represented among both localizations. Localizations with significant distribution differences (i.e. p-value &#x0003c; 1e-3) were annotated as related to the particular cell cycle stage.</p></sec><sec id="S26"><title>Functional enrichment analysis</title><p id="P74">Gene Ontology (GO) enrichments were performed using GO-term Finder Version 0.86, available through the <italic toggle="yes">Saccharomyces cerevisiae</italic> Genome Database (<ext-link xlink:href="https://www.yeastgenome.org/goTermFinder" ext-link-type="uri">https://www.yeastgenome.org/goTermFinder</ext-link>). We applied gene set enrichment analysis (GSEA) using Python package GSEApy<sup><xref rid="R70" ref-type="bibr">70</xref></sup> (<ext-link xlink:href="https://github.com/zqfang/GSEApy" ext-link-type="uri">https://github.com/zqfang/GSEApy</ext-link>) to analyse hierarchically clustered protein groups, sub-compartmental groups and sets of multi-localizing and mixed-localizing proteins (<bold>Table S2, S3</bold>). Query gene sets for GSEA included GO biological process, cellular component and molecular function standards<sup><xref rid="R29" ref-type="bibr">29</xref></sup>. GSEA results were filtered to include gene sets with p-values below 0.05 and a minimum gene set size of 2. We applied Bonferroni correction to obtain adjusted p-values. We also applied one-sided Fisher&#x02019;s exact test with Costanzo group 19<sup><xref rid="R32" ref-type="bibr">32</xref></sup> categories to analyse nucleus OR cytoplasm, nucleus AND cytoplasm gene sets, reporting protein sets with p-value &#x0003c; 0.05 as the ones showing enrichment (<bold>Table S3</bold>).</p></sec><sec id="S27"><title>Discovery of interacting proteins from scFPs</title><p id="P75">We identified clusters containing potentially interacting proteins using two steps. First, we hierarchically clustered scFPs from the test set (we used average linkage and a correlation metric). After that, we divided the dendrogram from top to bottom and traced the number of unique proteins inside the cluster along with the division thresholds of 0.05 points. We found thresholds of the dendrogram at which the number of proteins in a cluster plateaus (95% of protein composition remains the same). After such &#x0201c;morphologically inseparable&#x0201d; clusters were identified, we used three data-driven scores to measure the quality of the resulting clusters - cell ratio, elbow point, and child ratio. Cell ratio <italic toggle="yes">c</italic> is an average percentage of a protein&#x02019;s cells that fall into a particular cluster. A higher cell ratio translates into less dispersed cells of the same protein, and more confident protein assignment into the particular cluster. Elbow point &#x1d458; is a clustering distance at the level of the current cut (1-PCC in our case). A lower elbow point corresponds to a smaller distance between proteins in their feature profiles space. Descendant ratio <italic toggle="yes">d</italic> of the particular root cluster is the percentage of its descendent clusters that were annotated to the same root. A high child ratio corresponds to more agreement of the child clusters, hence indicating a more confident prediction. We devise a final score S as follows:
<disp-formula id="FD4">
<mml:math id="M31" display="block"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:math>
</disp-formula>
We used a final score cutoff of 0.6 to produce a list of 88 high-confidence clusters. We compared performance of our adaptive thresholding approach with clustering approaches from three different families - connectivity (hierarchical clustering<sup><xref rid="R33" ref-type="bibr">33</xref></sup>), centroid (k-means<sup><xref rid="R49" ref-type="bibr">49</xref></sup>) and density methods (DBSCAN<sup><xref rid="R50" ref-type="bibr">50</xref></sup>) (<xref rid="F5" ref-type="fig">Fig. 5c</xref>). We performed clustering on the same test set of scFPs with different approaches. For each of the methods used in our comparison, we tried a range of hyperparameters (k ranging from 5 to 500 with a step of 5 in k-means, epsilon ranging from 0.1 to 5 with a step of 0.1 in DBSCAN, and correlation threshold ranging from 0.05 to 0.5 with a step of 0.025 for hierarchical clustering) and report the ones corresponding to the maximal median F1-score across all clusters. F1 scores were calculated by assigning each pair of scFPs ground truth label (0 or 1 depending on whether they are part of the same protein complex) and predicted label (0 or 1 depending on whether they are part of the same cluster).</p></sec><sec id="S28"><title>Gradient maps</title><p id="P76">We applied the SmoothGrad method to obtain per-feature gradient maps of the input images<sup><xref rid="R55" ref-type="bibr">55</xref></sup>. Original gradient maps <inline-formula><mml:math id="M32" display="inline"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/></mml:math></inline-formula> compute the derivative of activation function <inline-formula><mml:math id="M33" display="inline"><mml:mi>S</mml:mi></mml:math></inline-formula> of the highest-scoring class <inline-formula><mml:math id="M34" display="inline"><mml:mi>c</mml:mi></mml:math></inline-formula> with respect to the input image <inline-formula><mml:math id="M35" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula>, and thus highlight pixels which influence classification decision:
<disp-formula id="FD5">
<mml:math id="M36" display="block"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math>
</disp-formula>
Since we were interested in feature interpretation, but not interpreting the classification decision, we modified this computation. In our implementation of gradient map <inline-formula><mml:math id="M37" display="inline"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we take the derivative of specific feature <inline-formula><mml:math id="M38" display="inline"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from the feature vector <inline-formula><mml:math id="M39" display="inline"><mml:mi>f</mml:mi></mml:math></inline-formula> with respect to the input image <inline-formula><mml:math id="M40" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula>:
<disp-formula id="FD6">
<mml:math id="M41" display="block"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mo>&#x02202;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math>
</disp-formula>
Hence, our gradient maps highlight regions of the image that impact the value of the selected feature. SmoothGrad produces a gradient map <inline-formula><mml:math id="M42" display="inline"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by averaging a number of gradient maps obtained from an input image with added noise <inline-formula><mml:math id="M43" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:
<disp-formula id="FD7">
<mml:math id="M44" display="block"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mi>&#x002c6;</mml:mi></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mspace width="0.25em"/></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math>
</disp-formula>
We used n=100 images and &#x003c3;=0.05 noise level.</p></sec></sec><sec sec-type="supplementary-material" id="SM1"><title>Supplementary Material</title><supplementary-material id="SD1" position="float" content-type="local-data"><label>Supplement 1</label><media xlink:href="NIHPP2023.02.24.529975v1-supplement-1.pdf" id="d64e2470" position="anchor"/></supplementary-material></sec></body><back><ack id="S29"><title>Acknowledgments</title><p id="P77">We thank Oren Kraus, Michael Costanzo, Nil Sahin, Alan Moses, Leah Cowen and Matej Usaj for valuable discussions and advice. This work was supported by grants from the National Institutes of Health (R01HG005853 to B.A., C.B.), and the Canadian Institutes of Health Research (PJT-180259 to B.A.). Equipment for automated image acquisition and analysis was purchased using funds from the Canadian Foundation for Innovation and the Ontario Research Fund. J.B. was supported by the Canadian Institute for Advanced Research (CIFAR) AI Chairs program and the National Sciences and Engineering Research Council (Canada). Computational resources were provided, in part, by the Province of Ontario and the Government of Canada through the Vector Institute for Artificial Intelligence. A.R. was supported by the Province of Ontario (Ontario Graduate Scholarship, 2021-2022) and the Vector Institute for Artificial Intelligence (Vector Institute Postgraduate Affiliate Scholarship, 2019-2021). C.B. is a Fellow of the CIFAR.</p></ack><fn-group><fn id="FN3"><p id="P79">Code availability</p><p id="P80">Source code for the PIFiA network and downstream analysis is available at <ext-link xlink:href="https://github.com/arazd/pifia" ext-link-type="uri">https://github.com/arazd/pifia</ext-link>.</p></fn></fn-group><sec sec-type="data-availability" id="S30"><title>Data availability</title><p id="P78">The image data used in this work are available at <ext-link xlink:href="https://thecellvision.org/pifia/" ext-link-type="uri">https://thecellvision.org/pifia/</ext-link>.</p></sec><ref-list><title>References</title><ref id="R1"><label>1.</label><mixed-citation publication-type="journal"><name><surname>Cho</surname><given-names>N. H.</given-names></name>
<etal/>
<article-title>OpenCell: Endogenous tagging for the cartography of human cellular organization</article-title>. <source>Science</source>
<volume>375</volume>, <fpage>eabi6983</fpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35271311</pub-id></mixed-citation></ref><ref id="R2"><label>2.</label><mixed-citation publication-type="journal"><name><surname>Chong</surname><given-names>Y. T.</given-names></name>
<etal/>
<article-title>Yeast proteome dynamics from single cell imaging and automated analysis</article-title>. <source>Cell</source>
<volume>161</volume>, <fpage>1413</fpage>&#x02013;<lpage>1424</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26046442</pub-id></mixed-citation></ref><ref id="R3"><label>3.</label><mixed-citation publication-type="journal"><name><surname>Mattiazzi Usaj</surname><given-names>M.</given-names></name>
<etal/>
<article-title>Systematic genetics and single-cell imaging reveal widespread morphological pleiotropy and cell-to-cell variability</article-title>. <source>Molecular systems biology</source>
<volume>16</volume>, <fpage>e9243</fpage> (<year>2020</year>).<pub-id pub-id-type="pmid">32064787</pub-id></mixed-citation></ref><ref id="R4"><label>4.</label><mixed-citation publication-type="journal"><name><surname>Thul</surname><given-names>P. J.</given-names></name>
<etal/>
<article-title>A subcellular map of the human proteome</article-title>. <source>Science</source>
<volume>356</volume>, <fpage>eaal3321</fpage> (<year>2017</year>).<pub-id pub-id-type="pmid">28495876</pub-id></mixed-citation></ref><ref id="R5"><label>5.</label><mixed-citation publication-type="journal"><name><surname>Thul</surname><given-names>P. J.</given-names></name> &#x00026; <name><surname>Lindskog</surname><given-names>C.</given-names></name>
<article-title>The human protein atlas: a spatial map of the human proteome</article-title>. <source>Protein Science</source>
<volume>27</volume>, <fpage>233</fpage>&#x02013;<lpage>244</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">28940711</pub-id></mixed-citation></ref><ref id="R6"><label>6.</label><mixed-citation publication-type="journal"><name><surname>Usaj</surname><given-names>M. M.</given-names></name>
<etal/>
<article-title>High-content screening for quantitative cell biology</article-title>. <source>Trends Cell Biol</source>. <volume>26</volume>, <fpage>598</fpage>&#x02013;<lpage>611</lpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27118708</pub-id></mixed-citation></ref><ref id="R7"><label>7.</label><mixed-citation publication-type="journal"><name><surname>McQuin</surname><given-names>C.</given-names></name>
<etal/>
<article-title>CellProfiler 3.0: Next-generation image processing for biology</article-title>. <source>PLoS biology</source>
<volume>16</volume>, <fpage>e2005970</fpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29969450</pub-id></mixed-citation></ref><ref id="R8"><label>8.</label><mixed-citation publication-type="journal"><name><surname>Kraus</surname><given-names>O. Z.</given-names></name>
<etal/>
<article-title>Automated analysis of high-content microscopy data with deep learning</article-title>. <source>Molecular systems biology</source>
<volume>13</volume>, <fpage>924</fpage> (<year>2017</year>).<pub-id pub-id-type="pmid">28420678</pub-id></mixed-citation></ref><ref id="R9"><label>9.</label><mixed-citation publication-type="journal"><name><surname>Kraus</surname><given-names>O. Z.</given-names></name>, &#x00026; <name><surname>Frey</surname><given-names>B. J.</given-names></name>
<article-title>Computer vision for high content screening</article-title>. <source>Critical reviews in biochemistry and molecular biology</source>
<volume>51</volume>, <fpage>102</fpage>&#x02013;<lpage>109</lpage> (<year>2016</year>).<pub-id pub-id-type="pmid">26806341</pub-id></mixed-citation></ref><ref id="R10"><label>10.</label><mixed-citation publication-type="journal"><name><surname>Huh</surname><given-names>W.</given-names></name>
<etal/>
<article-title>Global analysis of protein localization in budding yeast</article-title>. <source>Nature</source>
<volume>425</volume>, <fpage>686</fpage>&#x02013;<lpage>691</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">14562095</pub-id></mixed-citation></ref><ref id="R11"><label>11.</label><mixed-citation publication-type="journal"><name><surname>Domnauer</surname><given-names>M.</given-names></name>
<etal/>
<article-title>Proteome plasticity in response to persistent environmental change</article-title>. <source>Mol. Cell</source>
<volume>81</volume>, <fpage>3294</fpage>&#x02013;<lpage>3309. e12</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34293321</pub-id></mixed-citation></ref><ref id="R12"><label>12.</label><mixed-citation publication-type="journal"><name><surname>Sullivan</surname><given-names>D. P.</given-names></name>
<etal/>
<article-title>Deep learning is combined with massive-scale citizen science to improve large-scale image classification</article-title>. <source>Nat. Biotechnol</source>. <volume>36</volume>, <fpage>820</fpage>&#x02013;<lpage>828</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30125267</pub-id></mixed-citation></ref><ref id="R13"><label>13.</label><mixed-citation publication-type="journal"><name><surname>Grys</surname><given-names>B. T.</given-names></name>
<etal/>
<article-title>Machine learning and computer vision approaches for phenotypic profiling</article-title>. <source>J. Cell Biol</source>. <volume>216</volume>, <fpage>65</fpage>&#x02013;<lpage>71</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">27940887</pub-id></mixed-citation></ref><ref id="R14"><label>14.</label><mixed-citation publication-type="journal"><name><surname>Kraus</surname><given-names>O. Z.</given-names></name>, <name><surname>Ba</surname><given-names>J. L.</given-names></name> &#x00026; <name><surname>Frey</surname><given-names>B. J.</given-names></name>
<article-title>Classifying and segmenting microscopy images with deep multiple instance learning</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>i52</fpage>&#x02013;<lpage>i59</lpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27307644</pub-id></mixed-citation></ref><ref id="R15"><label>15.</label><mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>A. X.</given-names></name>, <name><surname>Kraus</surname><given-names>O. Z.</given-names></name>, <name><surname>Cooper</surname><given-names>S.</given-names></name> &#x00026; <name><surname>Moses</surname><given-names>A. M.</given-names></name>
<article-title>Learning unsupervised feature representations for single cell microscopy images with paired cell inpainting</article-title>. <source>PLoS computational biology</source>
<volume>15</volume>, <fpage>e1007348</fpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31479439</pub-id></mixed-citation></ref><ref id="R16"><label>16.</label><mixed-citation publication-type="confproc"><name><surname>Chen</surname><given-names>T.</given-names></name>, <name><surname>Kornblith</surname><given-names>S.</given-names></name>, <name><surname>Norouzi</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Hinton</surname><given-names>G.</given-names></name>
<source>A simple framework for contrastive learning of visual representations</source> (<conf-name>International conference on machine learning, PMLR</conf-name>, <year>2020</year>).</mixed-citation></ref><ref id="R17"><label>17.</label><mixed-citation publication-type="confproc"><name><surname>Jenni</surname><given-names>S.</given-names></name> &#x00026;<name><surname>Favaro</surname><given-names>P.</given-names></name>
<source>Self-supervised feature learning by learning to spot artifacts</source> (<conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name>, <year>2018</year>).</mixed-citation></ref><ref id="R18"><label>18.</label><mixed-citation publication-type="journal"><name><surname>Jing</surname><given-names>L.</given-names></name> &#x00026; <name><surname>Tian</surname><given-names>Y.</given-names></name>
<article-title>Self-supervised visual feature learning with deep neural networks: A survey</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>. <volume>43</volume>, <fpage>4037</fpage>&#x02013;<lpage>4058</lpage> (<year>2020</year>).</mixed-citation></ref><ref id="R19"><label>19.</label><mixed-citation publication-type="journal"><name><surname>Jaiswal</surname><given-names>A.</given-names></name>, <name><surname>Babu</surname><given-names>A. R.</given-names></name>, <name><surname>Zadeh</surname><given-names>M. Z.</given-names></name>, <name><surname>Banerjee</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Makedon</surname><given-names>F.</given-names></name>
<article-title>A survey on contrastive self-supervised learning</article-title>. <source>Technologies</source>
<volume>9</volume>, <fpage>2</fpage> (<year>2020</year>).</mixed-citation></ref><ref id="R20"><label>20.</label><mixed-citation publication-type="confproc"><name><surname>Kolesnikov</surname><given-names>A.</given-names></name>, <name><surname>Zhai</surname><given-names>X.</given-names></name> &#x00026; <name><surname>Beyer</surname><given-names>L.</given-names></name>
<source>Revisiting self-supervised visual representation learning</source> (<conf-name>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</conf-name>, <year>2019</year>).</mixed-citation></ref><ref id="R21"><label>21.</label><mixed-citation publication-type="journal"><name><surname>Guo</surname><given-names>S.</given-names></name>
<etal/>
<article-title>Revealing architectural order with quantitative label-free imaging and deep learning</article-title>. <source>Elife</source>
<volume>9</volume>, <fpage>e55502</fpage> (<year>2020</year>).<pub-id pub-id-type="pmid">32716843</pub-id></mixed-citation></ref><ref id="R22"><label>22.</label><mixed-citation publication-type="journal"><name><surname>Kobayashi</surname><given-names>H.</given-names></name>, <name><surname>Cheveralls</surname><given-names>K. C.</given-names></name>, <name><surname>Leonetti</surname><given-names>M. D.</given-names></name> &#x00026; <name><surname>Royer</surname><given-names>L. A.</given-names></name>
<article-title>Self-supervised deep learning encodes high-resolution features of protein subcellular localization</article-title>. <source>Nature methods</source>
<volume>19</volume>, <fpage>995</fpage>&#x02013;<lpage>1003</lpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35879608</pub-id></mixed-citation></ref><ref id="R23"><label>23.</label><mixed-citation publication-type="journal"><name><surname>Zaritsky</surname><given-names>A.</given-names></name>
<etal/>
<article-title>Interpretable deep learning uncovers cellular properties in label-free live cell images that are predictive of highly metastatic melanoma</article-title>. <source>Cell Systems</source>
<volume>12</volume>, <fpage>733</fpage>&#x02013;<lpage>747. e6</lpage> (<year>2021</year>).<pub-id pub-id-type="pmid">34077708</pub-id></mixed-citation></ref><ref id="R24"><label>24.</label><mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>D. P.</given-names></name> &#x00026; <name><surname>Welling</surname><given-names>M.</given-names></name>
<article-title>Auto-encoding variational bayes</article-title>. <source>arXiv preprint arXiv:1312.6114</source> (<year>2013</year>).</mixed-citation></ref><ref id="R25"><label>25.</label><mixed-citation publication-type="journal"><name><surname>Van Den Oord</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Vinyals</surname><given-names>O.</given-names></name>
<article-title>Neural discrete representation learning</article-title>. <source>Advances in neural information processing systems</source>
<volume>30</volume> (<year>2017</year>).</mixed-citation></ref><ref id="R26"><label>26.</label><mixed-citation publication-type="confproc"><name><surname>Huang</surname><given-names>G.</given-names></name>, <name><surname>Liu</surname><given-names>Z.</given-names></name>, <name><surname>Van Der Maaten</surname><given-names>L.</given-names></name> &#x00026; <name><surname>Weinberger</surname><given-names>K. Q.</given-names></name>
<source>Densely connected convolutional networks</source> (<conf-name>Proceedings of the IEEE conference on computer vision and pattern recognition</conf-name>, <year>2017</year>).</mixed-citation></ref><ref id="R27"><label>27.</label><mixed-citation publication-type="journal"><name><surname>Ho</surname><given-names>B.</given-names></name>, <name><surname>Baryshnikova</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Brown</surname><given-names>G. W.</given-names></name>
<article-title>Unification of protein abundance datasets yields a quantitative Saccharomyces cerevisiae proteome</article-title>. <source>Cell systems</source>
<volume>6</volume>, <fpage>192</fpage>&#x02013;<lpage>205. e3</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29361465</pub-id></mixed-citation></ref><ref id="R28"><label>28.</label><mixed-citation publication-type="book"><name><surname>Yan Tong</surname><given-names>A. H.</given-names></name> &#x00026; <name><surname>Boone</surname><given-names>C.</given-names></name> in <source>Yeast Protocol</source>
<fpage>171</fpage>&#x02013;<lpage>191</lpage> (<publisher-name>Springer</publisher-name>, <year>2006</year>).</mixed-citation></ref><ref id="R29"><label>29.</label><mixed-citation publication-type="journal"><collab>Gene Ontology Consortium</collab>. <article-title>The Gene Ontology (GO) database and informatics resource</article-title>. <source>Nucleic Acids Res</source>. <volume>32</volume>, <fpage>D258</fpage>&#x02013;<lpage>D261</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">14681407</pub-id></mixed-citation></ref><ref id="R30"><label>30.</label><mixed-citation publication-type="journal"><name><surname>Kanehisa</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Goto</surname><given-names>S.</given-names></name>
<article-title>KEGG: kyoto encyclopedia of genes and genomes</article-title>. <source>Nucleic Acids Res</source>. <volume>28</volume>, <fpage>27</fpage>&#x02013;<lpage>30</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10592173</pub-id></mixed-citation></ref><ref id="R31"><label>31.</label><mixed-citation publication-type="journal"><name><surname>Meldal</surname><given-names>B. H.</given-names></name>
<etal/>
<article-title>The complex portal-an encyclopaedia of macromolecular complexes</article-title>. <source>Nucleic Acids Res</source>. <volume>43</volume>, <fpage>D479</fpage>&#x02013;<lpage>D484</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25313161</pub-id></mixed-citation></ref><ref id="R32"><label>32.</label><mixed-citation publication-type="journal"><name><surname>Costanzo</surname><given-names>M.</given-names></name>
<etal/>
<article-title>A global genetic interaction network maps a wiring diagram of cellular function</article-title>. <source>Science</source>
<volume>353</volume>, <fpage>aaf1420</fpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27708008</pub-id></mixed-citation></ref><ref id="R33"><label>33.</label><mixed-citation publication-type="journal"><name><surname>Murtagh</surname><given-names>F.</given-names></name> &#x00026; <name><surname>Contreras</surname><given-names>P.</given-names></name>
<article-title>Algorithms for hierarchical clustering: an overview</article-title>. <source>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</source>
<volume>2</volume>, <fpage>86</fpage>&#x02013;<lpage>97</lpage> (<year>2012</year>).</mixed-citation></ref><ref id="R34"><label>34.</label><mixed-citation publication-type="journal"><name><surname>Vinh</surname><given-names>N. X.</given-names></name>, <name><surname>Epps</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Bailey</surname><given-names>J.</given-names></name>
<article-title>Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance</article-title>. <source>The Journal of Machine Learning Research</source>
<volume>11</volume>, <fpage>2837</fpage>&#x02013;<lpage>2854</lpage> (<year>2010</year>).</mixed-citation></ref><ref id="R35"><label>35.</label><mixed-citation publication-type="journal"><name><surname>Van der Maaten</surname><given-names>L.</given-names></name> &#x00026; <name><surname>Hinton</surname><given-names>G.</given-names></name>
<article-title>Visualizing data using t-SNE</article-title>. <source>Journal of machine learning research</source>
<volume>9</volume> (<year>2008</year>).</mixed-citation></ref><ref id="R36"><label>36.</label><mixed-citation publication-type="book"><name><surname>Silverman</surname><given-names>B. W.</given-names></name> in <source>Density estimation for statistics and data analysis</source> (<publisher-name>Routledge</publisher-name>, <year>2018</year>).</mixed-citation></ref><ref id="R37"><label>37.</label><mixed-citation publication-type="journal"><name><surname>Eldakak</surname><given-names>A.</given-names></name>
<etal/>
<article-title>Asymmetrically inherited multidrug resistance transporters are recessive determinants in cellular replicative ageing</article-title>. <source>Nat. Cell Biol</source>. <volume>12</volume>, <fpage>799</fpage>&#x02013;<lpage>805</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20657593</pub-id></mixed-citation></ref><ref id="R38"><label>38.</label><mixed-citation publication-type="journal"><name><surname>Decottignies</surname><given-names>A.</given-names></name>
<etal/>
<article-title>ATPase and multidrug transport activities of the overexpressed yeast ABC protein Yor1p</article-title>. <source>J. Biol. Chem</source>. <volume>273</volume>, <fpage>12612</fpage>&#x02013;<lpage>12622</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9575223</pub-id></mixed-citation></ref><ref id="R39"><label>39.</label><mixed-citation publication-type="journal"><name><surname>Laussel</surname><given-names>C.</given-names></name>
<etal/>
<article-title>2-deoxyglucose transiently inhibits yeast AMPK signaling and triggers glucose transporter endocytosis, potentiating the drug toxicity</article-title>. <source>PLoS Genetics</source>
<volume>18</volume>, <fpage>e1010169</fpage> (<year>2022</year>).<pub-id pub-id-type="pmid">35951639</pub-id></mixed-citation></ref><ref id="R40"><label>40.</label><mixed-citation publication-type="journal"><name><surname>Phung</surname><given-names>H. T. T.</given-names></name>, <name><surname>Tran</surname><given-names>D. H.</given-names></name> &#x00026; <name><surname>Nguyen</surname><given-names>T. X.</given-names></name>
<article-title>The cruciform DNA-binding protein Crp1 stimulates the endonuclease activity of Mus81&#x02013;Mms4 in Saccharomyces cerevisiae</article-title>. <source>FEBS Lett</source>. <volume>594</volume>, <fpage>4320</fpage>&#x02013;<lpage>4337</lpage> (<year>2020</year>).<pub-id pub-id-type="pmid">32936932</pub-id></mixed-citation></ref><ref id="R41"><label>41.</label><mixed-citation publication-type="journal"><name><surname>Neuber</surname><given-names>O.</given-names></name>, <name><surname>Jarosch</surname><given-names>E.</given-names></name>, <name><surname>Volkwein</surname><given-names>C.</given-names></name>, <name><surname>Walter</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Sommer</surname><given-names>T.</given-names></name>
<article-title>Ubx2 links the Cdc48 complex to ER-associated protein degradation</article-title>. <source>Nat. Cell Biol</source>. <volume>7</volume>, <fpage>993</fpage>&#x02013;<lpage>998</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">16179953</pub-id></mixed-citation></ref><ref id="R42"><label>42.</label><mixed-citation publication-type="journal"><name><surname>Boone</surname><given-names>C.</given-names></name>, <name><surname>Sommer</surname><given-names>S. S.</given-names></name>, <name><surname>Hensel</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Bussey</surname><given-names>H.</given-names></name>
<article-title>Yeast KRE genes provide evidence for a pathway of cell wall beta-glucan assembly</article-title>. <source>J. Cell Biol</source>. <volume>110</volume>, <fpage>1833</fpage>&#x02013;<lpage>1843</lpage> (<year>1990</year>).<pub-id pub-id-type="pmid">2186051</pub-id></mixed-citation></ref><ref id="R43"><label>43.</label><mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>D.</given-names></name>, <name><surname>Friesen</surname><given-names>H.</given-names></name> &#x00026; <name><surname>Andrews</surname><given-names>B.</given-names></name>
<article-title>Pho85, a multifunctional cyclin-dependent protein kinase in budding yeast</article-title>. <source>Mol. Microbiol</source>. <volume>66</volume>, <fpage>303</fpage>&#x02013;<lpage>314</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17850263</pub-id></mixed-citation></ref><ref id="R44"><label>44.</label><mixed-citation publication-type="journal"><name><surname>Youn</surname><given-names>J.</given-names></name>
<etal/>
<article-title>Functional analysis of kinases and transcription factors in Saccharomyces cerevisiae using an integrated overexpression library</article-title>. <source>G3: Genes, Genomes, Genetics</source>
<volume>7</volume>, <fpage>911</fpage>&#x02013;<lpage>921</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">28122947</pub-id></mixed-citation></ref><ref id="R45"><label>45.</label><mixed-citation publication-type="journal"><name><surname>Costanzo</surname><given-names>M.</given-names></name>
<etal/>
<article-title>The genetic landscape of a cell</article-title>. <source>Science</source>
<volume>327</volume>, <fpage>425</fpage>&#x02013;<lpage>431</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20093466</pub-id></mixed-citation></ref><ref id="R46"><label>46.</label><mixed-citation publication-type="journal"><name><surname>Haase</surname><given-names>S. B.</given-names></name> &#x00026; <name><surname>Wittenberg</surname><given-names>C.</given-names></name>
<article-title>Topology and control of the cell-cycle-regulated transcriptional circuitry</article-title>. <source>Genetics</source>
<volume>196</volume>, <fpage>65</fpage>&#x02013;<lpage>90</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24395825</pub-id></mixed-citation></ref><ref id="R47"><label>47.</label><mixed-citation publication-type="journal"><name><surname>Tkach</surname><given-names>J. M.</given-names></name>
<etal/>
<article-title>Dissecting DNA damage response pathways by analysing protein localization and abundance changes during DNA replication stress</article-title>. <source>Nat. Cell Biol</source>. <volume>14</volume>, <fpage>966</fpage>&#x02013;<lpage>976</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22842922</pub-id></mixed-citation></ref><ref id="R48"><label>48.</label><mixed-citation publication-type="journal"><name><surname>McKnight</surname><given-names>P. E.</given-names></name> &#x00026; <name><surname>Najab</surname><given-names>J.</given-names></name>
<article-title>Mann-Whitney U Test</article-title>. <source>The Corsini encyclopedia of psychology</source>, <fpage>1</fpage> (<year>2010</year>).</mixed-citation></ref><ref id="R49"><label>49.</label><mixed-citation publication-type="confproc"><name><surname>Sculley</surname><given-names>D.</given-names></name>
<source>Web-scale k-means clustering</source> (<conf-name>Proceedings of the 19th international conference on World wide web</conf-name>, <year>2010</year>).</mixed-citation></ref><ref id="R50"><label>50.</label><mixed-citation publication-type="other"><name><surname>Ester</surname><given-names>M.</given-names></name>, <name><surname>Kriegel</surname><given-names>H.</given-names></name>, <name><surname>Sander</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Xu</surname><given-names>X.</given-names></name>
<source>A density-based algorithm for discovering clusters in large spatial databases with noise</source>. (<comment>kdd Ser. 96</comment>, <year>1996</year>).</mixed-citation></ref><ref id="R51"><label>51.</label><mixed-citation publication-type="journal"><name><surname>Stark</surname><given-names>C.</given-names></name>
<etal/>
<article-title>BioGRID: a general repository for interaction datasets</article-title>. <source>Nucleic Acids Res</source>. <volume>34</volume>, <fpage>D535</fpage>&#x02013;<lpage>D539</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16381927</pub-id></mixed-citation></ref><ref id="R52"><label>52.</label><mixed-citation publication-type="journal"><name><surname>Deshpande</surname><given-names>I.</given-names></name>
<etal/>
<article-title>The Sir4 H-BRCT domain interacts with phospho-proteins to sequester and repress yeast heterochromatin</article-title>. <source>EMBO J</source>. <volume>38</volume>, <fpage>e101744</fpage> (<year>2019</year>).<pub-id pub-id-type="pmid">31515872</pub-id></mixed-citation></ref><ref id="R53"><label>53.</label><mixed-citation publication-type="journal"><name><surname>Selvaraju</surname><given-names>R. R.</given-names></name>
<etal/>
<article-title>Grad-CAM: Why did you say that?</article-title>
<source>arXiv preprint arXiv:1611.07450</source> (<year>2016</year>).</mixed-citation></ref><ref id="R54"><label>54.</label><mixed-citation publication-type="confproc"><name><surname>Zeiler</surname><given-names>M. D.</given-names></name> &#x00026;<name><surname>Fergus</surname><given-names>R.</given-names></name>
<source>Visualizing and understanding convolutional networks</source> (<conf-name>European conference on computer vision</conf-name>, <publisher-name>Springer</publisher-name>, <year>2014</year>).</mixed-citation></ref><ref id="R55"><label>55.</label><mixed-citation publication-type="journal"><name><surname>Smilkov</surname><given-names>D.</given-names></name>, <name><surname>Thorat</surname><given-names>N.</given-names></name>, <name><surname>Kim</surname><given-names>B.</given-names></name>, <name><surname>Vi&#x000e9;gas</surname><given-names>F.</given-names></name> &#x00026; <name><surname>Wattenberg</surname><given-names>M.</given-names></name>
<article-title>Smoothgrad: removing noise by adding noise</article-title>. <source>arXiv preprint arXiv:1706.03825</source> (<year>2017</year>).</mixed-citation></ref><ref id="R56"><label>56.</label><mixed-citation publication-type="confproc"><name><surname>Deng</surname><given-names>J.</given-names></name>
<etal/>
<source>Imagenet: A large-scale hierarchical image database</source> (<conf-name>2009 IEEE conference on computer vision and pattern recognition</conf-name>, <publisher-name>Ieee</publisher-name>, <year>2009</year>).</mixed-citation></ref><ref id="R57"><label>57.</label><mixed-citation publication-type="journal"><name><surname>Razdaibiedina</surname><given-names>A.</given-names></name>, <name><surname>Velayutham</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Modi</surname><given-names>M.</given-names></name>
<article-title>Multi-defect microscopy image restoration under limited data conditions</article-title>. <source>arXiv preprint arXiv:1910.14207</source> (<year>2019</year>).</mixed-citation></ref><ref id="R58"><label>58.</label><mixed-citation publication-type="journal"><name><surname>Albert</surname><given-names>S.</given-names></name>
<etal/>
<article-title>Proteasomes tether to two distinct sites at the nuclear pore complex</article-title>. <source>Proceedings of the National Academy of Sciences</source>
<volume>114</volume>, <fpage>13726</fpage>&#x02013;<lpage>13731</lpage> (<year>2017</year>).</mixed-citation></ref><ref id="R59"><label>59.</label><mixed-citation publication-type="journal"><name><surname>He</surname><given-names>C.</given-names></name>, <name><surname>Zhou</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Kennedy</surname><given-names>B. K.</given-names></name>
<article-title>The yeast replicative aging model</article-title>. <source>Biochimica et Biophysica Acta (BBA)-Molecular Basis of Disease</source>
<volume>1864</volume>, <fpage>2690</fpage>&#x02013;<lpage>2696</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29524633</pub-id></mixed-citation></ref><ref id="R60"><label>60.</label><mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>M. J.</given-names></name>, <name><surname>Chong</surname><given-names>Y. T.</given-names></name>, <name><surname>Boone</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Andrews</surname><given-names>B.</given-names></name>
<article-title>Liquid growth of arrayed fluorescently tagged Saccharomyces cerevisiae strains for live-cell high-throughput microscopy screens</article-title>. <source>Cold Spring Harbor Protocols</source>
<volume>2016</volume>, <fpage>pdb. prot088799</fpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27037071</pub-id></mixed-citation></ref><ref id="R61"><label>61.</label><mixed-citation publication-type="journal"><name><surname>Meurer</surname><given-names>M.</given-names></name>
<etal/>
<article-title>Genome-wide C-SWAT library for high-throughput yeast genome tagging</article-title>. <source>Nature methods</source>
<volume>15</volume>, <fpage>598</fpage>&#x02013;<lpage>600</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29988096</pub-id></mixed-citation></ref><ref id="R62"><label>62.</label><mixed-citation publication-type="journal"><name><surname>Sheff</surname><given-names>M. A.</given-names></name> &#x00026; <name><surname>Thorn</surname><given-names>K. S.</given-names></name>
<article-title>Optimized cassettes for fluorescent protein tagging in Saccharomyces cerevisiae</article-title>. <source>Yeast</source>
<volume>21</volume>, <fpage>661</fpage>&#x02013;<lpage>670</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15197731</pub-id></mixed-citation></ref><ref id="R63"><label>63.</label><mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>D. P.</given-names></name> &#x00026; <name><surname>Ba</surname><given-names>J.</given-names></name>
<article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv preprint arXiv:1412.6980</source> (<year>2014</year>).</mixed-citation></ref><ref id="R64"><label>64.</label><mixed-citation publication-type="journal"><name><surname>Srivastava</surname><given-names>N.</given-names></name>, <name><surname>Hinton</surname><given-names>G.</given-names></name>, <name><surname>Krizhevsky</surname><given-names>A.</given-names></name>, <name><surname>Sutskever</surname><given-names>I.</given-names></name> &#x00026; <name><surname>Salakhutdinov</surname><given-names>R.</given-names></name>
<article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>The journal of machine learning research</source>
<volume>15</volume>, <fpage>1929</fpage>&#x02013;<lpage>1958</lpage> (<year>2014</year>).</mixed-citation></ref><ref id="R65"><label>65.</label><mixed-citation publication-type="journal"><name><surname>Girosi</surname><given-names>F.</given-names></name>, <name><surname>Jones</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Poggio</surname><given-names>T.</given-names></name>
<article-title>Regularization theory and neural networks architectures</article-title>. <source>Neural Comput</source>. <volume>7</volume>, <fpage>219</fpage>&#x02013;<lpage>269</lpage> (<year>1995</year>).</mixed-citation></ref><ref id="R66"><label>66.</label><mixed-citation publication-type="journal"><name><surname>Abdi</surname><given-names>H.</given-names></name> &#x00026; <name><surname>Williams</surname><given-names>L. J.</given-names></name>
<article-title>Principal component analysis</article-title>. <source>Wiley interdisciplinary reviews: computational statistics</source>
<volume>2</volume>, <fpage>433</fpage>&#x02013;<lpage>459</lpage> (<year>2010</year>).</mixed-citation></ref><ref id="R67"><label>67.</label><mixed-citation publication-type="journal"><name><surname>Razdaibiedina</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Brechalov</surname><given-names>A.</given-names></name>
<article-title>Learning multi-scale functional representations of proteins from single-cell microscopy data</article-title>. <source>arXiv preprint arXiv:2205.11676</source> (<year>2022</year>).</mixed-citation></ref><ref id="R68"><label>68.</label><mixed-citation publication-type="journal"><name><surname>Scott</surname><given-names>D. W.</given-names></name>
<article-title>On optimal and data-based histograms</article-title>. <source>Biometrika</source>
<volume>66</volume>, <fpage>605</fpage>&#x02013;<lpage>610</lpage> (<year>1979</year>).</mixed-citation></ref><ref id="R69"><label>69.</label><mixed-citation publication-type="journal"><name><surname>Rousseeuw</surname><given-names>P. J.</given-names></name>
<article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>. <source>J. Comput. Appl. Math</source>. <volume>20</volume>, <fpage>53</fpage>&#x02013;<lpage>65</lpage> (<year>1987</year>).</mixed-citation></ref><ref id="R70"><label>70.</label><mixed-citation publication-type="journal"><name><surname>Kuleshov</surname><given-names>M. V.</given-names></name>
<etal/>
<article-title>Enrichr: a comprehensive gene set enrichment analysis web server 2016 update</article-title>. <source>Nucleic Acids Res</source>. <volume>44</volume>, <fpage>W90</fpage>&#x02013;<lpage>W97</lpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27141961</pub-id></mixed-citation></ref></ref-list></back><floats-group><fig position="float" id="F1"><label>Figure 1.</label><caption><title>Overview of the PIFiA workflow.</title><p id="P81"><bold>a</bold>, The backbone of PIFiA is a deep learning model, which contains convolutional blocks followed by fully-connected layers. Shown are examples of activations from passing a micrograph of fluorescently labeled Nup2 protein (Nup2-GFP) through the PIFiA network, with corresponding patterns recognized by the convolutional filters. Feature profiles are extracted from the second fully-connected layer, for use in downstream applications (c, d, e). <bold>b</bold>, Illustration of two types of feature profiles produced by PIFiA - single-cell feature profiles (extracted from a single crop) and averaged feature profiles (obtained by averaging all single-cell feature profiles of that protein). <bold>c</bold>, Schematic representation of the global hierarchy of protein feature profile similarities to reveal different levels of functional information. <bold>d</bold>, Illustration of protein function prediction using self-supervised PIFiA feature profiles. <bold>e</bold>, An illustrative example of using PIFiA single-cell feature profiles to investigate the localization heterogeneity of a protein.</p></caption><graphic xlink:href="nihpp-2023.02.24.529975v1-f0001" position="float"/></fig><fig position="float" id="F2"><label>Figure 2.</label><caption><title>Comparison of PIFiA performance to the existing supervised and self-supervised methods for protein representation learning.</title><p id="P82">Bar graphs show the performance of PIFiA and four other methods (X axis) at detecting pairs of functionally related genes/proteins. Performance was assessed using: <bold>a</bold>, the adjusted mutual information; <bold>b</bold>, average precision; <bold>c</bold>, F-score on four biological standards [X axis: Gene Ontology (GO) Cellular Component (CC), GO Slim Bioprocess (GO BP Slim), Kyoto Encyclopedia of Genes and Genomes Pathways (KEGG pathways) and European Bioinformatics Institute protein complexes (Protein Complexes). Error bars indicate the standard deviation of the scores across three independent runs (for deep learning models).</p></caption><graphic xlink:href="nihpp-2023.02.24.529975v1-f0002" position="float"/></fig><fig position="float" id="F3"><label>Figure 3.</label><caption><title>Clustering of PIFiA average feature profiles and analysis of the associated biological information.</title><p id="P83"><bold>a</bold>, Subcellular organization revealed by clustering of PIFiA&#x02019;s average feature profiles. The plot to the left of the Y axis shows the adjusted mutual information curve between clustering labels and GO Cellular Component labels at different distance thresholds. The distance threshold (d = 0.72) indicated on the clustergram produces clusters associated with cell compartments (color codes on the right). <bold>b</bold>, The top three Gene Ontology Cellular Component scores for each cluster defined in a are shown. <bold>c</bold>, Whole-proteome tSNE projection of PIFiA average feature profiles. Each point on the plot represents a protein colored according to a localization category predicted by logistic regression (see <xref rid="S2" ref-type="sec">Results</xref> for training details). <bold>d</bold>, Annotation of the whole-proteome tSNE projection with GO bioprocess categories shown as Gaussian kernel density estimates. Bioprocesses were selected according to the lowest variance from different cellular components. The color intensity of the kernel density estimate contour plots corresponds to the cumulative probability mass below the drawn contour. <bold>e</bold>, Annotation of the whole proteome tSNE projection with sub-compartmental protein groups predicted by clustering of PIFiA feature profiles (cyto - cytoplasmic cluster, nuc - nuclear cluster, mito - mitochondrial cluster etc.; full descriptions of clusters are in <bold>Table S2</bold>). <bold>f</bold>, Representative micrographs of cells expressing mNeonGreen- (left; green images) or mScarlet- (middle; red images) tagged proteins annotated to different sub-compartmental groups within three cellular compartments: <italic toggle="yes">nucleus</italic> (top), <italic toggle="yes">cell periphery</italic> (middle) or <italic toggle="yes">endoplasmic reticulum</italic> (ER, bottom) groups. Overlays of the mNeonGreen and mScarlet images are shown on the right. The tagged proteins are indicated on the micrographs (scale bar shown bottom right).</p></caption><graphic xlink:href="nihpp-2023.02.24.529975v1-f0003" position="float"/></fig><fig position="float" id="F4"><label>Figure 4.</label><caption><title>Identification of proteins with morphological heterogeneity using PIFiA single-cell feature profiles.</title><p id="P84"><bold>a</bold>, Summary of whole-proteome analysis of localization heterogeneity. The heatmap depicts ratios of cells falling into a mixed localization category, secondary and primary localization regions (following the introduced scoring schema). Proteins are arranged in the following order top-to-bottom - proteins with homogeneous localizations, OR-type proteins and AND-type proteins. Proteins with low ratios in all three columns (yellow color) feature many cells that fall into the low confidence region. <bold>b</bold>, Dissecting localization heterogeneity of a protein at a single-cell level : homogeneous localization. Examples of two proteins with homogeneous localization patterns are illustrated using a scatter plot. Each point on the scatter plot corresponds to a single-cell crop, mapped to the probability of nuclear and cytoplasmic localization according to the LR predictions. In this example, the majority of Nat5-GFP expressing cells exhibit clear cytoplasmic localization, while most Tfc7-GFP expressing cells show a clear nuclear pattern. <bold>c</bold>, Dissecting localization heterogeneity of a protein at a single-cell level: heterogeneous localization. Examples of a protein with AND-type localization heterogeneity (Pho85, single-cell FPs shows patterns from its primary AND secondary localization), and multi-localizing heterogeneity (Stb1, protein can be in either its primary OR secondary localization, but not both at the same time) are illustrated using a scatterplot. Cells expressing the Pho85 protein show a mixed signal from the nucleus and cytoplasm, with most cells being distributed along the diagonal. In contrast, Stb1 has two populations of cells in the scatter plot centered either around the nuclear or the cytoplasmic corner. <bold>d</bold>, Schema of scoring proteins for localization heterogeneity using a single-cell level distribution of localization probabilities. Probabilities are obtained from primary and secondary localizations (i.e. first and second most probable localizations of the logistic regression classification of that protein). <bold>e</bold>, Localization co-occurrence heatmap for 396 AND-localizing proteins, showing numbers of proteins present at two localizations. The scale bar is set to a maximum intensity of 50 to enable visualization of categories with fewer proteins (see quantities in <bold>Table S3</bold>). <bold>f</bold>, Circle plot depicting localization patterns of 256 OR-type proteins. Thickness of the line connecting two localizations indicates the number of proteins showing localization heterogeneity between these localizations. <bold>g</bold>, Localization heterogeneity related to cell cycle position for 136 proteins, which exhibited statistically significant cell cycle variation. Connections indicate localizations of the proteins that are present at specific cell cycle stages (thicker lines indicate a more common connection between particular localization change and cell cycle stage transition). The color of the heatmap indicates the number of heterogeneous proteins that are present in the corresponding cell cycle phase for a particular localization.</p></caption><graphic xlink:href="nihpp-2023.02.24.529975v1-f0004" position="float"/></fig><fig position="float" id="F5"><label>Figure 5.</label><caption><title>Discovery of protein functional modules using PIFiA single-cell feature profiles.</title><p id="P85"><bold>a</bold>, Visualization of protein complex clusters on a single-cell tSNE plot of PIFiA feature profiles. The central plot shows a whole proteome tSNE projection of PIFiA single-cell feature profiles (scFPs). Each point on the plot represents a protein that is colored according to 15 different subcellular localizations (color codes are explained below the plot). Zoom-in plots show a more detailed view of some regions of the global tSNE, showing single-cell features from the test set corresponding to proteins from the same complex with the same color palette, each protein shown in different color. <bold>b</bold>, The scFPs dendrogram shows clustering of scFPs highlighting a region that identifies a nuclear pore cluster among nuclear periphery scFPs.The line graph on the right shows changes in the number of proteins in a cluster (X axis) when the correlation threshold for clustering is changed (Y axis). Zoom-in plots of two clusters at different correlation thresholds (red and grey dashed lines) are shown as scFPs tSNE plots to the right. <bold>c</bold>, Violin plots comparing the performance of four clustering approaches on 140 protein complexes are shown: our clustering using PIFiA scFPs, hierarchical clustering, k-means and DBSCAN. <bold>d</bold>, Plot illustrating the fraction of proteins in each cluster with a protein-protein interaction annotated in the BioGrid (blue) or as protein complex member (yellow). Percentage of cluster proteins participating in a protein-protein interaction or being part of the protein complex are shown on the y-axis. Cluster numbers are sorted based on the number of discovered interactions.</p></caption><graphic xlink:href="nihpp-2023.02.24.529975v1-f0005" position="float"/></fig><fig position="float" id="F6"><label>Figure 6.</label><caption><title>Interpretation of PIFiA features.</title><p id="P86"><bold>a</bold>, Heatmap of the logistic regression coefficients for localization prediction associated with each feature. Each feature was mapped to a localization (based on the maximal coefficient value), and features were sorted in descending order of coefficients. <bold>b, c</bold>, Classification accuracy depends on the number of features used to train the logistic regression. We trained logistic regressions with varying numbers of features in the representation profile (sorted in the order of importance for the localization). The three largest and most complex localizations are shown in b, while three smaller and more homogeneous localizations are depicted in c. Shading shows standard deviation across 5 runs. <bold>d</bold>, Gradient maps highlight regions of the input image that CNN &#x0201c;pays attention to&#x0201d;. We show proteins from six distinct subcellular compartments and their gradient maps obtained from four different features (most visually distinct gradient maps with the highest activation values are shown). Features result in different gradient signals, confirming that the CNN captures a variety of within-cell morphological patterns.</p></caption><graphic xlink:href="nihpp-2023.02.24.529975v1-f0006" position="float"/></fig></floats-group></article>
